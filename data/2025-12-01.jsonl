{"id": "2511.21781", "pdf": "https://arxiv.org/pdf/2511.21781", "abs": "https://arxiv.org/abs/2511.21781", "authors": ["Mehyar Mlaweh", "Tristan Cazenave", "Ines Alaya"], "title": "BeeRNA: tertiary structure-based RNA inverse folding using Artificial Bee Colony", "categories": ["q-bio.BM", "cs.AI"], "comment": "Accepted at the AI in Drug Discovery Workshop, AAAI 2026, Singapore", "summary": "The Ribonucleic Acid (RNA) inverse folding problem, designing nucleotide sequences that fold into specific tertiary structures, is a fundamental computational biology problem with important applications in synthetic biology and bioengineering. The design of complex three-dimensional RNA architectures remains computationally demanding and mostly unresolved, as most existing approaches focus on secondary structures. In order to address tertiary RNA inverse folding, we present BeeRNA, a bio-inspired method that employs the Artificial Bee Colony (ABC) optimization algorithm. Our approach combines base-pair distance filtering with RMSD-based structural assessment using RhoFold for structure prediction, resulting in a two-stage fitness evaluation strategy. To guarantee biologically plausible sequences with balanced GC content, the algorithm takes thermodynamic constraints and adaptive mutation rates into consideration. In this work, we focus primarily on short and medium-length RNAs ($<$ 100 nucleotides), a biologically significant regime that includes microRNAs (miRNAs), aptamers, and ribozymes, where BeeRNA achieves high structural fidelity with practical CPU runtimes. The lightweight, training-free implementation will be publicly released for reproducibility, offering a promising bio-inspired approach for RNA design in therapeutics and biotechnology."}
{"id": "2511.22239", "pdf": "https://arxiv.org/pdf/2511.22239", "abs": "https://arxiv.org/abs/2511.22239", "authors": ["Somnath Mondal", "Tinkal Mondal", "Soumajit Pramanik", "Rukmankesh Mehra"], "title": "DeepPNI: Language- and graph-based model for mutation-driven protein-nucleic acid energetics", "categories": ["q-bio.BM", "cs.AI"], "comment": null, "summary": "The interaction between proteins and nucleic acids is crucial for processes that sustain cellular function, including DNA maintenance and the regulation of gene expression and translation. Amino acid mutations in protein-nucleic acid complexes often lead to vital diseases. Experimental techniques have their own specific limitations in predicting mutational effects in protein-nucleic acid complexes. In this study, we compiled a large dataset of 1951 mutations including both protein-DNA and protein-RNA complexes and integrated structural and sequential features to build a deep learning-based regression model named DeepPNI. This model estimates mutation-induced binding free energy changes in protein-nucleic acid complexes. The structural features are encoded via edge-aware RGCN and the sequential features are extracted using protein language model ESM-2. We have achieved a high average Pearson correlation coefficient (PCC) of 0.76 in the large dataset via five-fold cross-validation. Consistent performance across individual dataset of protein-DNA, protein-RNA complexes, and different experimental temperature split dataset make the model generalizable. Our model showed good performance in complex-based five-fold cross-validation, which proved its robustness. In addition, DeepPNI outperformed in external dataset validation, and comparison with existing tools"}
{"id": "2511.21900", "pdf": "https://arxiv.org/pdf/2511.21900", "abs": "https://arxiv.org/abs/2511.21900", "authors": ["Patricia Suriana", "Joshua A. Rackers", "Ewa M. Nowara", "Pedro O. Pinheiro", "John M. Nicoloudis", "Vishnu Sresht"], "title": "Beyond Atoms: Evaluating Electron Density Representation for 3D Molecular Learning", "categories": ["cs.LG", "q-bio.BM"], "comment": null, "summary": "Machine learning models for 3D molecular property prediction typically rely on atom-based representations, which may overlook subtle physical information. Electron density maps -- the direct output of X-ray crystallography and cryo-electron microscopy -- offer a continuous, physically grounded alternative. We compare three voxel-based input types for 3D convolutional neural networks (CNNs): atom types, raw electron density, and density gradient magnitude, across two molecular tasks -- protein-ligand binding affinity prediction (PDBbind) and quantum property prediction (QM9). We focus on voxel-based CNNs because electron density is inherently volumetric, and voxel grids provide the most natural representation for both experimental and computed densities. On PDBbind, all representations perform similarly with full data, but in low-data regimes, density-based inputs outperform atom types, while a shape-based baseline performs comparably -- suggesting that spatial occupancy dominates this task. On QM9, where labels are derived from Density Functional Theory (DFT) but input densities from a lower-level method (XTB), density-based inputs still outperform atom-based ones at scale, reflecting the rich structural and electronic information encoded in density. Overall, these results highlight the task- and regime-dependent strengths of density-derived inputs, improving data efficiency in affinity prediction and accuracy in quantum property modeling."}
{"id": "2511.21770", "pdf": "https://arxiv.org/pdf/2511.21770", "abs": "https://arxiv.org/abs/2511.21770", "authors": ["Luke Rimmo Lego", "Samantha Gauthier", "Denver Jn. Baptiste"], "title": "Automated Statistical and Machine Learning Platform for Biological Research", "categories": ["q-bio.QM", "cs.LG", "stat.ML"], "comment": "7 pages, 2 figures, 25 equations", "summary": "Research increasingly relies on computational methods to analyze experimental data and predict molecular properties. Current approaches often require researchers to use a variety of tools for statistical analysis and machine learning, creating workflow inefficiencies. We present an integrated platform that combines classical statistical methods with Random Forest classification for comprehensive data analysis that can be used in the biological sciences. The platform implements automated hyperparameter optimization, feature importance analysis, and a suite of statistical tests including t tests, ANOVA, and Pearson correlation analysis. Our methodology addresses the gap between traditional statistical software, modern machine learning frameworks and biology, by providing a unified interface accessible to researchers without extensive programming experience. The system achieves this through automatic data preprocessing, categorical encoding, and adaptive model configuration based on dataset characteristics. Initial testing protocols are designed to evaluate classification accuracy across diverse chemical datasets with varying feature distributions. This work demonstrates that integrating statistical rigor with machine learning interpretability can accelerate biological discovery workflows while maintaining methodological soundness. The platform's modular architecture enables future extensions to additional machine learning algorithms and statistical procedures relevant to bioinformatics."}
{"id": "2511.23114", "pdf": "https://arxiv.org/pdf/2511.23114", "abs": "https://arxiv.org/abs/2511.23114", "authors": ["Ankit Gupta", "Mustafa Khammash"], "title": "A Spectral Koopman Approximation Framework for Stochastic Reaction Networks", "categories": ["q-bio.MN", "math.PR", "q-bio.QM"], "comment": "7 figures", "summary": "Stochastic reaction networks (SRNs) are a general class of continuous-time Markov jump processes used to model a wide range of systems, including biochemical dynamics in single cells, ecological and epidemiological populations, and queueing or communication networks. Yet analyzing their dynamics remains challenging because these processes are high-dimensional and their transient behavior can vary substantially across different initial molecular or population states. Here we introduce a spectral framework for the stochastic Koopman operator that provides a tractable, low-dimensional representation of SRN dynamics over continuous time, together with computable error estimates. By exploiting the compactness of the Koopman operator, we recover dominant spectral modes directly from simulated or experimental data, enabling efficient prediction of moments, event probabilities, and other summary statistics across all initial states. We further derive continuous-time parameter sensitivities and cross-spectral densities, offering new tools for probing noise structure and frequency-domain behavior. We demonstrate the approach on biologically relevant systems, including synthetic intracellular feedback controllers, stochastic oscillators, and inference of initial-state distributions from high-temporal-resolution flow cytometry. Together, these results establish spectral Koopman analysis as a powerful and general framework for studying stochastic dynamical systems across the biological, ecological, and computational sciences."}
{"id": "2511.22050", "pdf": "https://arxiv.org/pdf/2511.22050", "abs": "https://arxiv.org/abs/2511.22050", "authors": ["Yingjue Bian", "Tianye Wang", "Shiming Tang", "Tai Sing Lee"], "title": "Integrative characterization of the topography of V4 neural codes using deep learning approaches", "categories": ["q-bio.NC"], "comment": "21 pages,11 figures,4 tables.Preprint", "summary": "Area V4 is a mid-level stage of the macaque ventral visual stream, known to encode intermediate visual features such as color, curvature, corners, texture, three-dimensional (3D) solids, and local form. Classical neurophysiological studies have typically examined these dimensions in isolation, contrasting V4 selectivity for shape versus texture, 3D solid surfaces versus two-dimensional (2D) flat patterns, or object form versus texture. Yet how these tunings relate to one another within individual neurons, and how they are jointly organized across the cortical surface, remain unknown. For instance, does a neuron selective for 2D contour-defined shape prefer 3D solid surfaces or 2D flat surfaces? How are preferences for such heterogeneous attributes arranged in a common topographic map? To address these questions, we leverage V4 \"digital twins\" -- deep neural network models fitted to large-scale, wide-field calcium imaging data comprising tens of thousands of natural images. These digital twins allow us to systematically probe not only the stimulus dimensions explored in earlier studies, but also new, multidimensional stimulus sets that reveal additional aspects of the V4 code. In this study, we find that neural pixels preferring 2D contour-defined shapes also tend to prefer 3D surface shape defined by shading or texture gradients and by object form. In contrast, pixels preferring 2D texture tend to prefer flat surfaces defined by uniform texture or reflectance. We propose that this division of labor suggests that V4 may decompose the encoding of geometrical shape and surface appearance of visual stimuli into distinct populations of neurons, organized as interleaved clusters in the V4 topographic map."}
{"id": "2511.22005", "pdf": "https://arxiv.org/pdf/2511.22005", "abs": "https://arxiv.org/abs/2511.22005", "authors": ["Mathieu Fourment", "Jiansi Gao", "Marc A Suchard", "Frederick A Matsen"], "title": "Assessing the Validity of the Fixed Tree Topology Assumption in Phylodynamic Inference", "categories": ["q-bio.PE"], "comment": null, "summary": "Fixed tree topologies are widely used in phylodynamic analyses to reduce computational burden, yet the consequences of this assumption remain insufficiently understood. Here, we systematically assess the impact of various fixed-topology strategies on phylogenetic and phylodynamic parameter estimates across a diverse set of viral datasets. We compare fully Bayesian joint inference with fixed-topology strategies, including conditioning on maximum likelihood trees subsequently dated with LSD or TreeTime. Our analyses show that global parameters of the substitution and site models are largely robust to the fixed-topology assumption, whereas parameters that depend on the temporal structure of the tree, such as molecular clock rates, node ages, and demographic histories, can exhibit substantial biases. We do treat unconstrained Bayesian analyses as the reference, although we recognize that these too are model-based approximations. Nevertheless, our results highlight serious discordance associated with fixing the topology and underscore the need for faster, time-aware methods that simultaneously integrate topology and parameter estimation. These findings raise important questions about the balance between computational efficiency and inferential accuracy in phylodynamic studies."}
{"id": "2511.23344", "pdf": "https://arxiv.org/pdf/2511.23344", "abs": "https://arxiv.org/abs/2511.23344", "authors": ["Valentin Wössner", "Falko Ziebert", "Ulrich S. Schwarz"], "title": "A theory for coexistence and selection of branched actin networks in a shared and finite pool of monomers", "categories": ["q-bio.SC", "cond-mat.soft", "physics.bio-ph"], "comment": "Revtex, 19 pages, 8 figures", "summary": "Cellular actin structures are continuously turned over while keeping similar sizes. Since they all compete for a shared pool of actin monomers, the question arises how they can coexist in these dynamic steady states. Recently, the coexistence of branched actin networks with different densities growing in a shared and finite pool of purified proteins has been demonstrated in a biomimetic bead assay. However, theoretical work in the context of organelle size regulation has mainly been focused on linear architectures, such as single filaments and bundles, and thus is not able to explain this observation. Here we show theoretically that the local depletion of actin monomers caused by the growth of a branched network naturally gives rise to a negative feedback loop between network density and growth rate, and that this competition is captured by one central equation. A comprehensive bifurcation analysis shows that the theory leads to well-defined steady states even in the case of multiple networks sharing the same pool of monomers, without any need for specific molecular processes. Under increasing competition strength, coexistence is replaced by selection. We also show that our theory is in excellent agreement with spatiotemporal simulations implemented in a finite element framework. In summary, our work suggests that local monomer depletion is the decisive and universal factor controlling growth of branched actin networks."}
{"id": "2511.22096", "pdf": "https://arxiv.org/pdf/2511.22096", "abs": "https://arxiv.org/abs/2511.22096", "authors": ["Sandya Subramanian", "Bharath Ramsundar"], "title": "Density-based Neural Temporal Point Processes for Heartbeat Dynamics", "categories": ["q-bio.TO", "eess.SP", "stat.AP"], "comment": "9 pages, 4 figures, Presented as a Workshop Paper at TS4H@ICLR2024", "summary": "Temporal point processes (TPPs) provide a natural mathematical framework for modeling heartbeats due to capturing underlying physiological inductive biases. In this work, we apply density-based neural TPPs to model heartbeat dynamics from 18 subjects. We adapt a goodness-of-fit framework from classical point process literature to Neural TPPs and use it to optimize hyperparameters, identify appropriate training sequence lengths to capture temporal dependencies, and demonstrate zero-shot predictive capability on heartbeat data."}
{"id": "2511.22821", "pdf": "https://arxiv.org/pdf/2511.22821", "abs": "https://arxiv.org/abs/2511.22821", "authors": ["Hamid Ismail", "Marwan Bikdash"], "title": "deepFEPS: Deep Learning-Oriented Feature Extraction for Biological Sequences", "categories": ["q-bio.GN"], "comment": "16 pages, 6 figures, bioinformatics tool for genomics analysis", "summary": "Machine- and deep-learning approaches for biological sequences depend critically on transforming raw DNA, RNA, and protein FASTA files into informative numerical representations. However, this process is often fragmented across multiple libraries and preprocessing steps, which creates a barrier for researchers without extensive computational expertise. To address this gap, we developed deepFEPS, an open-source toolkit that unifies state-of-the-art feature extraction methods for sequence data within a single, reproducible workflow. deepFEPS integrates five families of modern feature extractors - k-mer embeddings (Word2Vec, FastText), document-level embeddings (Doc2Vec), transformer-based encoders (DNABERT, ProtBERT, and ESM2), autoencoder-derived latent features, and graph-based embeddings - into one consistent platform. The system accepts FASTA input via a web interface or command-line tool, exposes key model parameters, and outputs analysis-ready feature matrices (CSV). Each run is accompanied by an automatic quality-control report including sequence counts, dimensionality, sparsity, variance distributions, class balance, and diagnostic visualizations. By consolidating advanced sequence embeddings into one environment, deepFEPS reduces preprocessing overhead, improves reproducibility, and shortens the path from raw sequences to downstream machine- and deep-learning applications. deepFEPS lowers the practical barrier to modern representation learning for bioinformatics, enabling both novice and expert users to generate advanced embeddings for classification, clustering, and predictive modeling. Its unified framework supports exploratory analyses, high-throughput studies, and integration into institutional workflows, while remaining extensible to emerging models and methods. The webserver is accessible at https://hdismail.com/deepfeps2/."}
{"id": "2511.22145", "pdf": "https://arxiv.org/pdf/2511.22145", "abs": "https://arxiv.org/abs/2511.22145", "authors": ["Cesar Nieto", "Sayeh Rezaee", "Cesar Augusto Vargas-Garcia", "Abhyudai Singh"], "title": "Dynamical Inference of Cell Size Regulation Parameters", "categories": ["q-bio.QM"], "comment": null, "summary": "Cells achieve size homeostasis by regulating their division timing based on their size, added size, and cell cycle time. Previous research under steady-state conditions demonstrated the robustness of these mechanisms. However, their dynamic responses in fluctuating environments, such as nutrient depletion due to population growth, remain challenging to fully characterize. Currently, advances in single-cell microscopy have revealed various cellular division strategies whose underlying molecular mechanisms are complex and not always available. This study introduces a novel approach to model cell size dynamics using a piecewise deterministic Markov chain framework, where cell division events are modeled as stochastic jumps determined by a division propensity dependent on both current cell size and added size since birth. We propose a three-parameter characterization for the division process: scale (target added size at division), shape (division stochasticity), and division strategy (relevance of cell size, added size, or cell cycle duration). We derive analytical formulas for the probability of division, and with this probability, we develop a maximum likelihood estimation (MLE) framework. We implement a systematic investigation of the accuracy of inference as a function of sample size. The model's performance is studied across various scenarios, including those exhibiting dynamical changes in one or more parameters, suggesting its broad applicability for analyzing new experimental data on cell size regulation in dynamic environments."}
{"id": "2511.22252", "pdf": "https://arxiv.org/pdf/2511.22252", "abs": "https://arxiv.org/abs/2511.22252", "authors": ["Vincent Fromion", "Philippe Robert", "Jana Zaherddine"], "title": "Stochastic Models of Resource Allocation in Chemical Reaction Networks", "categories": ["math.PR", "q-bio.MN"], "comment": null, "summary": "This paper analyses of a stochastic model of a chemical reaction network with three types of chemical species ${\\cal R}$, ${\\cal M}$ and ${\\cal U}$ that interact to transform a flow of external resources, the chemical species ${\\cal Q}$, to produce a product, the chemical species ${\\cal P}_r$. A regulation mechanism involving the sequestration of the chemical species ${\\cal R}$ when the flow of resources is too low is investigated. The original motivation of the study is of analyzing the qualitative properties of a key regulation mechanism of gene expression in biological cells, the {\\em stringent response}.\n  A scaling analysis of a Markov process in $\\N^5$ representing the state of the chemical reaction network is achieved. It is shown that, depending on the parameters of the model, there are, quite surprisingly, three possible asymptotic regimes. To each of them corresponds a stochastic averaging principle with a fast process expressed in terms of a network of $M/M/\\infty$ queues. One of these regimes, the optimal sequestration regime, does not seem to have been identified up to now. Under this regime, the input flow of resources is low but the state of the network is still acceptable in terms of unused macro-molecules, showing the remarkable efficiency of this regulation mechanism. The technical proofs of the main convergence results rely on a combination of coupling arguments, technical estimates of the solutions of SDEs, of sample paths of fast processes in particular, and the stability properties of some dynamical systems in $\\R^2$."}
{"id": "2511.22848", "pdf": "https://arxiv.org/pdf/2511.22848", "abs": "https://arxiv.org/abs/2511.22848", "authors": ["Martina Del Gaudio", "Federico Ghimenti", "Surya Ganguli"], "title": "Short-term plasticity recalls forgotten memories through a trampoline mechanism", "categories": ["q-bio.NC", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": null, "summary": "We analyze continuous Hopfield associative memories augmented by additional, rapid short-term associative synaptic plasticity. Through the cavity method, we determine the boundary between the retrieval and forgetting, or spin-glass phase, of the network as a function of the fraction of stored memories and the neuronal gain. We find that short-term synaptic plasticity yields marginal improvements in critical memory capacity. However, through dynamical mean field theory, backed by extensive numerical simulations, we find that short-term synaptic plasticity has a dramatic impact on memory retrieval above the critical capacity. When short-term synaptic plasticity is turned on, the combined neuronal and synaptic dynamics descends a high-dimensional energy landscape over both neurons and synapses. The energy landscape over neurons alone is thus dynamic, and is lowered in the vicinity of recent neuronal patterns visited by the network, just like the surface of a trampoline is lowered in the vicinity of regions recently visited by a heavy ball. This trampoline-like reactivity of the neuronal energy landscape to short-term plasticity in synapses can lead to the recall of stored memories that would otherwise have been forgotten. This occurs because the dynamics without short-term plasticity transiently moves towards a stored memory before departing away from it. Thus short-term plasticity, operating during the transient, lowers the energy in the vicinity of the stored memory, eventually trapping the combined neuronal and synaptic dynamics at a fixed point close to the stored memory. In this manner, short-term plasticity enables the recall of memories that would otherwise be forgotten, by trapping transients that would otherwise escape. We furthermore find an optimal time constant for short-term synaptic plasticity, matched to the transient dynamics, to empower recall of forgotten memories."}
{"id": "2511.22736", "pdf": "https://arxiv.org/pdf/2511.22736", "abs": "https://arxiv.org/abs/2511.22736", "authors": ["Martin Frohn", "Niels Holtgrefe", "Leo van Iersel", "Mark Jones", "Steven Kelk"], "title": "Bounds on the sequence length sufficient to reconstruct level-1 phylogenetic networks", "categories": ["q-bio.PE", "math.CO"], "comment": null, "summary": "Phylogenetic trees and networks are graphs used to model evolutionary relationships, with trees representing strictly branching histories and networks allowing for events in which lineages merge, called reticulation events. While the question of data sufficiency has been studied extensively in the context of trees, it remains largely unexplored for networks. In this work we take a first step in this direction by establishing bounds on the amount of genomic data required to reconstruct binary level-$1$ semi-directed phylogenetic networks, which are binary networks in which reticulation events are indicated by directed edges, all other edges are undirected, and cycles are vertex-disjoint. For this class, methods have been developed recently that are statistically consistent. Roughly speaking, such methods are guaranteed to reconstruct the correct network assuming infinitely long genomic sequences. Here we consider the question whether networks from this class can be uniquely and correctly reconstructed from finite sequences. Specifically, we present an inference algorithm that takes as input genetic sequence data, and demonstrate that the sequence length sufficient to reconstruct the correct network with high probability, under the Cavender-Farris-Neyman model of evolution, scales logarithmically, polynomially, or polylogarithmically with the number of taxa, depending on the parameter regime. As part of our contribution, we also present novel inference rules for quartet data in the semi-directed phylogenetic network setting."}
{"id": "2511.22519", "pdf": "https://arxiv.org/pdf/2511.22519", "abs": "https://arxiv.org/abs/2511.22519", "authors": ["Wojciech Zarzecki", "Paulina Szymczak", "Ewa Szczurek", "Kamil Deja"], "title": "FoldSAE: Learning to Steer Protein Folding Through Sparse Representations", "categories": ["q-bio.QM"], "comment": "15 pages, 1o figures, submitted to RECOMB 2026", "summary": "RFdiffusion is a popular and well-established model for generation of protein structures. However, this generative process offers limited insight into its internal representations and how they contribute to the final protein structure. Concurrently, recent work in mechanistic interpretability has successfully used Sparse Autoencoders (SAEs) to discover interpretable features within neural networks. We combine these concepts by applying SAE to the internal representations of RFdiffusion to uncover secondary structure-specific features and establish a relationship between them and generated protein structures. Building on these insights, we introduce a novel steering mechanism that enables precise control of secondary structure formation through a tunable hyperparameter, while simultaneously revealing interpretable block and neuron-level representations within RFdiffusion. Our work pioneers a new framework for making RFdiffusion more interpretable, demonstrating how understanding internal features can be directly translated into precise control over the protein design process."}
{"id": "2511.21848", "pdf": "https://arxiv.org/pdf/2511.21848", "abs": "https://arxiv.org/abs/2511.21848", "authors": ["Eric Leonardis", "Akira Nagamori", "Ayesha Thanawalla", "Yuanjia Yang", "Joshua Park", "Hutton Saunders", "Eiman Azim", "Talmo Pereira"], "title": "Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics", "categories": ["cs.LG", "cs.RO", "q-bio.NC", "q-bio.QM"], "comment": "Accepted at NeurIPS 2025 Workshop Data on the Brain & Mind: Concrete Applications of AI to Neuroscience and Cognitive Science. 12 pages, 4 figures", "summary": "The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control."}
{"id": "2511.22841", "pdf": "https://arxiv.org/pdf/2511.22841", "abs": "https://arxiv.org/abs/2511.22841", "authors": ["Hong Zheng", "Shimin Su", "Caiqi Liu", "Jingzhi Lou", "Lirong Cao", "Yexian Zhang", "Zhihui Zhang", "Marc Ka Chun Chong", "Benny Chung-Ying Zee", "Peter Pak-Hang Cheung", "Haogao Gu", "Juan Pu", "Leo Lit Man Poon", "Hui-Ling Yen", "Maggie Haitian Wang"], "title": "A novel approach to profile global circulation pathway of SARS-CoV-2 variants by site-based mutation dynamics", "categories": ["q-bio.PE", "q-bio.QM"], "comment": null, "summary": "The genetic evolution of SARS-CoV-2 has caused recurring epidemic waves, understanding its global dispersal patterns is critical for effective surveillance. We developed the Site-based mutation dynamics - Equal Power Sampling (S-EPS) framework, a phylogenetic-free, bias-correcting framework for profiling viral source-sink dynamics. Applying S-EPS to 6.6 million SARS-CoV-2 genomes (March 2020 - June 2024) from 13 regions worldwide, we identified Africa and the Indian subcontinent as the predominant sources of key mutations. Southeast Asia serves as an early transmission hub, while Russia and South America mainly acted as sinks. Key mutations took longer to establish fitness in source regions than externally. Once an amino acid substitution on the receptor-binding domain reached 1% prevalence in major sources, there is an 80% probability it would spread elsewhere, with a 2-month median lead time (IQR: 1-4). Our findings underscore the importance of genetic surveillance, with S-EPS offering enhanced capability for monitoring emerging viral threats."}
{"id": "2511.21848", "pdf": "https://arxiv.org/pdf/2511.21848", "abs": "https://arxiv.org/abs/2511.21848", "authors": ["Eric Leonardis", "Akira Nagamori", "Ayesha Thanawalla", "Yuanjia Yang", "Joshua Park", "Hutton Saunders", "Eiman Azim", "Talmo Pereira"], "title": "Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics", "categories": ["cs.LG", "cs.RO", "q-bio.NC", "q-bio.QM"], "comment": "Accepted at NeurIPS 2025 Workshop Data on the Brain & Mind: Concrete Applications of AI to Neuroscience and Cognitive Science. 12 pages, 4 figures", "summary": "The brain has evolved to effectively control the body, and in order to understand the relationship we need to model the sensorimotor transformations underlying embodied control. As part of a coordinated effort, we are developing a general-purpose platform for behavior-driven simulation modeling high fidelity behavioral dynamics, biomechanics, and neural circuit architectures underlying embodied control. We present a pipeline for taking kinematics data from the neuroscience lab and creating a pipeline for recapitulating those natural movements in a biomechanical model. We implement a imitation learning framework to perform a dexterous forelimb reaching task with a musculoskeletal model in a simulated physics environment. The mouse arm model is currently training at faster than 1 million training steps per second due to GPU acceleration with JAX and Mujoco-MJX. We present results that indicate that adding naturalistic constraints on energy and velocity lead to simulated musculoskeletal activity that better predict real EMG signals. This work provides evidence to suggest that energy and control constraints are critical to modeling musculoskeletal motor control."}
{"id": "2511.21940", "pdf": "https://arxiv.org/pdf/2511.21940", "abs": "https://arxiv.org/abs/2511.21940", "authors": ["Kiran Nair", "Hubert Cecotti"], "title": "Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection", "categories": ["cs.LG", "eess.SP", "q-bio.NC"], "comment": "20 Pages, prepared for a Journal", "summary": "Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems."}
{"id": "2511.23209", "pdf": "https://arxiv.org/pdf/2511.23209", "abs": "https://arxiv.org/abs/2511.23209", "authors": ["Chao Wang", "Minlan Li", "Chang Liu"], "title": "Stochastic fluctuations in an eco-evolutionary game dynamics with environmental feedbacks", "categories": ["q-bio.PE"], "comment": null, "summary": "Building upon the eco-evolutionary game dynamics framework established by Tilman et al., we investigate stochastic fluctuations in a two-strategy system incorporating environmental feedback mechanisms, where the payoff matrix exhibits population size dependence. We adopt a systematic approach which is the so-called $Ω$-expansion. When the stochastic factor is integrated, it is shown that the population size for each strategy fluctuates around the interior equilibrium of the macroscopic equations (corresponding to the deterministic model of the eco-evolutionary game) and its variance converges to a constant that is proportional to the environmental carrying capacity if the interior equilibrium is asymptotically stable. The simulation results demonstrate that the $Ω$ expansion provides a valid approximation, and the reliability of the aforementioned conclusions is verified. Therefore, analogous to Fudenberg and Harris' s stochastic replicator dynamics for infinite populations under external noise (\\emph{J. Econ. Theory 57, 420-441}), the dynamic stability of the eco-evolutionary game can be extended to the stochastic regime when the environmental carrying capacity is sufficiently large."}
{"id": "2511.21919", "pdf": "https://arxiv.org/pdf/2511.21919", "abs": "https://arxiv.org/abs/2511.21919", "authors": ["Francisco Sena", "Aleksandr Politov", "Corentin Moumard", "Manuel Cáceres", "Sebastian Schmidt", "Juha Harviainen", "Alexandru I. Tomescu"], "title": "Identifying all snarls and superbubbles in linear-time, via a unified SPQR-tree framework", "categories": ["cs.DS", "cs.DM", "q-bio.QM"], "comment": null, "summary": "Snarls and superbubbles are fundamental pangenome decompositions capturing variant sites. These bubble-like structures underpin key tasks in computational pangenomics, including structural-variant genotyping, distance indexing, haplotype sampling, and variant annotation. Snarls can be quadratically-many in the size of the graph, and since their introduction in 2018 with the vg toolkit, there has been no work on identifying all snarls in linear time. Moreover, while it is known how to find superbubbles in linear time, this result is a highly specialized solution only achieved after a long series of papers.\n  We present the first algorithm identifying all snarls in linear time. This is based on a new representation of all snarls, of size linear in the input graph size, and which can be computed in linear time. Our algorithm is based on a unified framework that also provides a new linear-time algorithm for finding superbubbles. An observation behind our results is that all such structures are separated from the rest of the graph by two vertices (except for cases which are trivially computable), i.e. their endpoints are a 2-separator of the underlying undirected graph. Based on this, we employ the well-known SPQR tree decomposition, which encodes all 2-separators, to guide a traversal that finds the bubble-like structures efficiently.\n  We implemented our algorithms in C++ (available at https://github.com/algbio/BubbleFinder) and evaluated them on various pangenomic datasets. Our algorithms outcompete or they are on the same level of existing methods. For snarls, we are up to two times faster than vg, while identifying all snarls. When computing superbubbles, we are up to 50 times faster than BubbleGun. Our SPQR tree framework provides a unifying perspective on bubble-like structures in pangenomics, together with a template for finding other bubble-like structures efficiently."}
{"id": "2511.22828", "pdf": "https://arxiv.org/pdf/2511.22828", "abs": "https://arxiv.org/abs/2511.22828", "authors": ["Arman Behrad", "Mitchell Ostrow", "Mohammad Taha Fakharian", "Ila Fiete", "Christian Beste", "Shervin Safavi"], "title": "Fast dynamical similarity analysis", "categories": ["cs.AI", "q-bio.NC"], "comment": null, "summary": "To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis."}
{"id": "2511.22841", "pdf": "https://arxiv.org/pdf/2511.22841", "abs": "https://arxiv.org/abs/2511.22841", "authors": ["Hong Zheng", "Shimin Su", "Caiqi Liu", "Jingzhi Lou", "Lirong Cao", "Yexian Zhang", "Zhihui Zhang", "Marc Ka Chun Chong", "Benny Chung-Ying Zee", "Peter Pak-Hang Cheung", "Haogao Gu", "Juan Pu", "Leo Lit Man Poon", "Hui-Ling Yen", "Maggie Haitian Wang"], "title": "A novel approach to profile global circulation pathway of SARS-CoV-2 variants by site-based mutation dynamics", "categories": ["q-bio.PE", "q-bio.QM"], "comment": null, "summary": "The genetic evolution of SARS-CoV-2 has caused recurring epidemic waves, understanding its global dispersal patterns is critical for effective surveillance. We developed the Site-based mutation dynamics - Equal Power Sampling (S-EPS) framework, a phylogenetic-free, bias-correcting framework for profiling viral source-sink dynamics. Applying S-EPS to 6.6 million SARS-CoV-2 genomes (March 2020 - June 2024) from 13 regions worldwide, we identified Africa and the Indian subcontinent as the predominant sources of key mutations. Southeast Asia serves as an early transmission hub, while Russia and South America mainly acted as sinks. Key mutations took longer to establish fitness in source regions than externally. Once an amino acid substitution on the receptor-binding domain reached 1% prevalence in major sources, there is an 80% probability it would spread elsewhere, with a 2-month median lead time (IQR: 1-4). Our findings underscore the importance of genetic surveillance, with S-EPS offering enhanced capability for monitoring emerging viral threats."}
{"id": "2511.22870", "pdf": "https://arxiv.org/pdf/2511.22870", "abs": "https://arxiv.org/abs/2511.22870", "authors": ["Jungwoo Seo", "David Keetae Park", "Shinjae Yoo", "Jiook Cha"], "title": "Scalable Diffusion Transformer for Conditional 4D fMRI Synthesis", "categories": ["cs.CV", "q-bio.NC"], "comment": "Accepted at NeurIPS 2025 Workshop: Foundation Models for the Brain and Body. 13 pages, 6 figures, 4 tables", "summary": "Generating whole-brain 4D fMRI sequences conditioned on cognitive tasks remains challenging due to the high-dimensional, heterogeneous BOLD dynamics across subjects/acquisitions and the lack of neuroscience-grounded validation. We introduce the first diffusion transformer for voxelwise 4D fMRI conditional generation, combining 3D VQ-GAN latent compression with a CNN-Transformer backbone and strong task conditioning via AdaLN-Zero and cross-attention. On HCP task fMRI, our model reproduces task-evoked activation maps, preserves the inter-task representational structure observed in real data (RSA), achieves perfect condition specificity, and aligns ROI time-courses with canonical hemodynamic responses. Performance improves predictably with scale, reaching task-evoked map correlation of 0.83 and RSA of 0.98, consistently surpassing a U-Net baseline on all metrics. By coupling latent diffusion with a scalable backbone and strong conditioning, this work establishes a practical path to conditional 4D fMRI synthesis, paving the way for future applications such as virtual experiments, cross-site harmonization, and principled augmentation for downstream neuroimaging models."}
{"id": "2511.23114", "pdf": "https://arxiv.org/pdf/2511.23114", "abs": "https://arxiv.org/abs/2511.23114", "authors": ["Ankit Gupta", "Mustafa Khammash"], "title": "A Spectral Koopman Approximation Framework for Stochastic Reaction Networks", "categories": ["q-bio.MN", "math.PR", "q-bio.QM"], "comment": "7 figures", "summary": "Stochastic reaction networks (SRNs) are a general class of continuous-time Markov jump processes used to model a wide range of systems, including biochemical dynamics in single cells, ecological and epidemiological populations, and queueing or communication networks. Yet analyzing their dynamics remains challenging because these processes are high-dimensional and their transient behavior can vary substantially across different initial molecular or population states. Here we introduce a spectral framework for the stochastic Koopman operator that provides a tractable, low-dimensional representation of SRN dynamics over continuous time, together with computable error estimates. By exploiting the compactness of the Koopman operator, we recover dominant spectral modes directly from simulated or experimental data, enabling efficient prediction of moments, event probabilities, and other summary statistics across all initial states. We further derive continuous-time parameter sensitivities and cross-spectral densities, offering new tools for probing noise structure and frequency-domain behavior. We demonstrate the approach on biologically relevant systems, including synthetic intracellular feedback controllers, stochastic oscillators, and inference of initial-state distributions from high-temporal-resolution flow cytometry. Together, these results establish spectral Koopman analysis as a powerful and general framework for studying stochastic dynamical systems across the biological, ecological, and computational sciences."}
