{"id": "2601.09758", "pdf": "https://arxiv.org/pdf/2601.09758", "abs": "https://arxiv.org/abs/2601.09758", "authors": ["Austin Talbot", "Yue Ke"], "title": "Detecting Batch Heterogeneity via Likelihood Clustering", "categories": ["q-bio.GN", "cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "Batch effects represent a major confounder in genomic diagnostics. In copy number variant (CNV) detection from NGS, many algorithms compare read depth between test samples and a reference sample, assuming they are process-matched. When this assumption is violated, with causes ranging from reagent lot changes to multi-site processing, the reference becomes inappropriate, introducing false CNV calls or masking true pathogenic variants. Detecting such heterogeneity before downstream analysis is critical for reliable clinical interpretation. Existing batch effect detection methods either cluster samples based on raw features, risking conflation of biological signal with technical variation, or require known batch labels that are frequently unavailable. We introduce a method that addresses both limitations by clustering samples according to their Bayesian model evidence. The central insight is that evidence quantifies compatibility between data and model assumptions, technical artifacts violate assumptions and reduce evidence, whereas biological variation, including CNV status, is anticipated by the model and yields high evidence. This asymmetry provides a discriminative signal that separates batch effects from biology. We formalize heterogeneity detection as a likelihood ratio test for mixture structure in evidence space, using parametric bootstrap calibration to ensure conservative false positive rates. We validate our approach on synthetic data demonstrating proper Type I error control, three clinical targeted sequencing panels (liquid biopsy, BRCA, and thalassemia) exhibiting distinct batch effect mechanisms, and mouse electrophysiology recordings demonstrating cross-modality generalization. Our method achieves superior clustering accuracy compared to standard correlation-based and dimensionality-reduction approaches while maintaining the conservativeness required for clinical usage."}
{"id": "2601.10464", "pdf": "https://arxiv.org/pdf/2601.10464", "abs": "https://arxiv.org/abs/2601.10464", "authors": ["Mikkel Meyer Andersen", "Nicole Huber", "Kimberly S Andreaggi", "Tóra Oluffa Stenberg Olsen", "Walther Parson", "Charla Marshall"], "title": "MitoFREQ: A Novel Approach for Mitogenome Frequency Estimation from Top-level Haplogroups and Single Nucleotide Variants", "categories": ["stat.AP", "q-bio.GN"], "comment": null, "summary": "Lineage marker population frequencies can serve as one way to express evidential value in forensic genetics. However, for high-quality whole mitochondrial DNA genome sequences (mitogenomes), population data remain limited. In this paper, we offer a new method, MitoFREQ, for estimating the population frequencies of mitogenomes. MitoFREQ uses the mitogenome resources HelixMTdb and gnomAD, harbouring information from 195,983 and 56,406 mitogenomes, respectively. Neither HelixMTdb nor gnomAD can be queried directly for individual mitogenome frequencies, but offers single nucleotide variant (SNV) allele frequencies for each of 30 \"top-level\" haplogroups (TLHG). We propose using the HelixMTdb and gnomAD resources by classifying a given mitogenome within the TLHG scheme and subsequently using the frequency of its rarest SNV within that TLHG weighted by the TLHG frequency. We show that this method is guaranteed to provide a higher population frequency estimate than if a refined haplogroup and its SNV frequencies were used. Further, we show that top-level haplogrouping can be achieved by using only 227 specific positions for 99.9% of the tested mitogenomes, potentially making the method available for low-quality samples. The method was tested on two types of datasets: high-quality forensic reference datasets and a diverse collection of scrutinised mitogenomes from GenBank. This dual evaluation demonstrated that the approach is robust across both curated forensic data and broader population-level sequences. This method produced likelihood ratios in the range of 100-100,000, demonstrating its potential to strengthen the statistical evaluation of forensic mtDNA evidence. We have developed an open-source R package `mitofreq` that implements our method, including a Shiny app where custom TLHG frequencies can be supplied."}
{"id": "2601.10202", "pdf": "https://arxiv.org/pdf/2601.10202", "abs": "https://arxiv.org/abs/2601.10202", "authors": ["Hongtao Li", "Jia Wei", "Jia Xiao", "Yuanjun Lai", "Mingyang Liu", "Shuzhen Lv", "Xueqiang Ouyang"], "title": "Robust and Generalizable Atrial Fibrillation Detection from ECG Using Time-Frequency Fusion and Supervised Contrastive Learning", "categories": ["q-bio.QM"], "comment": null, "summary": "Atrial fibrillation (AF) is a common cardiac arrhythmia that significantly increases the risk of stroke and heart failure, necessitating reliable and generalizable detection methods from electrocardiogram (ECG) recordings. Although deep learning has advanced automated AF diagnosis, existing approaches often struggle to exploit complementary time-frequency information effectively, limiting both robustness under intra-dataset and generalization across diverse clinical datasets. To address these challenges, we propose a cross-modal deep learning framework comprising two key components: a Bidirectional Gating Module (BGM) and a Cross-modal Supervised Contrastive Learning (CSCL) strategy. The BGM facilitates dynamic, reciprocal refinement between time and frequency domain features, enhancing model robustness to signal variations within a dataset. Meanwhile, CSCL explicitly structures the joint embedding space by pulling together label-consistent samples and pushing apart different ones, thereby improving inter-class separability and enabling strong cross-dataset generalization. We evaluate our method through five-fold cross-validation on the AFDB and the CPSC2021 dataset, as well as bidirectional cross-dataset experiments (training on one and testing on the other). Results show consistent improvements over state-of-the-art methods across multiple metrics, demonstrating that our approach achieves both high intra-dataset robustness and excellent cross-dataset generalization. We further demonstrate that our method achieves high computational efficiency and anti-interference capability, making it suitable for edge deployment."}
{"id": "2601.10405", "pdf": "https://arxiv.org/pdf/2601.10405", "abs": "https://arxiv.org/abs/2601.10405", "authors": ["Joseph Malinzi", "Amina Eladdadi", "Rachid Ouifki", "Raluca Eftimie", "Anotida Madzvamuse", "Helen M. Byrne"], "title": "A Predictive Model for Synergistic Oncolytic Virotherapy: Unveiling the Ping-Pong Mechanism and Optimal Timing of Combined Vesicular Stomatitis and Vaccinia Viruses", "categories": ["q-bio.QM", "math.DS"], "comment": null, "summary": "We present a mathematical model that describes the synergistic mechanism of combined Vesicular Stomatitis Virus (VSV) and Vaccinia Virus (VV). The model captures the dynamic interplay between tumor cells, viral replication, and the interferon-mediated immune response, revealing a `ping-pong' synergy where VV-infected cells produce B18R protein that neutralizes interferon-$α$, thereby enhancing VSV replication within the tumor. Numerical simulations demonstrate that this combination achieves complete tumor clearance in approximately 50 days, representing an 11\\% acceleration compared to VV monotherapy (56 days), while VSV alone fails to eradicate tumors. Through bifurcation analysis, we identify critical thresholds for viral burst size and B18R inhibition, while sensitivity analysis highlights infection rates and burst sizes as the most influential parameters for treatment efficacy. Temporal optimization reveals that therapeutic outcomes are maximized through immediate VSV administration followed by delayed VV injection within a 1-19 day window, offering a strategic approach to overcome the timing and dosing challenges inherent in OVT."}
{"id": "2601.09737", "pdf": "https://arxiv.org/pdf/2601.09737", "abs": "https://arxiv.org/abs/2601.09737", "authors": ["Fernando Alcalde Cuesta", "Gustavo Guerberoff", "Álvaro Lozano Rojo"], "title": "Absorption and fixation times for evolutionary processes on graphs", "categories": ["q-bio.PE", "math-ph", "math.PR"], "comment": "29 pages", "summary": "In this paper, we study the absorption and fixation times for evolutionary processes on graphs, under different updating rules. While in Moran process a single neighbour is randomly chosen to be replaced, in proliferation processes other neighbours can be replaced using Bernoulli or binomial draws depending on $0 < p \\leq 1$. There is a critical value $p_c$ such that the proliferation is advantageous or disadvantageous in terms of fixation probability depending on whether $p > p_c$ or $p < p_c$.\n  We clarify the role of symmetries for computing the fixation time in Moran process. We show that the Maruyama-Kimura symmetry depend on the graph structure induced in each state, implying asymmetry for all graphs except cliques and cycles. There is a fitness value, not necessarily $1$, beyond which the fixation time decreases monotonically.\n  We apply Harris' graphical method to prove that the fixation time decreases monotonically depending on $p$. Thus there exists another value $p_t$ for which the proliferation is advantageous or disadvantageous in terms of time. However, at the critical level $p=p_c$, the proliferation is highly advantageous when $r \\to +\\infty$."}
{"id": "2601.10070", "pdf": "https://arxiv.org/pdf/2601.10070", "abs": "https://arxiv.org/abs/2601.10070", "authors": ["Mohammad Abbadi"], "title": "Comparative Evaluation of Deep Learning-Based and WHO-Informed Approaches for Sperm Morphology Assessment", "categories": ["cs.LG", "cs.CV", "eess.IV", "q-bio.QM"], "comment": "Under review at Computers in Biology and Medicine", "summary": "Assessment of sperm morphological quality remains a critical yet subjective component of male fertility evaluation, often limited by inter-observer variability and resource constraints. This study presents a comparative biomedical artificial intelligence framework evaluating an image-based deep learning model (HuSHeM) alongside a clinically grounded baseline derived from World Health Organization criteria augmented with the Systemic Inflammation Response Index (WHO(+SIRI)).\n  The HuSHeM model was trained on high-resolution sperm morphology images and evaluated using an independent clinical cohort. Model performance was assessed using discrimination, calibration, and clinical utility analyses. The HuSHeM model demonstrated higher discriminative performance, as reflected by an increased area under the receiver operating characteristic curve with relatively narrow confidence intervals compared to WHO(+SIRI). Precision-recall analysis further indicated improved performance under class imbalance, with higher precision-recall area values across evaluated thresholds. Calibration analysis indicated closer agreement between predicted probabilities and observed outcomes for HuSHeM, while decision curve analysis suggested greater net clinical benefit across clinically relevant threshold probabilities.\n  These findings suggest that image-based deep learning may offer improved predictive reliability and clinical utility compared with traditional rule-based and inflammation-augmented criteria. The proposed framework supports objective and reproducible assessment of sperm morphology and may serve as a decision-support tool within fertility screening and referral workflows. The proposed models are intended as decision-support or referral tools and are not designed to replace clinical judgment or laboratory assessment."}
{"id": "2601.09738", "pdf": "https://arxiv.org/pdf/2601.09738", "abs": "https://arxiv.org/abs/2601.09738", "authors": ["Haley Stone", "Jing Du", "Yang Yang", "Ashna Desai", "Rebecca Dawson", "Hao Xue", "David Heslop", "Matthew Scotch", "Andreas Züfle", "C. Raina MacIntyre", "Flora Salim"], "title": "From Ecological Connectivity to Outbreak Risk: A Heterogeneous Graph Network for Epidemiological Reasoning under Sparse Spatiotemporal Data", "categories": ["q-bio.PE", "cs.SI"], "comment": "17 pages, 4 figures", "summary": "Estimating population-level prevalence and transmission dynamics of wildlife pathogens can be challenging, partly because surveillance data is sparse, detection-driven, and unevenly sequenced. Using highly pathogenic avian influenza A/H5 clade 2.3.4.4b as a case study, we develop zooNet, a graph-based epidemiological framework that integrates mechanistic transmission simulation, metadata-driven genetic distance imputation, and spatiotemporal graph learning to reconstruct outbreak dynamics from incomplete observations. Applied to wild bird surveillance data from the United States during 2022, zooNet recovered coherent spatiotemporal structure despite intermittent detections, revealing sustained regional circulation across multiple migratory flyways. The framework consistently identified counties with ongoing transmission weeks to months before confirmed detections, including persistent activity in northeastern regions prior to documented re-emergence. These signals were detectable even in areas with sparse sequencing and irregular reporting. These results show that explicitly representing ecological processes and inferred genomic connectivity within a unified graph structure allows persistence and spatial risk structure to be inferred from detection-driven wildlife surveillance data."}
{"id": "2601.10250", "pdf": "https://arxiv.org/pdf/2601.10250", "abs": "https://arxiv.org/abs/2601.10250", "authors": ["Raffaella Fiamma Cabini", "Deborah Barkauskas", "Guangyu Chen", "Zhi-Qi Cheng", "David E Cicchetti", "Judith Drazba", "Rodrigo Fernandez-Gonzalez", "Raymond Hawkins", "Yujia Hu", "Jyoti Kini", "Charles LeWarne", "Xufeng Lin", "Sai Preethi Nakkina", "John W Peterson", "Koert Schreurs", "Ayushi Singh", "Kumaran Bala Kandan Viswanathan", "Inge MN Wortel", "Sanjian Zhang", "Rolf Krause", "Santiago Fernandez Gonzalez", "Diego Ulisse Pizzagalli"], "title": "Cell Behavior Video Classification Challenge, a benchmark for computer vision methods in time-lapse microscopy", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": null, "summary": "The classification of microscopy videos capturing complex cellular behaviors is crucial for understanding and quantifying the dynamics of biological processes over time. However, it remains a frontier in computer vision, requiring approaches that effectively model the shape and motion of objects without rigid boundaries, extract hierarchical spatiotemporal features from entire image sequences rather than static frames, and account for multiple objects within the field of view.\n  To this end, we organized the Cell Behavior Video Classification Challenge (CBVCC), benchmarking 35 methods based on three approaches: classification of tracking-derived features, end-to-end deep learning architectures to directly learn spatiotemporal features from the entire video sequence without explicit cell tracking, or ensembling tracking-derived with image-derived features.\n  We discuss the results achieved by the participants and compare the potential and limitations of each approach, serving as a basis to foster the development of computer vision methods for studying cellular dynamics."}
{"id": "2601.09747", "pdf": "https://arxiv.org/pdf/2601.09747", "abs": "https://arxiv.org/abs/2601.09747", "authors": ["Marcílio Ferreira dos Santos", "Cleiton de Lima Ricardo"], "title": "Topological Percolation in Urban Dengue Transmission: A Multi-Scale Analysis of Spatial Connectivity", "categories": ["q-bio.PE", "math.GT", "stat.AP"], "comment": "12 pages, 4 figures", "summary": "We investigate the spatial organization of dengue cases in the city of Recife, Brazil, from 2015 to 2024, using tools from statistical physics and topological data analysis. Reported cases are modeled as point clouds in a metric space, and their spatial connectivity is studied through Vietoris-Rips filtrations and zero-dimensional persistent homology, which captures the emergence and collapse of connected components across spatial scales. By parametrizing the filtration using percentiles of the empirical distance distribution, we identify critical percolation thresholds associated with abrupt growth of the largest connected component. These thresholds define distinct geometric regimes, ranging from fragmented spatial patterns to highly concentrated, percolated structures. Remarkably, years with similar incidence levels exhibit qualitatively different percolation behavior, demonstrating that case counts alone do not determine the spatial organization of transmission. Our analysis further reveals pronounced temporal heterogeneity in the percolation properties of dengue spread, including a structural rupture in 2020 characterized by delayed or absent spatial percolation. These findings highlight percolation-based topological observables as physically interpretable and sensitive descriptors of urban epidemic structure, offering a complementary perspective to traditional spatial and epidemiological analyses."}
{"id": "2601.09813", "pdf": "https://arxiv.org/pdf/2601.09813", "abs": "https://arxiv.org/abs/2601.09813", "authors": ["James W. G. Doran", "Dennis Mujuni", "Kit Gallagher", "Christian A. Yates", "Ruth Bowness"], "title": "An agent-based modelling approach to investigate the impact of gender on tuberculosis transmission in Uganda", "categories": ["q-bio.PE"], "comment": null, "summary": "Tuberculosis (TB) is an airborne disease caused by the pathogen Mycobacterium tuberculosis. In 2023, it returned to being the leading cause of death from an infectious agent globally, replacing COVID-19; in the nineteenth century, one in seven of all humans died of tuberculosis. More than 10 million people are diagnosed with TB every year. The majority of cases in adults occur in males (62.5% of all global adult cases in 2023, compared to 37.5% in females). The main reasons for males suffering from a higher burden of global TB cases, compared to females, may be in large part due to population-scale factors, such as employment type, the quantity and type of social contacts they make, and their health-seeking behaviours (e.g. differences in diagnostic and treatment delays between genders). To investigate which population-scale factors are most important in determining this higher TB burden in males, we have developed an age- and gender-stratified, spatially heterogeneous epidemiological agent-based model. We have focused specifically on Kampala, the capital of Uganda, which is a high-burden TB country. We considered counterfactual scenarios to elucidate the impact of gender on the epidemiology of TB. Setting disease progression parameters equal between the genders leads to a reduction in both male-to-female case ratio and total case numbers."}
{"id": "2601.09816", "pdf": "https://arxiv.org/pdf/2601.09816", "abs": "https://arxiv.org/abs/2601.09816", "authors": ["Dan Braha", "Marcus A. M. de Aguiar"], "title": "The multi-allelic Moran process as a multi-zealot voter model: exact results and consequences for diversity thresholds", "categories": ["q-bio.PE", "nlin.AO"], "comment": "37 pages, 7 figures", "summary": "The Moran process is a foundational model of genetic drift and mutation in finite populations. In its standard two-allele form with population size $n$, allele counts, and hence allele frequencies, change through stochastic replacement and mutation, yet converge to a stationary distribution. This distribution undergoes a qualitative transition at the \\emph{critical mutation rate} $μ_c=1/(2n)$: at $μ=μ_c$ it is exactly uniform, so that the probability of observing $k$ copies of allele~1 (and $n-k$ of allele~2) is $π(k)=1/(n+1)$ for $k=0,\\dots,n$. For $μ<μ_c$ diversity is low: the stationary distribution places most of its mass near $k=0$ and $k=n$, and the population is therefore typically dominated by one allele. For $μ>μ_c$, on the other hand, diversity is high: the distribution concentrates around intermediate values, so that both alleles are commonly present at comparable frequencies. Recently, the two-allele Moran process was shown to be exactly equivalent to the voter model with two candidates and $α_1$ and $α_2$ committed voters (\\emph{zealots}) in a population of $n+α_1+α_2$, where mutation is played by zealot influence. Here we extend this equivalence to multiple alleles and multiple candidates. Using the mapping, we derive the exact stationary distribution of allele counts for well-mixed populations with an arbitrary number $m$ of alleles, and obtain the critical mutation rate $μ_c = 1/(m+2n-2)$, which depends explicitly on $m$. We then analyze the Moran process on randomly connected populations and show that both the stationary distribution and $μ_c$ are invariant to network structure and coincide with the well-mixed results. Finally, simulations on general network topologies show that structural heterogeneity can substantially reshape the stationary allele distribution and, consequently, the level of genetic diversity."}
{"id": "2601.10364", "pdf": "https://arxiv.org/pdf/2601.10364", "abs": "https://arxiv.org/abs/2601.10364", "authors": ["Bjarki Eldon"], "title": "Gene genealogies in diploid populations evolving according to sweepstakes reproduction", "categories": ["q-bio.PE", "math.PR"], "comment": "41 pages, 9 figures", "summary": "Recruitment dynamics, or the distribution of the number of offspring among individuals, is central for understanding ecology and evolution. Sweepstakes reproduction (heavy right-tailed offspring number distribution) is central for understanding the ecology and evolution of highly fecund natural populations. Sweepstakes reproduction can induce jumps in type frequencies and multiple mergers in gene genealogies of sampled gene copies. We take sweepstakes reproduction to be skewed offspring number distribution due to mechanisms not involving natural selection, such as in chance matching of broadcast spawning with favourable environmental conditions. Here, we consider population genetic models of sweepstakes reproduction in a diploid panmictic populations absent selfing and evolving in a random environment. Our main results are {\\it (i)} continuous-time Beta and Poisson-Dirichlet coalescents, when combining the results the skewness parameter $α$ of the Beta-coalescent ranges from $0$ to $2$, and the Beta-coalescents may be incomplete due to an upper bound on the number of potential offspring produced by any pair of parents; {\\it (ii)} in large populations time is measured in units proportional to either $N/\\log N$ or $N$ generations (where $2N$ is the population size when constant); {\\it (iii)} it follows that incorporating population size changes leads to time-changed coalescents with the time-change independent of $α$; {\\it (iv)} using simulations we show that the ancestral process is not well approximated by the corresponding coalescent (as measured through certain functionals of the processes); {\\it (v)} whenever the skewness of the offspring number distribution is increased the conditional (conditioned on the population ancestry) and the unconditional ancestral processes are not in good agreement."}
