{"id": "2511.02128", "pdf": "https://arxiv.org/pdf/2511.02128", "abs": "https://arxiv.org/abs/2511.02128", "authors": ["Michael Chungyoun", "Gabe Au", "Britnie Carpentier", "Sreevarsha Puvada", "Courtney Thomas", "Jeffrey J. Gray"], "title": "DL4Proteins Jupyter Notebooks Teach how to use Artificial Intelligence for Biomolecular Structure Prediction and Design", "categories": ["q-bio.BM"], "comment": "27 pages, 5 figures", "summary": "Computational methods for predicting and designing biomolecular structures\nare increasingly powerful. While previous approaches relied on physics-based\nmodeling, modern tools, such as AlphaFold2 in CASP14, leverage artificial\nintelligence (AI) to achieve significantly improved performance. The growing\nimpact of AI-based tools in protein science necessitates enhanced educational\nmaterials that improve AI literacy among both established scientists seeking to\ndeepen their expertise and new researchers entering the field. To address this\nneed, we developed DL4Proteins, a series of ten interactive notebook modules\nthat introduce fundamental machine learning (ML) concepts, guide users through\ntraining ML models for protein-related tasks, and ultimately present\ncutting-edge protein structure prediction and design pipelines. With nothing\nmore than a web browser, learners can now access state-of-the-art computational\ntools employed by professional protein engineers - ranging from all-atom\nprotein design to fine-tuning protein language models for biophysically\nrelevant functional tasks. By increasing accessibility, this notebook series\nbroadens participation in AI-driven protein research. The complete notebook\nseries is publicly available at\nhttps://github.com/Graylab/DL4Proteins-notebooks."}
{"id": "2511.02622", "pdf": "https://arxiv.org/pdf/2511.02622", "abs": "https://arxiv.org/abs/2511.02622", "authors": ["Giuseppe Sacco", "Giovanni Bussi", "Guido Sanguinetti"], "title": "Machine Learning for RNA Secondary Structure Prediction: a review of current methods and challenges", "categories": ["q-bio.BM", "physics.bio-ph", "physics.comp-ph"], "comment": null, "summary": "Predicting the secondary structure of RNA is a core challenge in\ncomputational biology, essential for understanding molecular function and\ndesigning novel therapeutics. The field has evolved from foundational but\naccuracy-limited thermodynamic approaches to a new data-driven paradigm\ndominated by machine learning and deep learning. These models learn folding\npatterns directly from data, leading to significant performance gains. This\nreview surveys the modern landscape of these methods, covering single-sequence,\nevolutionary-based, and hybrid models that blend machine learning with\nbiophysics. A central theme is the field's \"generalization crisis,\" where\npowerful models were found to fail on new RNA families, prompting a\ncommunity-wide shift to stricter, homology-aware benchmarking. In response to\nthe underlying challenge of data scarcity, RNA foundation models have emerged,\nlearning from massive, unlabeled sequence corpora to improve generalization.\nFinally, we look ahead to the next set of major hurdles-including the accurate\nprediction of complex motifs like pseudoknots, scaling to kilobase-length\ntranscripts, incorporating the chemical diversity of modified nucleotides, and\nshifting the prediction target from static structures to the dynamic ensembles\nthat better capture biological function. We also highlight the need for a\nstandardized, prospective benchmarking system to ensure unbiased validation and\naccelerate progress."}
{"id": "2511.02769", "pdf": "https://arxiv.org/pdf/2511.02769", "abs": "https://arxiv.org/abs/2511.02769", "authors": ["Bum Chul Kwon", "Ben Shapira", "Moshiko Raboh", "Shreyans Sethi", "Shruti Murarka", "Joseph A Morrone", "Jianying Hu", "Parthasarathy Suryanarayanan"], "title": "STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "16 pages, 3 figures, 2 tables", "summary": "The chemical space of drug-like molecules is vast, motivating the development\nof generative models that must learn broad chemical distributions, enable\nconditional generation by capturing structure-property representations, and\nprovide fast molecular generation. Meeting the objectives depends on modeling\nchoices, including the probabilistic modeling approach, the conditional\ngenerative formulation, the architecture, and the molecular input\nrepresentation. To address the challenges, we present STAR-VAE\n(Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder),\na scalable latent-variable framework with a Transformer encoder and an\nautoregressive Transformer decoder. It is trained on 79 million drug-like\nmolecules from PubChem, using SELFIES to guarantee syntactic validity. The\nlatent-variable formulation enables conditional generation: a property\npredictor supplies a conditioning signal that is applied consistently to the\nlatent prior, the inference network, and the decoder. Our contributions are:\n(i) a Transformer-based latent-variable encoder-decoder model trained on\nSELFIES representations; (ii) a principled conditional latent-variable\nformulation for property-guided generation; and (iii) efficient finetuning with\nlow-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation\nwith limited property and activity data. On the GuacaMol and MOSES benchmarks,\nour approach matches or exceeds baselines, and latent-space analyses reveal\nsmooth, semantically structured representations that support both unconditional\nexploration and property-aware generation. On the Tartarus benchmarks, the\nconditional model shifts docking-score distributions toward stronger predicted\nbinding. These results suggest that a modernized, scale-appropriate VAE remains\ncompetitive for molecular generation when paired with principled conditioning\nand parameter-efficient finetuning."}
{"id": "2511.02332", "pdf": "https://arxiv.org/pdf/2511.02332", "abs": "https://arxiv.org/abs/2511.02332", "authors": ["Hongyang Jiang", "Yuezhu Wang", "Ke Feng", "Chaoyi Yin", "Yi Chang", "Huiyan Sun"], "title": "Biological Regulatory Network Inference through Circular Causal Structure Learning", "categories": ["q-bio.MN", "cs.AI"], "comment": null, "summary": "Biological networks are pivotal in deciphering the complexity and\nfunctionality of biological systems. Causal inference, which focuses on\ndetermining the directionality and strength of interactions between variables\nrather than merely relying on correlations, is considered a logical approach\nfor inferring biological networks. Existing methods for causal structure\ninference typically assume that causal relationships between variables can be\nrepresented by directed acyclic graphs (DAGs). However, this assumption is at\nodds with the reality of widespread feedback loops in biological systems,\nmaking these methods unsuitable for direct use in biological network inference.\nIn this study, we propose a new framework named SCALD (Structural CAusal model\nfor Loop Diagram), which employs a nonlinear structure equation model and a\nstable feedback loop conditional constraint through continuous optimization to\ninfer causal regulatory relationships under feedback loops. We observe that\nSCALD outperforms state-of-the-art methods in inferring both transcriptional\nregulatory networks and signaling transduction networks. SCALD has\nirreplaceable advantages in identifying feedback regulation. Through\ntranscription factor (TF) perturbation data analysis, we further validate the\naccuracy and sensitivity of SCALD. Additionally, SCALD facilitates the\ndiscovery of previously unknown regulatory relationships, which we have\nsubsequently confirmed through ChIP-seq data analysis. Furthermore, by\nutilizing SCALD, we infer the key driver genes that facilitate the\ntransformation from colon inflammation to cancer by examining the dynamic\nchanges within regulatory networks during the process."}
{"id": "2511.02263", "pdf": "https://arxiv.org/pdf/2511.02263", "abs": "https://arxiv.org/abs/2511.02263", "authors": ["Jaeyeon Lee", "Hyun-Hwan Jeong", "Zhandong Liu"], "title": "LA-MARRVEL: A Knowledge-Grounded and Language-Aware LLM Reranker for AI-MARRVEL in Rare Disease Diagnosis", "categories": ["q-bio.GN", "cs.AI"], "comment": null, "summary": "Diagnosing rare diseases often requires connecting variant-bearing genes to\nevidence that is written as unstructured clinical prose, which the current\nestablished pipelines still leave for clinicians to reconcile manually. To this\nend, we introduce LA-MARRVEL, a knowledge-grounded and language-aware reranking\nlayer that operates on top of AI-MARRVEL: it supplies expert-engineered\ncontext, queries a large language model multiple times, and aggregates the\nresulting partial rankings with a ranked voting method to produce a stable,\nexplainable gene ranking. Evaluated on three real-world cohorts (BG, DDD, UDN),\nLA-MARRVEL consistently improves Recall@K over AI-MARRVEL and established\nphenotype-driven tools such as Exomiser and LIRICAL, with especially large\ngains on cases where the first-stage ranker placed the causal gene lower. Each\nranked gene is accompanied by LLM-generated reasoning that integrates\nphenotypic, inheritance, and variant-level evidence, thereby making the output\nmore interpretable and facilitating clinical review."}
{"id": "2511.01905", "pdf": "https://arxiv.org/pdf/2511.01905", "abs": "https://arxiv.org/abs/2511.01905", "authors": ["John A. Mackenzie", "Adam Hillman", "M. Gabriela M. Gomes"], "title": "The impact of nonheritable variation in division rates on population growth across environments", "categories": ["q-bio.PE"], "comment": "15 pages, 7 figures", "summary": "We analyse a series of bacterial growth models with in-built inter-individual\nvariation in rates of cell division. We show that this variation leads to\nreduced population growth in favorable regimes and reduced population killing\nin detrimental environments. By treating environmental stress as a model\nparameter, we then show that the reduction in population growth aggravates with\nstress. We apply these models to data on growth rates for populations of green\nalgae {\\em Clamydomonas reinhardtii}. Specifically, we compare growth rates of\ntwo ancestral strains and respective mutation accumulation lines, measured\nalong a stress gradient. The data had previously shown mutants growing\nconsistently slower than ancestors, and this effect aggravating with stress.\nHere we show that this trend is expected if mutants are more variable than\nancestors in individual rates of cell division, even if their means are higher.\nThis can open new prospects for prediction of how populations respond to\nenvironmental changes."}
{"id": "2511.01868", "pdf": "https://arxiv.org/pdf/2511.01868", "abs": "https://arxiv.org/abs/2511.01868", "authors": ["Ching-Chih Sung", "Shuntaro Suzuki", "Francis Pingfan Chien", "Komei Sugiura", "Yu Tsao"], "title": "Condition-Invariant fMRI Decoding of Speech Intelligibility with Deep State Space Model", "categories": ["q-bio.NC", "cs.LG", "cs.SD", "eess.AS", "eess.SP"], "comment": null, "summary": "Clarifying the neural basis of speech intelligibility is critical for\ncomputational neuroscience and digital speech processing. Recent neuroimaging\nstudies have shown that intelligibility modulates cortical activity beyond\nsimple acoustics, primarily in the superior temporal and inferior frontal gyri.\nHowever, previous studies have been largely confined to clean speech, leaving\nit unclear whether the brain employs condition-invariant neural codes across\ndiverse listening environments. To address this gap, we propose a novel\narchitecture built upon a deep state space model for decoding intelligibility\nfrom fMRI signals, specifically tailored to their high-dimensional temporal\nstructure. We present the first attempt to decode intelligibility across\nacoustically distinct conditions, showing our method significantly outperforms\nclassical approaches. Furthermore, region-wise analysis highlights\ncontributions from auditory, frontal, and parietal regions, and cross-condition\ntransfer indicates the presence of condition-invariant neural codes, thereby\nadvancing understanding of abstract linguistic representations in the brain."}
{"id": "2511.01953", "pdf": "https://arxiv.org/pdf/2511.01953", "abs": "https://arxiv.org/abs/2511.01953", "authors": ["Takaaki Tachibana", "Toru Nagasaka", "Yukari Adachi", "Hiroki Kagiyama", "Ryota Ito", "Mitsugu Fujita", "Kimihiro Yamashita", "Yoshihiro Kakeji"], "title": "Reliability Assessment Framework Based on Feature Separability for Pathological Cell Image Classification under Prior Bias", "categories": ["q-bio.QM", "eess.IV"], "comment": null, "summary": "\\textbf{Background and objective:} Prior probability shift between training\nand deployment datasets challenges deep learning--based medical image\nclassification. Standard correction methods reweight posterior probabilities to\nadjust prior bias, yet their benefit is inconsistent. We developed a\nreliability framework identifying when prior correction helps or harms\nperformance in pathological cell image analysis. \\textbf{Methods:} We analyzed\n303 colorectal cancer specimens with CD103/CD8 immunostaining, yielding\n185{,}432 annotated cell images across 16 cell types. ResNet models were\ntrained under varying bias ratios (1.1--20$\\times$). Feature separability was\nquantified using cosine similarity--based likelihood quality scores, reflecting\nintra- versus inter-class distinctions in learned feature spaces. Multiple\nlinear regression, ANOVA, and generalized additive models (GAMs) evaluated\nassociations among feature separability, prior bias, sample adequacy, and F1\nperformance. \\textbf{Results:} Feature separability dominated performance\n($\\beta = 1.650$, $p < 0.001$), showing 412-fold stronger impact than prior\nbias ($\\beta = 0.004$, $p = 0.018$). GAM analysis showed strong predictive\npower ($R^2 = 0.876$) with mostly linear trends. A quality threshold of 0.294\neffectively identified cases requiring correction (AUC = 0.610). Cell types\nscoring $>0.5$ were robust without correction, whereas those $<0.3$\nconsistently required adjustment. \\textbf{Conclusion:} Feature extraction\nquality, not bias magnitude, governs correction benefit. The proposed framework\nprovides quantitative guidance for selective correction, enabling efficient\ndeployment and reliable diagnostic AI."}
{"id": "2511.02418", "pdf": "https://arxiv.org/pdf/2511.02418", "abs": "https://arxiv.org/abs/2511.02418", "authors": ["Xiaoyu Zhang", "Zhou Fang"], "title": "Biomolecular LQR under Partial Observation", "categories": ["q-bio.MN", "math.OC"], "comment": null, "summary": "This paper introduces a biomolecular Linear Quadratic Regulator (LQR) to\ninvestigate the design principles of gene regulatory networks. We show that for\nfundamental gene regulation network, the bio-controller derived from LQR theory\nprecisely recapitulate natural network motifs, such as auto-regulation and\nincoherent feedforward loops. This emulation arises from a fundamental\nprinciple: the LQR cost function mathematically encodes environmental survival\ndemands, which subsequently drives the selection of both network topology and\nbiochemical parameters. Our work thus establishes a theoretical basis for\ninterpreting biological circuit design, directly linking evolutionary pressures\nto observable regulatory structures."}
{"id": "2511.01920", "pdf": "https://arxiv.org/pdf/2511.01920", "abs": "https://arxiv.org/abs/2511.01920", "authors": ["Lillian Achola Oluoch", "Florent Ouabo Kamkumo", "Ralf Wunderlich"], "title": "Stochastic Models and Estimation of Undetected Infections in the Transmission of Zika Virus", "categories": ["q-bio.PE", "math.PR", "92D30, 92-10, 60J60, 60G35, 62M20"], "comment": "49 pages", "summary": "Zika fever, a mosquito-borne viral disease with potential severe neurological\ncomplications and birth defects, remains a significant public health concern.\nThe epidemiological models often oversimplify the dynamics of Zika transmission\nby assuming immediate detection of all infected cases. This study provides an\nenhanced SEIR (Susceptible-Exposed-Infectious-Recovered) model to incorporate\npartial information by distinguishing between detected and undetected Zika\ninfections (also known as \"dark figures\"). By distinguishing the compartments,\nthe model captures the complexities of disease spread by accounting for\nuncertainties about transmission and the number of undetected infections. This\nmodel implements the Kalman filter technique to estimate the hidden states from\nthe observed states. Numerical simulations were performed to understand the\ndynamics of Zika transmission and real-world data was utilized for\nparameterization and validation of the model. The study aims to provide\ninformation on the impact of undetected Zika infections on disease spread\nwithin the population, which will contribute to evidence-based decision making\nin public health policy and practice."}
{"id": "2511.01870", "pdf": "https://arxiv.org/pdf/2511.01870", "abs": "https://arxiv.org/abs/2511.01870", "authors": ["Christian Schiffer", "Zeynep Boztoprak", "Jan-Oliver Kropp", "Julia Thönnißen", "Katia Berr", "Hannah Spitzer", "Katrin Amunts", "Timo Dickscheid"], "title": "CytoNet: A Foundation Model for the Human Cerebral Cortex", "categories": ["q-bio.NC", "cs.AI", "cs.LG", "I.2.6; I.2.10; I.4.7; I.5.1; I.5.4"], "comment": "Under review for journal publication", "summary": "To study how the human brain works, we need to explore the organization of\nthe cerebral cortex and its detailed cellular architecture. We introduce\nCytoNet, a foundation model that encodes high-resolution microscopic image\npatches of the cerebral cortex into highly expressive feature representations,\nenabling comprehensive brain analyses. CytoNet employs self-supervised learning\nusing spatial proximity as a powerful training signal, without requiring manual\nlabelling. The resulting features are anatomically sound and biologically\nrelevant. They encode general aspects of cortical architecture and unique\nbrain-specific traits. We demonstrate top-tier performance in tasks such as\ncortical area classification, cortical layer segmentation, cell morphology\nestimation, and unsupervised brain region mapping. As a foundation model,\nCytoNet offers a consistent framework for studying cortical microarchitecture,\nsupporting analyses of its relationship with other structural and functional\nbrain features, and paving the way for diverse neuroscientific investigations."}
{"id": "2511.02735", "pdf": "https://arxiv.org/pdf/2511.02735", "abs": "https://arxiv.org/abs/2511.02735", "authors": ["Eva Guttmann-Flury", "Jian Zhao", "Mohamad Sawan"], "title": "Spatial Insight: How Data-Driven Regions of Interest Selection Enhances Single-Trial P300 Classification in EEG-Based BCIs", "categories": ["q-bio.QM"], "comment": null, "summary": "EEG-based Brain-Computer Interfaces (BCIs) frequently face spatial\nspecificity limitations in detecting single-trial P300 potentials, a\nneurophysiological hallmark leveraged for both BCI control and\nneurodegenerative disease diagnostics. We present a novel framework combining\neLORETA source localization with cross-subject functional connectivity to\nidentify stable regions of interest (ROIs) across sessions. Analyzing\n62-channel EEG data from 31 subjects (63 sessions, 2,520 trials), we\ndemonstrate that phase-lagged connectivity metrics can reliably isolate\ntask-relevant hubs in deeper cortical-subcortical structures like the insula\nand parietal regions - critical for Alzheimer's disease biomarkers. By\nintegrating spatially stable ROIs with dynamic temporal agreement, our hybrid\nclassification systematically outperforms whole-brain approaches in different\nfrequency bands (up to 5.4% depending on the connectivity method and the\nspectral range) while maintaining millisecond-level temporal precision.\n  To the best of our knowledge, this is the first study to establish\ncross-subject ROI consensus through source-space connectivity, bypassing scalp\nEEG's depth constraints to probe Alzheimer's-relevant networks. The framework's\nrobustness to noise and compatibility with portable systems offer significant\npotential for global deployment in early neurodegenerative disease detection.\nFuture integration of individualized anatomical data or adaptive parameter\noptimization could refine this tool for clinical deployment, enhancing the\ncurrent max accuracy of 81.57% in the 1-15 Hz range."}
{"id": "2511.01939", "pdf": "https://arxiv.org/pdf/2511.01939", "abs": "https://arxiv.org/abs/2511.01939", "authors": ["David J. D. Earn", "Todd L. Parsons"], "title": "Epidemic Momentum", "categories": ["q-bio.PE", "92D30"], "comment": "35 pages, 1 table, 4 figures", "summary": "Infectious disease outbreaks have precipitated a profusion of mathematical\nmodels. We introduce a unifying concept of \"epidemic momentum\" -- prevalence\nweighted by the capacity to infect in the future -- and use it to reveal a\ncommon underlying geometry that corresponds to contours of a generic first\nintegral. Exploiting this conserved quantity, we show that it is possible to\n(i) disentangle the basic reproduction number $R_0$ from the population\nproportion that was immune before a disease invasion or re-emergence and (ii)\ninfer both from observed data. This separation enables us to revise the\nclassical estimate of the epidemic final size, incorporating prior population\nimmunity. To illustrate the utility of these insights, we present a novel\nreappraisal of the main wave of the 1918 influenza pandemic."}
{"id": "2511.02063", "pdf": "https://arxiv.org/pdf/2511.02063", "abs": "https://arxiv.org/abs/2511.02063", "authors": ["Dale Zhou", "Danielle Cosme", "Yoona Kang", "Ovidia Stanoi", "David M. Lydon-Staley", "Peter J. Mucha", "Emily B. Falk", "Kevin N. Ochsner", "Dani S. Bassett"], "title": "Neural dynamics of cognitive control: Current tensions and future promise", "categories": ["q-bio.NC"], "comment": null, "summary": "Cognitive control is a suite of processes that helps individuals pursue goals\ndespite resistance or uncertainty about what to do. Although cognitive control\nhas been extensively studied as a dynamic feedback loop of perception,\nvaluation, and action, it remains incompletely understood as a cohesive dynamic\nand distributed neural process. Here, we critically examine the history of and\nadvances in the study of cognitive control, including how metaphors and\ncultural norms of power, morality, and rationality are intertwined with\ndefinitions of control, to consider holistically how different models explain\nwhich brain regions act as controllers. Controllers, the source of top-down\nsignals, are typically localized in regions whose neural activations implement\nelementary component processes of control, including conflict monitoring and\nbehavioral inhibition. Top-down signals from these regions guide the activation\nof other task-specific regions, biasing them towards task-specific activity\npatterns. A relatively new approach, network control theory, has roots in\ndynamical systems theory and systems engineering. This approach can\nmathematically show that controllers are regions with strongly nested and\nrecurrent anatomical connectivity that efficiently propagate top-down signals,\nand precisely estimate the amount, location, and timing of signaling required\nto bias global activity to task-specific patterns. The theory converges with\nprior evidence, offers new mathematical tools and intuitions for understanding\ncontrol loops across levels of analysis, and naturally produces graded\npredictions of control across brain regions and modules of psychological\nfunction that have been unconsidered or marginalized. We describe how prior\napproaches converge and diverge, noting directions for future integration to\nimprove understanding of how the brain instantiates cognitive control."}
{"id": "2511.02038", "pdf": "https://arxiv.org/pdf/2511.02038", "abs": "https://arxiv.org/abs/2511.02038", "authors": ["Elham Gholamzadeh", "Kajal Singla", "Nico Scherf"], "title": "Predicting Microbial Interactions Using Graph Neural Networks", "categories": ["cs.LG", "q-bio.QM", "68T05", "I.2.6; I.5.1"], "comment": "9 pages, 3 figures, NeurIPS 2025 Workshop New Perspectives in Graph\n  Machine Learning", "summary": "Predicting interspecies interactions is a key challenge in microbial ecology,\nas these interactions are critical to determining the structure and activity of\nmicrobial communities. In this work, we used data on monoculture growth\ncapabilities, interactions with other species, and phylogeny to predict a\nnegative or positive effect of interactions. More precisely, we used one of the\nlargest available pairwise interaction datasets to train our models, comprising\nover 7,500 interactions be- tween 20 species from two taxonomic groups\nco-cultured under 40 distinct carbon conditions, with a primary focus on the\nwork of Nestor et al.[28 ]. In this work, we propose Graph Neural Networks\n(GNNs) as a powerful classifier to predict the direction of the effect. We\nconstruct edge-graphs of pairwise microbial interactions in order to leverage\nshared information across individual co-culture experiments, and use GNNs to\npredict modes of interaction. Our model can not only predict binary\ninteractions (positive/negative) but also classify more complex interaction\ntypes such as mutualism, competition, and parasitism. Our initial results were\nencouraging, achieving an F1-score of 80.44%. This significantly outperforms\ncomparable methods in the literature, including conventional Extreme Gradient\nBoosting (XGBoost) models, which reported an F1-score of 72.76%."}
{"id": "2511.01943", "pdf": "https://arxiv.org/pdf/2511.01943", "abs": "https://arxiv.org/abs/2511.01943", "authors": ["Guillaume Hummel", "David Pflieger", "Alexandre Berr", "Laurence Drouard"], "title": "From the RNA world to land plants: Evolutionary insights from tRNA genes", "categories": ["q-bio.PE"], "comment": "25 pages, 7 figures, 19 supplemental figures", "summary": "Transfer RNAs (tRNAs) are universal adaptors of the genetic code, yet their\nevolutionary dynamics across photosynthetic eukaryotes remain underexplored.\nHere, we present the largest comparative re-analysis integrating the PlantRNA\ndatabase with published data to explore tRNA gene evolution. We find that tRNA\ngene repertoires have been deeply shaped by ecological transitions, genome\narchitecture, and translational demands. Terrestrialization marks a major shift\nin tRNA evolution, characterized by the loss of selenoproteins and their\ndedicated selenocysteine tRNAs in land plants compared to algae. Patterns of\nintron prevalence, position, and structure diverged among lineages, with\nextensive intron loss occurring around the origin of land plants. Organellar\ngenomes exhibit divergent trajectories: mitochondrial tRNA sets are highly\nlabile due to recurrent gene losses, imports, and horizontal transfers, whereas\nplastid repertoires are comparatively stable with lineage-specific exceptions.\nIn parallel, angiosperm nuclear tRNA genes exhibit reinforced cis-regulatory\nelements, consistent with increased and developmentally complex translational\ndemands, and their copy number correlates tightly with codon usage and amino\nacid composition. Finally, conserved yet family-biased clustering of nuclear\ntRNA genes reveals contrasting organizational principles in plants versus\nmetazoans. Together, these findings establish tRNA gene evolution as a major\ndeterminant of translational capacity and a key driver of photosynthetic\ndiversification."}
{"id": "2511.02722", "pdf": "https://arxiv.org/pdf/2511.02722", "abs": "https://arxiv.org/abs/2511.02722", "authors": ["Subati Abulikemu", "Puria Radmard", "Michail Mamalakis", "John Suckling"], "title": "Association-sensory spatiotemporal hierarchy and functional gradient-regularised recurrent neural network with implications for schizophrenia", "categories": ["q-bio.NC"], "comment": "34 pages, 9 figures", "summary": "The human neocortex is functionally organised at its highest level along a\ncontinuous sensory-to-association (AS) hierarchy. This study characterises the\nAS hierarchy of patients with schizophrenia in a comparison with controls.\nUsing a large fMRI dataset (N=355), we extracted individual AS gradients via\nspectral analysis of brain connectivity, quantified hierarchical specialisation\nby gradient spread, and related this spread with connectivity geometry. We\nfound that schizophrenia compresses the AS hierarchy indicating reduced\nfunctional differentiation. By modelling neural timescale with the\nOrnstein-Uhlenbeck process, we observed that the most specialised, locally\ncohesive regions at the gradient extremes exhibit dynamics with a longer time\nconstant, an effect that is attenuated in schizophrenia. To study computation,\nwe used the gradients to regularise subject-specific recurrent neural networks\n(RNNs) trained on working memory tasks. Networks endowed with greater gradient\nspread learned more efficiently, plateaued at lower task loss, and maintained\nstronger alignment to the prescribed AS hierarchical geometry. Fixed point\nlinearisation showed that high-range networks settled into more stable neural\nstates during memory delay, evidenced by lower energy and smaller maximal\nJacobian eigenvalues. This gradient-regularised RNN framework therefore links\nlarge-scale cortical architecture with fixed point stability, providing a\nmechanistic account of how gradient de-differentiation could destabilise neural\ncomputations in schizophrenia, convergently supported by empirical timescale\nflattening and model-based evidence of less stable fixed points."}
{"id": "2511.02437", "pdf": "https://arxiv.org/pdf/2511.02437", "abs": "https://arxiv.org/abs/2511.02437", "authors": ["K. M. D. Chan", "D. T. Crommelin", "M. R. H. Mandjes"], "title": "Asymptotic behavior for a general class of spreading models", "categories": ["q-bio.PE", "math.DS"], "comment": null, "summary": "Growing literatures on epidemic and rumor dynamics show that infection and\ninformation coevolve. We present a unified framework for modeling the spread of\ninfection and information: a general class of interaction-driven fluid-limit\nmodels expressed as coupled ODEs. The class includes the SIR epidemic model,\nthe Daley-Kendall rumor model, and many extensions. For this general class, we\nderive theoretical results: under explicit graph-theoretic conditions, we\nobtain a classification of asymptotic behavior and motivate a conjecture of\nexponential decay for vanishing states. When these conditions are violated, the\nclassification can fail, and decay may become non-exponential (e.g.,\nalgebraic). In deriving the main result, we establish asymptotic stability and\n$L^1$-integrability properties for state variables. Alongside these results, we\nintroduce the dependency graph that captures outflow dependencies and offers a\nnew angle on the structure of this model class. Finally, we illustrate the\nresults with several examples, including a heterogeneous rumor model and a\nrumor-dependent SIR model, showing how small changes to the dependency graph\ncan flip asymptotic behavior and reshape epidemic trajectories."}
{"id": "2511.02766", "pdf": "https://arxiv.org/pdf/2511.02766", "abs": "https://arxiv.org/abs/2511.02766", "authors": ["Enso Onill Torres Alegre"], "title": "Microbes in the Moonlight: How the Gut Microbiota Influences Sleep", "categories": ["q-bio.NC"], "comment": "31 pages, 2 tables, 1 figure. Review article on the gut microbiota\n  sleep axis", "summary": "The gut microbiota has emerged as a fundamental regulator of sleep\nphysiology, influencing neural, endocrine, and immune pathways through the\ngut-microbiota-brain axis (GMBA). This bidirectional communication system\nmodulates neurotransmitter production, circadian rhythms, and metabolic\nhomeostasis, while disruptions in microbial composition have been linked to\nsleep disorders, neuroinflammation, and systemic immune dysfunction. Recent\nfindings suggest that gut dysbiosis contributes to sleep disturbances by\naltering serotonin, GABA, and short-chain fatty acid (SCFA) metabolism, with\nimplications for neurodegenerative diseases, metabolic syndromes, and mood\ndisorders. Additionally, the gut microbiota interacts with the endocrine and\nimmune systems, shaping inflammatory responses and stress adaptation\nmechanisms. This review explores the intricate connections between sleep and\nthe gut microbiota, integrating emerging research on microbiota-targeted\ntherapies, such as probiotics, fecal microbiota transplantation (FMT), and\nchrononutrition, as potential interventions to restore sleep homeostasis and\nimprove health outcomes"}
{"id": "2511.01885", "pdf": "https://arxiv.org/pdf/2511.01885", "abs": "https://arxiv.org/abs/2511.01885", "authors": ["Robyn Wyrick"], "title": "Mirror-Neuron Patterns in AI Alignment", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "comment": "51 pages, Masters thesis. 10 tables, 7 figures, project data & code\n  here: https://github.com/robynwyrick/mirror-neuron-frog-and-toad", "summary": "As artificial intelligence (AI) advances toward superhuman capabilities,\naligning these systems with human values becomes increasingly critical. Current\nalignment strategies rely largely on externally specified constraints that may\nprove insufficient against future super-intelligent AI capable of circumventing\ntop-down controls.\n  This research investigates whether artificial neural networks (ANNs) can\ndevelop patterns analogous to biological mirror neurons cells that activate\nboth when performing and observing actions, and how such patterns might\ncontribute to intrinsic alignment in AI. Mirror neurons play a crucial role in\nempathy, imitation, and social cognition in humans. The study therefore asks:\n(1) Can simple ANNs develop mirror-neuron patterns? and (2) How might these\npatterns contribute to ethical and cooperative decision-making in AI systems?\n  Using a novel Frog and Toad game framework designed to promote cooperative\nbehaviors, we identify conditions under which mirror-neuron patterns emerge,\nevaluate their influence on action circuits, introduce the Checkpoint Mirror\nNeuron Index (CMNI) to quantify activation strength and consistency, and\npropose a theoretical framework for further study.\n  Our findings indicate that appropriately scaled model capacities and\nself/other coupling foster shared neural representations in ANNs similar to\nbiological mirror neurons. These empathy-like circuits support cooperative\nbehavior and suggest that intrinsic motivations modeled through mirror-neuron\ndynamics could complement existing alignment techniques by embedding\nempathy-like mechanisms directly within AI architectures."}
{"id": "2511.02241", "pdf": "https://arxiv.org/pdf/2511.02241", "abs": "https://arxiv.org/abs/2511.02241", "authors": ["Brennen A. Hill"], "title": "Structural Plasticity as Active Inference: A Biologically-Inspired Architecture for Homeostatic Control", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC", "68T07, 92B20", "I.2.6; I.2.0; I.2.11"], "comment": null, "summary": "Traditional neural networks, while powerful, rely on biologically implausible\nlearning mechanisms such as global backpropagation. This paper introduces the\nStructurally Adaptive Predictive Inference Network (SAPIN), a novel\ncomputational model inspired by the principles of active inference and the\nmorphological plasticity observed in biological neural cultures. SAPIN operates\non a 2D grid where processing units, or cells, learn by minimizing local\nprediction errors. The model features two primary, concurrent learning\nmechanisms: a local, Hebbian-like synaptic plasticity rule based on the\ntemporal difference between a cell's actual activation and its learned\nexpectation, and a structural plasticity mechanism where cells physically\nmigrate across the grid to optimize their information-receptive fields. This\ndual approach allows the network to learn both how to process information\n(synaptic weights) and also where to position its computational resources\n(network topology). We validated the SAPIN model on the classic Cart Pole\nreinforcement learning benchmark. Our results demonstrate that the architecture\ncan successfully solve the CartPole task, achieving robust performance. The\nnetwork's intrinsic drive to minimize prediction error and maintain homeostasis\nwas sufficient to discover a stable balancing policy. We also found that while\ncontinual learning led to instability, locking the network's parameters after\nachieving success resulted in a stable policy. When evaluated for 100 episodes\npost-locking (repeated over 100 successful agents), the locked networks\nmaintained an average 82% success rate."}
{"id": "2511.02558", "pdf": "https://arxiv.org/pdf/2511.02558", "abs": "https://arxiv.org/abs/2511.02558", "authors": ["Ali Farki", "Elaheh Moradi", "Deepika Koundal", "Jussi Tohka"], "title": "Forecasting Future Anatomies: Longitudianl Brain Mri-to-Mri Prediction", "categories": ["cs.CV", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Predicting future brain state from a baseline magnetic resonance image (MRI)\nis a central challenge in neuroimaging and has important implications for\nstudying neurodegenerative diseases such as Alzheimer's disease (AD). Most\nexisting approaches predict future cognitive scores or clinical outcomes, such\nas conversion from mild cognitive impairment to dementia. Instead, here we\ninvestigate longitudinal MRI image-to-image prediction that forecasts a\nparticipant's entire brain MRI several years into the future, intrinsically\nmodeling complex, spatially distributed neurodegenerative patterns. We\nimplement and evaluate five deep learning architectures (UNet, U2-Net, UNETR,\nTime-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL).\nPredicted follow-up MRIs are directly compared with the actual follow-up scans\nusing metrics that capture global similarity and local differences. The best\nperforming models achieve high-fidelity predictions, and all models generalize\nwell to an independent external dataset, demonstrating robust cross-cohort\nperformance. Our results indicate that deep learning can reliably predict\nparticipant-specific brain MRI at the voxel level, offering new opportunities\nfor individualized prognosis."}
