{"id": "2510.01632", "pdf": "https://arxiv.org/pdf/2510.01632", "abs": "https://arxiv.org/abs/2510.01632", "authors": ["Xin Wang", "Carlos Oliver"], "title": "BioBlobs: Differentiable Graph Partitioning for Protein Representation Learning", "categories": ["q-bio.BM", "cs.AI"], "comment": null, "summary": "Protein function is driven by coherent substructures which vary in size and\ntopology, yet current protein representation learning models (PRL) distort\nthese signals by relying on rigid substructures such as k-hop and fixed radius\nneighbourhoods. We introduce BioBlobs, a plug-and-play, fully differentiable\nmodule that represents proteins by dynamically partitioning structures into\nflexibly-sized, non-overlapping substructures (\"blobs\"). The resulting blobs\nare quantized into a shared and interpretable codebook, yielding a discrete\nvocabulary of function-relevant protein substructures used to compute protein\nembeddings. We show that BioBlobs representations improve the performance of\nwidely used protein encoders such as GVP-GNN across various PRL tasks. Our\napproach highlights the value of architectures that directly capture\nfunction-relevant protein substructures, enabling both improved predictive\nperformance and mechanistic insight into protein function."}
{"id": "2510.01571", "pdf": "https://arxiv.org/pdf/2510.01571", "abs": "https://arxiv.org/abs/2510.01571", "authors": ["Hanqun Cao", "Hongrui Zhang", "Junde Xu", "Zhou Zhang", "Lingdong Shen", "Minghao Sun", "Ge Liu", "Jinbo Xu", "Wu-Jun Li", "Jinren Ni", "Cesar de la Fuente-Nunez", "Tianfan Fu", "Yejin Choi", "Pheng-Ann Heng", "Fang Wu"], "title": "From Supervision to Exploration: What Does Protein Language Model Learn During Reinforcement Learning?", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "comment": "24 pages, 7 figures, 4 tables", "summary": "Protein language models (PLMs) have advanced computational protein science\nthrough large-scale pretraining and scalable architectures. In parallel,\nreinforcement learning (RL) has broadened exploration and enabled precise\nmulti-objective optimization in protein design. Yet whether RL can push PLMs\nbeyond their pretraining priors to uncover latent sequence-structure-function\nrules remains unclear. We address this by pairing RL with PLMs across four\ndomains: antimicrobial peptide design, kinase variant optimization, antibody\nengineering, and inverse folding. Using diverse RL algorithms and model\nclasses, we ask if RL improves sampling efficiency and, more importantly, if it\nreveals capabilities not captured by supervised learning. Across benchmarks, RL\nconsistently boosts success rates and sample efficiency. Performance follows a\nthree-factor interaction: task headroom, reward fidelity, and policy capacity\njointly determine gains. When rewards are accurate and informative, policies\nhave sufficient capacity, and tasks leave room beyond supervised baselines,\nimprovements scale; when rewards are noisy or capacity is constrained, gains\nsaturate despite exploration. This view yields practical guidance for RL in\nprotein design: prioritize reward modeling and calibration before scaling\npolicy size, match algorithm and regularization strength to task difficulty,\nand allocate capacity where marginal gains are largest. Implementation is\navailable at https://github.com/chq1155/RL-PLM."}
{"id": "2510.01890", "pdf": "https://arxiv.org/pdf/2510.01890", "abs": "https://arxiv.org/abs/2510.01890", "authors": ["Anders Irbäck", "Lucas Knuthson", "Sandipan Mohanty"], "title": "Folding lattice proteins confined on minimal grids using a quantum-inspired encoding", "categories": ["quant-ph", "cond-mat.soft", "physics.bio-ph", "q-bio.BM"], "comment": "22 pages, 5 figures", "summary": "Steric clashes pose a challenge when exploring dense protein systems using\nconventional explicit-chain methods. A minimal example is a single lattice\nprotein confined on a minimal grid, with no free sites. Finding its minimum\nenergy is a hard optimization problem, withsimilarities to scheduling problems.\nIt can be recast as a quadratic unconstrained binary optimization (QUBO)\nproblem amenable to classical and quantum approaches. We show that this problem\nin its QUBO form can be swiftly and consistently solved for chain length 48,\nusing either classical simulated annealing or hybrid quantum-classical\nannealing on a D-Wave system. In fact, the latter computations required about\n10 seconds. We also test linear and quadratic programming methods, which work\nwell for a lattice gas but struggle with chain constraints. All methods are\nbenchmarked against exact results obtained from exhaustive structure\nenumeration, at a high computational cost."}
{"id": "2510.02259", "pdf": "https://arxiv.org/pdf/2510.02259", "abs": "https://arxiv.org/abs/2510.02259", "authors": ["Tobias Kreiman", "Yutong Bai", "Fadi Atieh", "Elizabeth Weaver", "Eric Qu", "Aditi S. Krishnapriyan"], "title": "Transformers Discover Molecular Structure Without Graph Priors", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "q-bio.BM"], "comment": null, "summary": "Graph Neural Networks (GNNs) are the dominant architecture for molecular\nmachine learning, particularly for molecular property prediction and machine\nlearning interatomic potentials (MLIPs). GNNs perform message passing on\npredefined graphs often induced by a fixed radius cutoff or k-nearest neighbor\nscheme. While this design aligns with the locality present in many molecular\ntasks, a hard-coded graph can limit expressivity due to the fixed receptive\nfield and slows down inference with sparse graph operations. In this work, we\ninvestigate whether pure, unmodified Transformers trained directly on Cartesian\ncoordinates$\\unicode{x2013}$without predefined graphs or physical\npriors$\\unicode{x2013}$can approximate molecular energies and forces. As a\nstarting point for our analysis, we demonstrate how to train a Transformer to\ncompetitive energy and force mean absolute errors under a matched training\ncompute budget, relative to a state-of-the-art equivariant GNN on the OMol25\ndataset. We discover that the Transformer learns physically consistent\npatterns$\\unicode{x2013}$such as attention weights that decay inversely with\ninteratomic distance$\\unicode{x2013}$and flexibly adapts them across different\nmolecular environments due to the absence of hard-coded biases. The use of a\nstandard Transformer also unlocks predictable improvements with respect to\nscaling training resources, consistent with empirical scaling laws observed in\nother domains. Our results demonstrate that many favorable properties of GNNs\ncan emerge adaptively in Transformers, challenging the necessity of hard-coded\ngraph inductive biases and pointing toward standardized, scalable architectures\nfor molecular modeling."}
{"id": "2510.01935", "pdf": "https://arxiv.org/pdf/2510.01935", "abs": "https://arxiv.org/abs/2510.01935", "authors": ["Evgeny Knyazev", "Timur Kulagin", "Ivan Antipenko", "Alexander Tonevitsky"], "title": "Single-cell sequencing of trophoblasts in preeclampsia and chemical hypoxia in BeWo b30 cells reveals EBI3, COL17A1, miR-27a-5p, and miR-193b-5p as hypoxia-response markers", "categories": ["q-bio.GN", "q-bio.CB", "q-bio.TO"], "comment": "27 pages, 10 figures, 2 tables", "summary": "Background. Preeclampsia (PE) complicates 2-8% of pregnancies and is marked\nby placental hypoxia and HIF-pathway activation, especially in early-onset PE\n(eoPE). Integrating patient tissue analyses with experimental models may reveal\ncommon molecular markers of trophoblast hypoxia.\n  Methods. We analyzed scRNA-seq data from 10 eoPE, 7 late-onset PE (loPE), and\ncorresponding control placentas, identifying villous cytotrophoblast (VCT),\nsyncytiotrophoblast (SCT), and extravillous trophoblast (EVT) subpopulations.\nBeWo b30 cells were treated for 24 h with CoCl2 (300 $\\mu$M) or an oxyquinoline\nderivative (OD, 5 $\\mu$M) to induce hypoxia. RNA and small RNA sequencing\nquantified mRNA and microRNA changes. PROGENy inferred pathway activities.\n  Results. ScRNA-seq revealed highest hypoxia pathway activation in eoPE, with\nEVT showing maximum activity among trophoblast populations. Nine genes were\nupregulated across all trophoblast types in eoPE: EBI3, CST6, FN1, RFK,\nCOL17A1, LDHA, PKP2, RPS4Y1, and RPS26. In vitro, OD induced more specific\nhypoxia responses than CoCl2, with 1,284 versus 3,032 differentially expressed\ngenes respectively. Critically, EBI3, FN1, and COL17A1 showed concordant\nupregulation in both placental tissue and OD-treated cells, while CoCl2\ntreatment produced opposite expression patterns. MicroRNA analysis identified\nhsa-miR-27a-5p and hsa-miR-193b-5p as consistently elevated in both\nexperimental conditions and previously reported in PE placental vesicles. We\nalso identified isoforms of hsa-miR-9-5p and hsa-miR-92b-3p as\nhypoxia-associated in trophoblast.\n  Conclusions. EBI3, COL17A1, hsa-miR-27a-5p, and hsa-miR-193b-5p emerge as\ntrophoblast hypoxia markers in PE. Oxyquinoline derivatives offer a more\nphysiologically relevant in vitro hypoxia model than CoCl2. This integrated\napproach advances understanding of PE pathophysiology and suggests candidate\ntherapeutic targets."}
{"id": "2510.01302", "pdf": "https://arxiv.org/pdf/2510.01302", "abs": "https://arxiv.org/abs/2510.01302", "authors": ["Kassahun Azezew", "Amsalu Tesema", "Bitew Mekuria", "Ayenew Kassie", "Animut Embiale", "Ayodeji Olalekan Salau", "Tsega Asresa"], "title": "Hybrid Predictive Modeling of Malaria Incidence in the Amhara Region, Ethiopia: Integrating Multi-Output Regression and Time-Series Forecasting", "categories": ["q-bio.OT", "cs.LG"], "comment": null, "summary": "Malaria remains a major public health concern in Ethiopia, particularly in\nthe Amhara Region, where seasonal and unpredictable transmission patterns make\nprevention and control challenging. Accurately forecasting malaria outbreaks is\nessential for effective resource allocation and timely interventions. This\nstudy proposes a hybrid predictive modeling framework that combines time-series\nforecasting, multi-output regression, and conventional regression-based\nprediction to forecast the incidence of malaria. Environmental variables, past\nmalaria case data, and demographic information from Amhara Region health\ncenters were used to train and validate the models. The multi-output regression\napproach enables the simultaneous prediction of multiple outcomes, including\nPlasmodium species-specific cases, temporal trends, and spatial variations,\nwhereas the hybrid framework captures both seasonal patterns and correlations\namong predictors. The proposed model exhibits higher prediction accuracy than\nsingle-method approaches, exposing hidden patterns and providing valuable\ninformation to public health authorities. This study provides a valid and\nrepeatable malaria incidence prediction framework that can support\nevidence-based decision-making, targeted interventions, and resource\noptimization in endemic areas."}
{"id": "2510.01201", "pdf": "https://arxiv.org/pdf/2510.01201", "abs": "https://arxiv.org/abs/2510.01201", "authors": ["Stefania Kaklamani", "Constantinos Simserides"], "title": "Psychoacoustic study of simple-tone dyads: frequency ratio and pitch", "categories": ["q-bio.NC"], "comment": "23 pages, 23 figures, 3 tables (including Appendix)", "summary": "This study investigates how listeners perceive consonance and dissonance in\ndyads composed of simple (sine) tones, focusing on the effects of frequency\nratio ($R$) and mean frequency ($F$). Seventy adult participants - categorized\nby musical training, gender, and age group - rated randomly ordered dyads using\nbinary preference responses (``like'' or ``dislike''). Dyads represented\nstandard Western intervals but were constructed with sine tones rather than\nmusical notes, preserving interval ratios while varying absolute pitch.\nStatistical analyses reveal a consistent decrease in preference with increasing\nmean frequency, regardless of interval class or participant group. Octaves,\nfifths, fourths, and sixths showed a nearly linear decline in preference with\nincreasing $F$. Major seconds were among the least preferred. Musicians rated\noctaves and certain consonant intervals more positively than non-musicians,\nwhile gender and age groups exhibited different sensitivity to high\nfrequencies. The findings suggest that both interval structure and pitch range\nshape the perception of consonance in simple-tone dyads, with possible\npsychoacoustic explanations involving frequency sensitivity and auditory\nfatigue at higher frequencies."}
{"id": "2510.01282", "pdf": "https://arxiv.org/pdf/2510.01282", "abs": "https://arxiv.org/abs/2510.01282", "authors": ["Shuyang Chu", "Jingang Shi", "Xu Cheng", "Haoyu Chen", "Xin Liu", "Jian Xu", "Guoying Zhao"], "title": "To Remember, To Adapt, To Preempt: A Stable Continual Test-Time Adaptation Framework for Remote Physiological Measurement in Dynamic Domain Shifts", "categories": ["q-bio.QM"], "comment": null, "summary": "Remote photoplethysmography (rPPG) aims to extract non-contact physiological\nsignals from facial videos and has shown great potential. However, existing\nrPPG approaches struggle to bridge the gap between source and target domains.\nRecent test-time adaptation (TTA) solutions typically optimize rPPG model for\nthe incoming test videos using self-training loss under an unrealistic\nassumption that the target domain remains stationary. However, time-varying\nfactors like weather and lighting in dynamic environments often cause continual\ndomain shifts. The erroneous gradients accumulation from these shifts may\ncorrupt the model's key parameters for physiological information, leading to\ncatastrophic forgetting. Therefore, We propose a physiology-related parameters\nfreezing strategy to retain such knowledge. It isolates physiology-related and\ndomain-related parameters by assessing the model's uncertainty to current\ndomain and freezes the physiology-related parameters during adaptation to\nprevent catastrophic forgetting. Moreover, the dynamic domain shifts with\nvarious non-physiological characteristics may lead to conflicting optimization\nobjectives during TTA, which is manifested as the over-adapted model losing its\nadaptability to future domains. To fix over-adaptation, we propose a preemptive\ngradient modification strategy. It preemptively adapts to future domains and\nuses the acquired gradients to modify current adaptation, thereby preserving\nthe model's adaptability. In summary, we propose a stable continual test-time\nadaptation (CTTA) framework for rPPG measurement, called \\textbf{PhysRAP},\nwhich \\textbf{R}emembers the past, \\textbf{A}dapts to the present, and\n\\textbf{P}reempts the future. Extensive experiments show its state-of-the-art\nperformance, especially in domain shifts. The code is available at\nhttps://github.com/xjtucsy/PhysRAP."}
{"id": "2510.02205", "pdf": "https://arxiv.org/pdf/2510.02205", "abs": "https://arxiv.org/abs/2510.02205", "authors": ["Tommaso Cossetto", "Jonathan Rodenfels", "Pablo Sartori"], "title": "Charting dissipation across the microbial world", "categories": ["q-bio.OT"], "comment": null, "summary": "The energy dissipated by a living organism is commonly identified with heat\ngeneration. However, as cells exchange metabolites with their environment they\nalso dissipate energy in the form of chemical entropy. How dissipation is\ndistributed between exchanges of heat and chemical entropy is largely\nunexplored. Here, we analyze an extensive experimental database recently\ncreated [1] to investigate how microbes partition dissipation between thermal\nand chemical entropy during growth. We find that aerobic respiration exchanges\nlittle chemical entropy and dissipation is primarily due to heat production, as\ncommonly assumed. However, we also find several types of anaerobic metabolism\nthat produce as much chemical entropy as heat. Counterintuitively, instances of\nanaerobic metabolisms such as acetotrophic methanogenesis and sulfur\nrespiration are endothermic. We conclude that, because of their metabolic\nversatility, microbes are able to exploit all combinations of heat and chemical\nentropy exchanges that result in a net production of entropy."}
{"id": "2510.01386", "pdf": "https://arxiv.org/pdf/2510.01386", "abs": "https://arxiv.org/abs/2510.01386", "authors": ["Lindsey Knowles", "Cesar Ceballos", "Rodrigo Pena"], "title": "A Single-Equation Approach to Classifying Neuronal Operational Modes", "categories": ["q-bio.NC", "math.DS"], "comment": "9 pages, 5 figures", "summary": "The neural coding is yet to be discovered. The neuronal operational modes\nthat arise with fixed inputs but with varying degrees of stimulation help to\nelucidate their coding properties. In neurons receiving in vivo stimulation, we\nshow that two operation modes can be described with simplified models: the\ncoincidence detection mode and the integration mode. Our derivations include a\nsimplified polynomial model with non-linear coefficients betam that captures\nthe subthreshold dynamics of these modes of operation. The resulting model can\nexplain these transitions with the sign and size of the smallest nonlinear\ncoefficient of the polynomial alone. Defining neuronal operational modes\nprovides insight into the processing and transmission of information through\nelectrical currents. Requisite operational modes for proper neuronal\nfunctioning may explain disorders involving dysfunction of electrophysiological\nbehavior, such as channelopathies."}
{"id": "2510.01287", "pdf": "https://arxiv.org/pdf/2510.01287", "abs": "https://arxiv.org/abs/2510.01287", "authors": ["Runchen Wang", "Junlin Guo", "Siqi Lu", "Ruining Deng", "Zhengyi Lu", "Yanfan Zhu", "Yuechen Yang", "Chongyu Qu", "Yu Wang", "Shilin Zhao", "Catie Chang", "Mitchell Wilkes", "Mengmeng Yin", "Haichun Yang", "Yuankai Huo"], "title": "Evaluating New AI Cell Foundation Models on Challenging Kidney Pathology Cases Unaddressed by Previous Foundation Models", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Accurate cell nuclei segmentation is critical for downstream tasks in kidney\npathology and remains a major challenge due to the morphological diversity and\nimaging variability of renal tissues. While our prior work has evaluated\nearly-generation AI cell foundation models in this domain, the effectiveness of\nrecent cell foundation models remains unclear. In this study, we benchmark\nadvanced AI cell foundation models (2025), including CellViT++ variants and\nCellpose-SAM, against three widely used cell foundation models developed prior\nto 2024, using a diverse large-scale set of kidney image patches within a\nhuman-in-the-loop rating framework. We further performed fusion-based ensemble\nevaluation and model agreement analysis to assess the segmentation capabilities\nof the different models. Our results show that CellViT++ [Virchow] yields the\nhighest standalone performance with 40.3% of predictions rated as \"Good\" on a\ncurated set of 2,091 challenging samples, outperforming all prior models. In\naddition, our fused model achieves 62.2% \"Good\" predictions and only 0.4%\n\"Bad\", substantially reducing segmentation errors. Notably, the fusion model\n(2025) successfully resolved the majority of challenging cases that remained\nunaddressed in our previous study. These findings demonstrate the potential of\nAI cell foundation model development in renal pathology and provide a curated\ndataset of challenging samples to support future kidney-specific model\nrefinement."}
{"id": "2510.01502", "pdf": "https://arxiv.org/pdf/2510.01502", "abs": "https://arxiv.org/abs/2510.01502", "authors": ["Kathy Garcia", "Leyla Isik"], "title": "Aligning Video Models with Human Social Judgments via Behavior-Guided Fine-Tuning", "categories": ["q-bio.NC", "cs.CV", "cs.LG"], "comment": "15 pages total, 4 figures. Includes 1 algorithm and 2 tables in the\n  appendix", "summary": "Humans intuitively perceive complex social signals in visual scenes, yet it\nremains unclear whether state-of-the-art AI models encode the same similarity\nstructure. We study (Q1) whether modern video and language models capture\nhuman-perceived similarity in social videos, and (Q2) how to instill this\nstructure into models using human behavioral data. To address this, we\nintroduce a new benchmark of over 49,000 odd-one-out similarity judgments on\n250 three-second video clips of social interactions, and discover a modality\ngap: despite the task being visual, caption-based language embeddings align\nbetter with human similarity than any pretrained video model. We close this gap\nby fine-tuning a TimeSformer video model on these human judgments with our\nnovel hybrid triplet-RSA objective using low-rank adaptation (LoRA), aligning\npairwise distances to human similarity. This fine-tuning protocol yields\nsignificantly improved alignment with human perceptions on held-out videos in\nterms of both explained variance and odd-one-out triplet accuracy. Variance\npartitioning shows that the fine-tuned video model increases shared variance\nwith language embeddings and explains additional unique variance not captured\nby the language model. Finally, we test transfer via linear probes and find\nthat human-similarity fine-tuning strengthens the encoding of social-affective\nattributes (intimacy, valence, dominance, communication) relative to the\npretrained baseline. Overall, our findings highlight a gap in pretrained video\nmodels' social recognition and demonstrate that behavior-guided fine-tuning\nshapes video representations toward human social perception."}
{"id": "2510.01298", "pdf": "https://arxiv.org/pdf/2510.01298", "abs": "https://arxiv.org/abs/2510.01298", "authors": ["Berker Demirel", "Marco Fumero", "Theofanis Karaletsos", "Francesco Locatello"], "title": "MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging", "categories": ["q-bio.QM", "cs.CV", "cs.LG"], "comment": null, "summary": "Simulating in silico cellular responses to interventions is a promising\ndirection to accelerate high-content image-based assays, critical for advancing\ndrug discovery and gene editing. To support this, we introduce MorphGen, a\nstate-of-the-art diffusion-based generative model for fluorescent microscopy\nthat enables controllable generation across multiple cell types and\nperturbations. To capture biologically meaningful patterns consistent with\nknown cellular morphologies, MorphGen is trained with an alignment loss to\nmatch its representations to the phenotypic embeddings of OpenPhenom, a\nstate-of-the-art biological foundation model. Unlike prior approaches that\ncompress multichannel stains into RGB images -- thus sacrificing\norganelle-specific detail -- MorphGen generates the complete set of fluorescent\nchannels jointly, preserving per-organelle structures and enabling a\nfine-grained morphological analysis that is essential for biological\ninterpretation. We demonstrate biological consistency with real images via\nCellProfiler features, and MorphGen attains an FID score over $35\\%$ lower than\nthe prior state-of-the-art MorphoDiff, which only generates RGB images for a\nsingle cell type. Code is available at https://github.com/czi-ai/MorphGen."}
{"id": "2510.01753", "pdf": "https://arxiv.org/pdf/2510.01753", "abs": "https://arxiv.org/abs/2510.01753", "authors": ["Sangjoon J. Kim", "Vicky Chan", "Niko Fullmer", "Emily R. Rosario", "Christine Kim", "Charles Y. Liu", "Marti Comellas", "Daniel K. Zondervan", "David J. Reinkensmeyer", "An H. Do"], "title": "Promoting arm movement practice with a novel wheelchair armrest early after stroke: A randomized controlled trial", "categories": ["q-bio.NC"], "comment": null, "summary": "Chronic upper extremity (UE) impairment is common after stroke. This study\nevaluated Boost, a novel wheelchair-mounted rehabilitation device designed to\nassist individuals in UE motor recovery during inpatient rehabilitation.\nThirty-five stroke inpatients were randomized to perform additional UE\nexercises alongside standard therapy, using either Boost or a\ntherapist-customized booklet for self-practice. Outcomes included the UE\nFugl-Meyer (UEFM) Exam, Box and Block Test, Motor Activity Log, Modified\nAshworth Scale, shoulder subluxation, and shoulder pain. At baseline, mean days\npost-stroke were 11.9$\\pm$4.6 and 13.1$\\pm$5.9, and UEFM scores were\n20.5$\\pm$10.1 and 21.0$\\pm$13.5. Intervention durations averaged 11.9$\\pm$4.0\nand 17.2$\\pm$8.8 days, respectively. Participants in the Boost group completed\n3,359$\\pm$3,137 additional arm movements. No significant between-group\ndifferences were found at the three-month follow-up. However, the Boost group\nshowed a trend toward greater UEFM improvement immediately post-intervention\n(11.8 vs. 6.9 points, p=0.06). Importantly, UEFM gains were predicted by the\nnumber of Boost exercises performed (p=0.02, R-square=0.34). Subgroup analysis\nrevealed that patients with less severe impairment (baseline UEFM >21) achieved\nsignificantly greater UEFM improvements at discharge with Boost compared to\ncontrols (15.8 vs. 7.8 points, p=0.01). These findings demonstrate the\nfeasibility of achieving thousands of additional UE practice movements while\nseated in a wheelchair without direct supervision during subacute\nrehabilitation. The added movement practice was well tolerated and may offer\nshort-term impairment-reduction benefits, particularly in those with less\nsevere impairment. Larger trials are needed to confirm efficacy, establish\noptimal dosage, and determine long-term clinical and functional benefits of\nBoost-assisted therapy."}
{"id": "2510.01428", "pdf": "https://arxiv.org/pdf/2510.01428", "abs": "https://arxiv.org/abs/2510.01428", "authors": ["Ching-Huei Tsou", "Michal Ozery-Flato", "Ella Barkan", "Diwakar Mahajan", "Ben Shapira"], "title": "BioVERSE: Representation Alignment of Biomedical Modalities to LLMs for Multi-Modal Reasoning", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) and biomedical foundation\nmodels (BioFMs) have achieved strong results in biological text reasoning,\nmolecular modeling, and single-cell analysis, yet they remain siloed in\ndisjoint embedding spaces, limiting cross-modal reasoning. We present BIOVERSE\n(Biomedical Vector Embedding Realignment for Semantic Engagement), a two-stage\napproach that adapts pretrained BioFMs as modality encoders and aligns them\nwith LLMs through lightweight, modality-specific projection layers. The\napproach first aligns each modality to a shared LLM space through independently\ntrained projections, allowing them to interoperate naturally, and then applies\nstandard instruction tuning with multi-modal data to bring them together for\ndownstream reasoning. By unifying raw biomedical data with knowledge embedded\nin LLMs, the approach enables zero-shot annotation, cross-modal question\nanswering, and interactive, explainable dialogue. Across tasks spanning\ncell-type annotation, molecular description, and protein function reasoning,\ncompact BIOVERSE configurations surpass larger LLM baselines while enabling\nricher, generative outputs than existing BioFMs, establishing a foundation for\nprincipled multi-modal biomedical reasoning."}
{"id": "2510.01864", "pdf": "https://arxiv.org/pdf/2510.01864", "abs": "https://arxiv.org/abs/2510.01864", "authors": ["Michaël Gillon"], "title": "A Modular Theory of Subjective Consciousness for Natural and Artificial Minds", "categories": ["q-bio.NC", "cs.AI"], "comment": "41 pages, 3 figures. Under review, comments welcome", "summary": "Understanding how subjective experience arises from information processing\nremains a central challenge in neuroscience, cognitive science, and AI\nresearch. The Modular Consciousness Theory (MCT) proposes a biologically\ngrounded and computationally explicit framework in which consciousness is a\ndiscrete sequence of Integrated Informational States (IISs). Each IIS is a\npacket of integrated information tagged with a multidimensional density vector\nthat quantifies informational richness. Its magnitude correlates with\nsubjective intensity, shaping memory, behavior, and continuity of experience.\nInputs from body and environment are adaptively filtered, processed by modules\n(abstraction, narration, evaluation, self-evaluation), and integrated into an\nIIS. The resulting packet, tagged with its density vector, is transmitted to\nbehavioral readiness, memory, and decision-making modules, closing the loop.\nThis explains why strongly tagged states exert greater influence on long-term\nmemory and action. Unlike Global Workspace Theory, Integrated Information\nTheory, or Higher-Order Thought, MCT specifies a full computational pipeline\nproducing discrete informational units with quantifiable internal structure.\nSubjectivity is reframed as a correlate of the density-tagging signal with\nfunctional consequences. MCT generates testable predictions, such as stress\nenhancing memory encoding, and provides a naturalistic blueprint for both\nbiological and artificial architectures. Consciousness, in this view, is not an\nirreducible essence but an evolvable, quantifiable, and constructible feature\nof complex information processing."}
{"id": "2510.01480", "pdf": "https://arxiv.org/pdf/2510.01480", "abs": "https://arxiv.org/abs/2510.01480", "authors": ["Ekaterina Podplutova", "Anastasia Vepreva", "Olga A. Konovalova", "Vladimir Vinogradov", "Dmitrii O. Shkil", "Andrei Dmitrenko"], "title": "Pharmacophore-Guided Generative Design of Novel Drug-Like Molecules", "categories": ["q-bio.QM", "cs.AI"], "comment": "AI4Mat-NeurIPS-2025 Poster", "summary": "The integration of artificial intelligence (AI) in early-stage drug discovery\noffers unprecedented opportunities for exploring chemical space and\naccelerating hit-to-lead optimization. However, docking optimization in\ngenerative approaches is computationally expensive and may lead to inaccurate\nresults. Here, we present a novel generative framework that balances\npharmacophore similarity to reference compounds with structural diversity from\nactive molecules. The framework allows users to provide custom reference sets,\nincluding FDA-approved drugs or clinical candidates, and guides the \\textit{de\nnovo} generation of potential therapeutics. We demonstrate its applicability\nthrough a case study targeting estrogen receptor modulators and antagonists for\nbreast cancer. The generated compounds maintain high pharmacophoric fidelity to\nknown active molecules while introducing substantial structural novelty,\nsuggesting strong potential for functional innovation and patentability.\nComprehensive evaluation of the generated molecules against common drug-like\nproperties confirms the robustness and pharmaceutical relevance of the\napproach."}
{"id": "2510.02182", "pdf": "https://arxiv.org/pdf/2510.02182", "abs": "https://arxiv.org/abs/2510.02182", "authors": ["Yule Wang", "Joseph Yu", "Chengrui Li", "Weihan Li", "Anqi Wu"], "title": "Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex with Mutual Information-Guided Diffusion", "categories": ["q-bio.NC", "cs.CV", "cs.LG"], "comment": null, "summary": "Understanding how neural populations in higher visual areas encode\nobject-centered visual information remains a central challenge in computational\nneuroscience. Prior works have investigated representational alignment between\nartificial neural networks and the visual cortex. Nevertheless, these findings\nare indirect and offer limited insights to the structure of neural populations\nthemselves. Similarly, decoding-based methods have quantified semantic features\nfrom neural populations but have not uncovered their underlying organizations.\nThis leaves open a scientific question: \"how feature-specific visual\ninformation is distributed across neural populations in higher visual areas,\nand whether it is organized into structured, semantically meaningful\nsubspaces.\" To tackle this problem, we present MIG-Vis, a method that leverages\nthe generative power of diffusion models to visualize and validate the\nvisual-semantic attributes encoded in neural latent subspaces. Our method first\nuses a variational autoencoder to infer a group-wise disentangled neural latent\nsubspace from neural populations. Subsequently, we propose a mutual information\n(MI)-guided diffusion synthesis procedure to visualize the specific\nvisual-semantic features encoded by each latent group. We validate MIG-Vis on\nmulti-session neural spiking datasets from the inferior temporal (IT) cortex of\ntwo macaques. The synthesized results demonstrate that our method identifies\nneural latent groups with clear semantic selectivity to diverse visual\nfeatures, including object pose, inter-category transformations, and\nintra-class content. These findings provide direct, interpretable evidence of\nstructured semantic representation in the higher visual cortex and advance our\nunderstanding of its encoding principles."}
{"id": "2510.01694", "pdf": "https://arxiv.org/pdf/2510.01694", "abs": "https://arxiv.org/abs/2510.01694", "authors": ["Tony Wong", "Ikchang Cho", "Maria R. D'Orsogna", "Tom Chou"], "title": "First passage times to T cell activation", "categories": ["q-bio.QM", "q-bio.CB", "35K57, 35Q92, 60J70, 92C17, 92C37"], "comment": null, "summary": "Effective recognition of foreign antigens by the adaptive immune system\nrelies on T cells being activated by antigen-presenting cells (APCs) in lymph\nnodes. Here, diffusing T cells may encounter cognate APCs that present matching\nantigen fragments or non-cognate ones that do not; they are also subject to\ndegradation. We develop a stochastic model in which T cell-APCs interact via a\nsequence of recognition steps, represented as a multistage Markov chain. T\ncells are successfully activated only if the terminal state associated with a\ncognate APC is reached. We compute the probability of successful activation in\nthe presence of interfering non-cognate APCs, T cell degradation, and lymph\nnode exit, and analyze the mean first-passage time to activation. We also\nincorporate a kinetic proofreading mechanism that enables state resetting, and\nshow how this enhances specificity toward cognate APCs."}
{"id": "2510.01858", "pdf": "https://arxiv.org/pdf/2510.01858", "abs": "https://arxiv.org/abs/2510.01858", "authors": ["Jacob J. W. Bakermans", "Pablo Tano", "Reidar Riveland", "Charles Findling", "Alexandre Pouget"], "title": "Compositional meta-learning through probabilistic task inference", "categories": ["cs.LG", "q-bio.NC"], "comment": null, "summary": "To solve a new task from minimal experience, it is essential to effectively\nreuse knowledge from previous tasks, a problem known as meta-learning.\nCompositional solutions, where common elements of computation are flexibly\nrecombined into new configurations, are particularly well-suited for\nmeta-learning. Here, we propose a compositional meta-learning model that\nexplicitly represents tasks as structured combinations of reusable\ncomputations. We achieve this by learning a generative model that captures the\nunderlying components and their statistics shared across a family of tasks.\nThis approach transforms learning a new task into a probabilistic inference\nproblem, which allows for finding solutions without parameter updates through\nhighly constrained hypothesis testing. Our model successfully recovers ground\ntruth components and statistics in rule learning and motor learning tasks. We\nthen demonstrate its ability to quickly infer new solutions from just single\nexamples. Together, our framework joins the expressivity of neural networks\nwith the data-efficiency of probabilistic inference to achieve rapid\ncompositional meta-learning."}
{"id": "2510.02037", "pdf": "https://arxiv.org/pdf/2510.02037", "abs": "https://arxiv.org/abs/2510.02037", "authors": ["Carlijn Lems", "Leslie Tessier", "John-Melle Bokhorst", "Mart van Rijthoven", "Witali Aswolinskiy", "Matteo Pozzi", "Natalie Klubickova", "Suzanne Dintzis", "Michela Campora", "Maschenka Balkenhol", "Peter Bult", "Joey Spronck", "Thomas Detone", "Mattia Barbareschi", "Enrico Munari", "Giuseppe Bogina", "Jelle Wesseling", "Esther H. Lips", "Francesco Ciompi", "Frédérique Meeuwsen", "Jeroen van der Laak"], "title": "A Multicentric Dataset for Training and Benchmarking Breast Cancer Segmentation in H&E Slides", "categories": ["q-bio.QM", "cs.CV", "eess.IV"], "comment": "Our dataset is available at https://zenodo.org/records/16812932 , our\n  code is available at https://github.com/DIAGNijmegen/beetle , and our\n  benchmark is available at https://beetle.grand-challenge.org/", "summary": "Automated semantic segmentation of whole-slide images (WSIs) stained with\nhematoxylin and eosin (H&E) is essential for large-scale artificial\nintelligence-based biomarker analysis in breast cancer. However, existing\npublic datasets for breast cancer segmentation lack the morphological diversity\nneeded to support model generalizability and robust biomarker validation across\nheterogeneous patient cohorts. We introduce BrEast cancEr hisTopathoLogy\nsEgmentation (BEETLE), a dataset for multiclass semantic segmentation of\nH&E-stained breast cancer WSIs. It consists of 587 biopsies and resections from\nthree collaborating clinical centers and two public datasets, digitized using\nseven scanners, and covers all molecular subtypes and histological grades.\nUsing diverse annotation strategies, we collected annotations across four\nclasses - invasive epithelium, non-invasive epithelium, necrosis, and other -\nwith particular focus on morphologies underrepresented in existing datasets,\nsuch as ductal carcinoma in situ and dispersed lobular tumor cells. The\ndataset's diversity and relevance to the rapidly growing field of automated\nbiomarker quantification in breast cancer ensure its high potential for reuse.\nFinally, we provide a well-curated, multicentric external evaluation set to\nenable standardized benchmarking of breast cancer segmentation models."}
{"id": "2510.01986", "pdf": "https://arxiv.org/pdf/2510.01986", "abs": "https://arxiv.org/abs/2510.01986", "authors": ["Varun Kotian", "Vishrut Jain", "Andrea Michelle Rios Lazcano", "Daan Marinus Pool", "Riender Happee", "Barys Shyrokau"], "title": "Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation", "categories": ["cs.RO", "cs.HC", "cs.SY", "eess.SY", "math.OC", "q-bio.NC", "I.6"], "comment": null, "summary": "Driving simulators are increasingly used in research and development.\nHowever, simulators often cause motion sickness due to downscaled motion and\nunscaled veridical visuals. In this paper, a motion cueing algorithm is\nproposed that reduces motion sickness as predicted by the subjective vertical\nconflict (SVC) model using model predictive control (MPC). Both sensory\nconflict and specific force errors are penalised in the cost function, allowing\nthe algorithm to jointly optimise fidelity and comfort.\n  Human-in-the-loop experiments were conducted to compare four simulator motion\nsettings: two variations of our MPC-based algorithm, one focused on pure\nspecific force tracking and the second compromising specific force tracking and\nmotion sickness minimisation, as well as reference adaptive washout and no\nmotion cases. The experiments were performed on a hexapod driving simulator\nwith participants exposed to passive driving.\n  Experimental motion sickness results closely matched the sickness model\npredictions. As predicted by the model, the no motion condition yielded the\nlowest sickness levels. However, it was rated lowest in terms of fidelity. The\ncompromise solution reduced sickness by over 50% (average MISC level 3 to 1.5)\ncompared to adaptive washout and the algorithm focusing on specific force\ntracking, without any significant reduction in fidelity rating.\n  The proposed approach for developing MCA that takes into account both the\nsimulator dynamics and time evolution of motion sickness offers a significant\nadvancement in achieving an optimal control of motion sickness and specific\nforce recreation in driving simulators, supporting broader simulator use."}
{"id": "2510.02139", "pdf": "https://arxiv.org/pdf/2510.02139", "abs": "https://arxiv.org/abs/2510.02139", "authors": ["Florensia Widjaja", "Zhangtianyi Chen", "Juexiao Zhou"], "title": "BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic Bioinformatics", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "cs.MA"], "comment": "20 pages, 8 figures, 3 tables", "summary": "Bioinformatics tools are essential for complex computational biology tasks,\nyet their integration with emerging AI-agent frameworks is hindered by\nincompatible interfaces, heterogeneous input-output formats, and inconsistent\nparameter conventions. The Model Context Protocol (MCP) provides a standardized\nframework for tool-AI communication, but manually converting hundreds of\nexisting and rapidly growing specialized bioinformatics tools into\nMCP-compliant servers is labor-intensive and unsustainable. Here, we present\nBioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter,\nwhich automatically generates robust MCP servers from tool documentation using\nlarge language models, and BioinfoMCP Benchmark, which systematically validates\nthe reliability and versatility of converted tools across diverse computational\ntasks. We present a platform of 38 MCP-converted bioinformatics tools,\nextensively validated to show that 94.7% successfully executed complex\nworkflows across three widely used AI-agent platforms. By removing technical\nbarriers to AI automation, BioinfoMCP enables natural-language interaction with\nsophisticated bioinformatics analyses without requiring extensive programming\nexpertise, offering a scalable path to intelligent, interoperable computational\nbiology."}
{"id": "2510.02120", "pdf": "https://arxiv.org/pdf/2510.02120", "abs": "https://arxiv.org/abs/2510.02120", "authors": ["Charalampos Lamprou", "Aamna Alshehhi", "Leontios J. Hadjileontiadis", "Mohamed L. Seghier"], "title": "VarCoNet: A variability-aware self-supervised framework for functional connectome extraction from resting-state fMRI", "categories": ["cs.NE", "cs.AI", "cs.LG", "q-bio.NC"], "comment": "My preview .pdf was not loading. Can you please share with me a\n  compiled .pdf file so I can confirm that the result is correct?", "summary": "Accounting for inter-individual variability in brain function is key to\nprecision medicine. Here, by considering functional inter-individual\nvariability as meaningful data rather than noise, we introduce VarCoNet, an\nenhanced self-supervised framework for robust functional connectome (FC)\nextraction from resting-state fMRI (rs-fMRI) data. VarCoNet employs\nself-supervised contrastive learning to exploit inherent functional\ninter-individual variability, serving as a brain function encoder that\ngenerates FC embeddings readily applicable to downstream tasks even in the\nabsence of labeled data. Contrastive learning is facilitated by a novel\naugmentation strategy based on segmenting rs-fMRI signals. At its core,\nVarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-series\nprocessing, enhanced with a robust Bayesian hyperparameter optimization. Our\nVarCoNet framework is evaluated on two downstream tasks: (i) subject\nfingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii)\nautism spectrum disorder (ASD) classification, using rs-fMRI data from the\nABIDE I and ABIDE II datasets. Using different brain parcellations, our\nextensive testing against state-of-the-art methods, including 13 deep learning\nmethods, demonstrates VarCoNet's superiority, robustness, interpretability, and\ngeneralizability. Overall, VarCoNet provides a versatile and robust framework\nfor FC analysis in rs-fMRI."}
{"id": "2510.01484", "pdf": "https://arxiv.org/pdf/2510.01484", "abs": "https://arxiv.org/abs/2510.01484", "authors": ["Michael B. Weissman"], "title": "Bayesian Re-Analysis of the Phylogenetic Topology of Early SARS-CoV-2 Case Sequences", "categories": ["q-bio.PE", "q-bio.QM"], "comment": "4642 words in main text", "summary": "A much-cited 2022 paper by Pekar et al. claimed that Bayesian analysis of the\nmolecular phylogeny of early SARS-CoV-2 cases indicated that it was more likely\nthat two successful introductions to humans had occurred than that just one\nhad. Here I show that after correcting a fundamental error in Bayesian\nreasoning the results in that paper give larger likelihood for a single\nintroduction than for two."}
{"id": "2510.01666", "pdf": "https://arxiv.org/pdf/2510.01666", "abs": "https://arxiv.org/abs/2510.01666", "authors": ["Jianxu Wang", "Ge Wang"], "title": "Median2Median: Zero-shot Suppression of Structured Noise in Images", "categories": ["eess.IV", "cs.CV", "q-bio.QM", "stat.ML"], "comment": "13 pages, 6 figures, not published yet", "summary": "Image denoising is a fundamental problem in computer vision and medical\nimaging. However, real-world images are often degraded by structured noise with\nstrong anisotropic correlations that existing methods struggle to remove. Most\ndata-driven approaches rely on large datasets with high-quality labels and\nstill suffer from limited generalizability, whereas existing zero-shot methods\navoid this limitation but remain effective only for independent and identically\ndistributed (i.i.d.) noise. To address this gap, we propose Median2Median\n(M2M), a zero-shot denoising framework designed for structured noise. M2M\nintroduces a novel sampling strategy that generates pseudo-independent\nsub-image pairs from a single noisy input. This strategy leverages directional\ninterpolation and generalized median filtering to adaptively exclude values\ndistorted by structured artifacts. To further enlarge the effective sampling\nspace and eliminate systematic bias, a randomized assignment strategy is\nemployed, ensuring that the sampled sub-image pairs are suitable for\nNoise2Noise training. In our realistic simulation studies, M2M performs on par\nwith state-of-the-art zero-shot methods under i.i.d. noise, while consistently\noutperforming them under correlated noise. These findings establish M2M as an\nefficient, data-free solution for structured noise suppression and mark the\nfirst step toward effective zero-shot denoising beyond the strict i.i.d.\nassumption."}
