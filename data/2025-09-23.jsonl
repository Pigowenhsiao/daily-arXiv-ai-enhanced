{"id": "2509.16301", "pdf": "https://arxiv.org/pdf/2509.16301", "abs": "https://arxiv.org/abs/2509.16301", "authors": ["Tiantian Yang", "Zhiqian Chen"], "title": "TF-DWGNet: A Directed Weighted Graph Neural Network with Tensor Fusion for Multi-Omics Cancer Subtype Classification", "categories": ["q-bio.QM", "cs.LG", "62R07"], "comment": "9 pages, 4 figures, 4 tables", "summary": "Integration and analysis of multi-omics data provide valuable insights for\ncancer subtype classification. However, such data are inherently heterogeneous,\nhigh-dimensional, and exhibit complex intra- and inter-modality dependencies.\nRecent advances in graph neural networks (GNNs) offer powerful tools for\nmodeling such structure. Yet, most existing methods rely on prior knowledge or\npredefined similarity networks to construct graphs, which are often undirected\nor unweighted, failing to capture the directionality and strength of biological\ninteractions. Interpretability at both the modality and feature levels also\nremains limited. To address these challenges, we propose TF-DWGNet, a novel\nGraph Neural Network framework that combines tree-based Directed Weighted graph\nconstruction with Tensor Fusion for multiclass cancer subtype classification.\nTF-DWGNet introduces two key innovations: a supervised tree-based approach for\nconstructing directed, weighted graphs tailored to each omics modality, and a\ntensor fusion mechanism that captures unimodal, bimodal, and trimodal\ninteractions using low-rank decomposition for efficiency. TF-DWGNet enables\nmodality-specific representation learning, joint embedding fusion, and\ninterpretable subtype prediction. Experiments on real-world cancer datasets\nshow that TF-DWGNet consistently outperforms state-of-the-art baselines across\nmultiple metrics and statistical tests. Moreover, it provides biologically\nmeaningful insights by ranking influential features and modalities. These\nresults highlight TF-DWGNet's potential for effective and interpretable\nmulti-omics integration in cancer research."}
{"id": "2509.16486", "pdf": "https://arxiv.org/pdf/2509.16486", "abs": "https://arxiv.org/abs/2509.16486", "authors": ["Travis E. Gibson"], "title": "Comment on \"mbtransfer: Microbiome intervention analysis using transfer functions and mirror statistics\": Implementation errors, theoretical misapplication, and methodological flaws", "categories": ["q-bio.QM"], "comment": "10 pages, 2 figures. Comment on arXiv:2306.06364, with the published\n  version in PLOS Computational Biology as doi:10.1371/journal.pcbi.1012196", "summary": "There are a number of errors in \"mbtransfer: Microbiome intervention analysis\nusing transfer functions and mirror statistics\" PLOS Comp Bio (2024) spanning\nmultiple aspects of the paper. The wrong inputs were provided to comparator\nmethods for model training, when forecasting one method was provided initial\nconditions in the wrong units, and performance metrics were calculated without\nproper unit conversion. The false discovery rate and power analysis conclusions\nprovided in the text are not supported by theory or the empirical testing that\nwas performed within the paper. The paper also has data leakage issues,\nequations are written down incorrectly, and incorrect definitions/terminology\nare used."}
{"id": "2509.16571", "pdf": "https://arxiv.org/pdf/2509.16571", "abs": "https://arxiv.org/abs/2509.16571", "authors": ["R. He"], "title": "Enhancing Antimicrobial Molecule Prediction via Dynamic Routing Capsule Networks and Multi-Source Molecular Embeddings", "categories": ["q-bio.QM"], "comment": null, "summary": "Antibiotics are a vital class of drugs closely associated with the prevention\nand treatment of bacterial infections. Accurate prediction of molecular\nantimicrobial activity remains a key challenge in the pursuit of novel\nantibiotic candidates. However, laboratory-based antimicrobial compounds\nidentification is costly, time-consuming, and prone to rediscovering known\nantibiotics, highlighting the urgent need for efficient and accurate\ncomputational models. Recent advances in machine learning (ML) and deep\nlearning (DL) have significantly enhanced the ability to explore chemical space\nand identify potential antimicrobial compounds. In this study, we particularly\nemphasize deep learning models and employ five chemistry language models\ntailored for chemical data to encode small molecules. Our model incorporates a\nunique capsule network architecture and introduces innovations in loss function\nselection and feature processing modules, demonstrating superior performance in\npredicting inhibitory activities against Escherichia coli and Acinetobacter\nbaumannii. We conducted a series of ablation studies to elucidate the\ncontributions of network design and input features. Case studies validated the\nusability and effectiveness of our model.To facilitate accessibility, we\ndeveloped an intuitive web portal to disseminate this novel tool. Our results\nindicate that the proposed approach offers improved predictive accuracy and\nenhanced interpretability, underscoring the potential of interpretable\nartificial intelligence methods in accelerating antibiotic discovery and\naddressing the urgent challenge of antimicrobial resistance."}
{"id": "2509.16908", "pdf": "https://arxiv.org/pdf/2509.16908", "abs": "https://arxiv.org/abs/2509.16908", "authors": ["Sixtus Dakurah"], "title": "Discrete Heat Kernels on Simplicial Complexes and Its Application to Functional Brain Networks", "categories": ["q-bio.QM", "q-bio.NC"], "comment": null, "summary": "Networks constitute fundamental organizational structures across biological\nsystems, although conventional graph-theoretic analyses capture exclusively\npairwise interactions, thereby omitting the intricate higher-order\nrelationships that characterize network complexity. This work proposes a\nunified framework for heat kernel smoothing on simplicial complexes, extending\nclassical signal processing methodologies from vertices and edges to cycles and\nhigher-dimensional structures. Through Hodge Laplacian, a discrete heat kernel\non a finite simplicial complex $\\mathcal{K}$ is constructed to smooth signals\non $k$-simplices via the boundary operator $\\partial_k$. Computationally\nefficient sparse algorithms for constructing boundary operators are developed\nto implement linear diffusion processes on $k$-simplices. The methodology\ngeneralizes heat kernel smoothing to $k$-simplices, utilizing boundary\nstructure to localize topological features while maintaining homological\ninvariance. Simulation studies demonstrate qualitative signal enhancement\nacross vertex and edge domains following diffusion processes. Application to\nparcellated human brain functional connectivity networks reveals that\nsimplex-space smoothing attenuates spurious connections while amplifying\ncoherent anatomical architectures, establishing practical significance for\ncomputational neuroscience applications."}
{"id": "2509.16661", "pdf": "https://arxiv.org/pdf/2509.16661", "abs": "https://arxiv.org/abs/2509.16661", "authors": ["Liav Daraf", "Yael Lavi", "Areej Saleem", "Daniel Sevilla Sanchez", "Yuri Feldman", "Lior Atia"], "title": "Cycling and tensed cells interpenetrated by non-cycling and compressed cells form a critical epithelial reticulum", "categories": ["q-bio.CB", "cond-mat.soft", "nlin.AO", "physics.bio-ph", "q-bio.TO"], "comment": "Supplementary video links are available on the video description\n  pages", "summary": "With the completion of development and wound repair, as the epithelium\napproaches homeostasis, cell proliferation is reduced to a minimum. In\nparallel, cellular motion transitions from a migratory unjammed state to a\nquiescent jammed state. This quiescent state is commonly regarded as devoid of\nlarge-scale regional variations in cell-cycle re-entry and cellular mechanics.\nTo the contrary, here we report that during late maturation there arises a\nheretofore unanticipated epithelial reticulum that is supracellular and spans\nmultiple scales of length. This reticulum evolves dynamically and comprises two\ninterpenetrating networks: large regions of cycling and mechanically tensed\ncells, embedded with islands of non-cycling and mechanically compressed cells.\nThe islands of compressed cells emerge and grow in cell numbers, with gradual\njamming and with reduced cellular rearrangements. We show how island growth is\nboth reversible, by provoking unjamming, and detainable, by cell cycle arrest\ntreatment. Moreover, the distribution of island sizes was found to conform to a\npower-law, thus leading us to employ a computational model of percolating\ncritical networks. Together, the observations indicate that the newly\ndiscovered epithelial reticulum self-organizes close to but just shy of\ncriticality - thus avoiding mergers of compressed cell islands. This\nquasi-criticality reframes epithelial homeostasis as a dynamic regional balance\nof forces and proliferation."}
{"id": "2509.16284", "pdf": "https://arxiv.org/pdf/2509.16284", "abs": "https://arxiv.org/abs/2509.16284", "authors": ["Adrija Datta", "Subramanian Sankaranarayanan", "Udit Bhatia"], "title": "Temporally staggered cropping co-benefits beneficial insects and pest control globally", "categories": ["q-bio.PE"], "comment": null, "summary": "Reconciling increasing food production with biodiversity conservation is\ncritical yet challenging, particularly given global declines in beneficial\ninsects driven by monoculture intensification. Intercropping, the simultaneous\nor sequential cultivation of multiple crops, has been proposed as a viable\nstrategy to enhance beneficial insect services and suppress pests, yet global\nevidence regarding optimal spatiotemporal intercropping configurations remains\nfragmented. Here, we synthesize results from 7,584 field experiments spanning\nsix continents and 22 Koppen climate regions, evaluating effects of spatial\n(row, strip, mixed, agroforestry) and temporal (additive, replacement, relay)\nintercropping configuations on beneficial insect (predators, parasitoids,\npollinators) abundance and pest suppression using the Management Efficiency\nRatio (MER; log ratio of abundance in intercropping versus monoculture). Relay\nintercropping, characterized by temporally staggered planting, emerged as the\nuniversally optimal temporal configuration, substantially increasing predator\n(MER = 0.473) and parasitoid populations (MER = 0.512) and effectively\nsuppressing pests (MER = -0.611) globally. At regional scales, identical\nspatiotemporal configurations simultaneously optimized beneficial insect\npredator abundance and pest suppression in 57% of regions, while other regions\nrequired distinct, insect-specific approaches. Our findings highlight relay\nintercropping as a globally generalizable solution, but underscore regional\nvariation that calls for targeted policies to simultaneously secure food\nproduction and biodiversity conservation."}
{"id": "2509.16250", "pdf": "https://arxiv.org/pdf/2509.16250", "abs": "https://arxiv.org/abs/2509.16250", "authors": ["Saifuddin Sagor", "Md Taimur Ahad", "Faruk Ahmed", "Rokonozzaman Ayon", "Sanzida Parvin"], "title": "A study on Deep Convolutional Neural Networks, transfer learning, and Mnet model for Cervical Cancer Detection", "categories": ["q-bio.TO", "cs.AI", "cs.CV"], "comment": null, "summary": "Early and accurate detection through Pap smear analysis is critical to\nimproving patient outcomes and reducing mortality of Cervical cancer.\nState-of-the-art (SOTA) Convolutional Neural Networks (CNNs) require\nsubstantial computational resources, extended training time, and large\ndatasets. In this study, a lightweight CNN model, S-Net (Simple Net), is\ndeveloped specifically for cervical cancer detection and classification using\nPap smear images to address these limitations. Alongside S-Net, six SOTA CNNs\nwere evaluated using transfer learning, including multi-path (DenseNet201,\nResNet152), depth-based (Serasnet152), width-based multi-connection (Xception),\ndepth-wise separable convolutions (MobileNetV2), and spatial exploitation-based\n(VGG19). All models, including S-Net, achieved comparable accuracy, with S-Net\nreaching 99.99%. However, S-Net significantly outperforms the SOTA CNNs in\nterms of computational efficiency and inference time, making it a more\npractical choice for real-time and resource-constrained applications. A major\nlimitation in CNN-based medical diagnosis remains the lack of transparency in\nthe decision-making process. To address this, Explainable AI (XAI) techniques,\nsuch as SHAP, LIME, and Grad-CAM, were employed to visualize and interpret the\nkey image regions influencing model predictions. The novelty of this study lies\nin the development of a highly accurate yet computationally lightweight model\n(S-Net) caPable of rapid inference while maintaining interpretability through\nXAI integration. Furthermore, this work analyzes the behavior of SOTA CNNs,\ninvestigates the effects of negative transfer learning on Pap smear images, and\nexamines pixel intensity patterns in correctly and incorrectly classified\nsamples."}
{"id": "2509.16229", "pdf": "https://arxiv.org/pdf/2509.16229", "abs": "https://arxiv.org/abs/2509.16229", "authors": ["Ildar Rakhmatulin"], "title": "Low-Cost Shield MicroBCI to Measure EEG with STM32", "categories": ["q-bio.NC"], "comment": null, "summary": "The article introduces an accessible pathway into neuroscience using the\nMicroBCI device, which leverages the STM32 Nucleo-55RG development board as the\ncore platform. MicroBCI enables the STM32 board to function as a brain-computer\ninterface, capable of recording EEG, EMG, and ECG signals across 8 channels.\nOver the past decade, the rapid growth of artificial intelligence has\ntransformed many fields, including neurobiology. The application of machine\nlearning methods has created opportunities for the practical use of EEG signals\nin diverse technological domains. This growing interest has fueled the\npopularity of affordable brain-computer interface systems that utilize\nnon-invasive electrodes for EEG acquisition. The MicroBCI device demonstrates\nreliable noise performance and accuracy for applied research and prototyping.\nFurthermore, it effectively detects alpha brain waves, confirming its ability\nto capture key neurological signals."}
{"id": "2509.17594", "pdf": "https://arxiv.org/pdf/2509.17594", "abs": "https://arxiv.org/abs/2509.17594", "authors": ["Erika M. Herrera Machado", "Jakob L. Andersen", "Rolf Fagerberg", "Daniel Merkle"], "title": "A Sensitivity Analysis Methodology For Rule-Based Stochastic Chemical Systems", "categories": ["q-bio.QM", "q-bio.MN"], "comment": null, "summary": "In this study, we introduce a sensitivity analysis methodology for stochastic\nsystems in chemistry, where dynamics are often governed by random processes.\nOur approach is based on gradient estimation via finite differences, averaging\nsimulation outcomes, and analyzing variability under intrinsic noise. We\ncharacterize gradient uncertainty as an angular range within which all\nplausible gradient directions are expected to lie. This uncertainty measure\nadaptively guides the number of simulations performed for each\nnominal-perturbation pair of points in order to minimize unnecessary\ncomputations while maintaining robustness.\n  Systematically exploring a range of parameter values across the parameter\nspace, rather than focusing on a single value, allows us to identify not only\nsensitive parameters but also regions of parameter space associated with\ndifferent levels of sensitivity. These results are visualized through vector\nfield plots to offer an intuitive representation of local sensitivity across\nparameter space. Additionally, global sensitivity coefficients are computed to\ncapture overall trends.\n  Flexibility regarding the choice of output observable measures is another key\nfeature of our method: while traditional sensitivity analyses often focus on\nspecies concentrations, our framework allows for the definition of a large\nrange of problem-specific observables. This makes it broadly applicable in\ndiverse chemical and biochemical scenarios. We demonstrate our approach on two\nsystems: classical Michaelis-Menten kinetics and a rule-based model of the\nformose reaction, using the cheminformatics software M{\\O}D for Gillespie-based\nstochastic simulations."}
{"id": "2509.16385", "pdf": "https://arxiv.org/pdf/2509.16385", "abs": "https://arxiv.org/abs/2509.16385", "authors": ["Luis F. Gordillo", "Priscilla E. Greenwood"], "title": "Parameter variability can produce heavy tails in a model for the spatial distribution of settling organisms", "categories": ["q-bio.PE", "stat.AP"], "comment": null, "summary": "We show that a simple mechanistic model of spatial dispersal for settling\norganisms, subject to parameter variability, can generate heavy-tailed radial\nprobability density functions. The movement of organisms in the model consists\nof a two-dimensional diffusion that ceases after a random time, where the\nparameters that characterize each of these stages have been randomized. Our\nfindings show that these minimal assumptions can yield heavy-tailed dispersal\npatterns, providing a simplified framework that increases the understanding of\nlong-distance dispersal events in movement ecology."}
{"id": "2509.16251", "pdf": "https://arxiv.org/pdf/2509.16251", "abs": "https://arxiv.org/abs/2509.16251", "authors": ["Rokonozzaman Ayon", "Md Taimur Ahad", "Bo Song", "Yan Li"], "title": "R-Net: A Reliable and Resource-Efficient CNN for Colorectal Cancer Detection with XAI Integration", "categories": ["q-bio.TO", "cs.AI", "cs.CV"], "comment": null, "summary": "State-of-the-art (SOTA) Convolutional Neural Networks (CNNs) are criticized\nfor their extensive computational power, long training times, and large\ndatasets. To overcome this limitation, we propose a reasonable network (R-Net),\na lightweight CNN only to detect and classify colorectal cancer (CRC) using the\nEnteroscope Biopsy Histopathological Hematoxylin and Eosin Image Dataset\n(EBHI). Furthermore, six SOTA CNNs, including Multipath-based CNNs\n(DenseNet121, ResNet50), Depth-based CNNs (InceptionV3), width-based\nmulti-connection CNNs (Xception), depth-wise separable convolutions\n(MobileNetV2), spatial exploitation-based CNNs (VGG16), Transfer learning, and\ntwo ensemble models are also tested on the same dataset. The ensemble models\nare a multipath-depth-width combination (DenseNet121-InceptionV3-Xception) and\na multipath-depth-spatial combination (ResNet18-InceptionV3-VGG16). However,\nthe proposed R-Net lightweight achieved 99.37% accuracy, outperforming\nMobileNet (95.83%) and ResNet50 (96.94%). Most importantly, to understand the\ndecision-making of R-Net, Explainable AI such as SHAP, LIME, and Grad-CAM are\nintegrated to visualize which parts of the EBHI image contribute to the\ndetection and classification process of R-Net. The main novelty of this\nresearch lies in building a reliable, lightweight CNN R-Net that requires fewer\ncomputing resources yet maintains strong prediction results. SOTA CNNs,\ntransfer learning, and ensemble models also extend our knowledge on CRC\nclassification and detection. XAI functionality and the impact of pixel\nintensity on correct and incorrect classification images are also some\nnovelties in CRC detection and classification."}
{"id": "2509.16232", "pdf": "https://arxiv.org/pdf/2509.16232", "abs": "https://arxiv.org/abs/2509.16232", "authors": ["Yue Jin"], "title": "Emotions are Recognized Patterns of Cognitive Activities", "categories": ["q-bio.NC", "cs.HC", "I.2.0"], "comment": "10 pages, 7 figures", "summary": "Emotions play a crucial role in human life. The research community has\nproposed many theories on emotions without reaching much consensus. The\nsituation is similar for emotions in cognitive architectures and autonomous\nagents. I propose in this paper that emotions are recognized patterns of\ncognitive activities. These activities are responses of an agent to the\ndeviations between the targets of its goals and the performances of its\nactions. Emotions still arise even if these activities are purely logical. I\nmap the patterns of cognitive activities to emotions. I show the link between\nemotions and attention and the impacts of the parameterized functions in the\ncognitive architecture on the computing of emotions. My proposition bridges\ndifferent theories on emotions and advances the building of consensus."}
{"id": "2509.18050", "pdf": "https://arxiv.org/pdf/2509.18050", "abs": "https://arxiv.org/abs/2509.18050", "authors": ["Katherina Cortes", "Daniel Korn", "Sarah Gehrke", "Kevin Schaper", "Corey Cox", "Patrick Golden", "Aaron Odell", "Bryan Laraway", "Madan Krishnamurthy", "Justin Reese", "Harry Caufield", "Sierra Moxon", "Ellen Elias", "Christopher J Mungall", "Melissa Haendel"], "title": "Why we need all the organisms: an exploration of the Monarch knowledge graph to aid mechanism discovery", "categories": ["q-bio.QM"], "comment": null, "summary": "Research done using model organisms has been fundamental to the biological\nunderstanding of human genes, diseases and phenotypes. Model organisms provide\ntractable systems for experiments to enhance understanding of biological\nmechanisms conserved across the evolutionary tree. Decades of model organism\nresearch has generated vast amounts of data; however, this data is split across\nmany domains, organisms, and biological fields of research. Knowledge graphs\n(KGs) are a computational way to aggregate and compile disparate information in\na parsable format. By unifying data across studies, organisms and time points,\nKG researchers can create novel targeted hypotheses. Here we demonstrate how\nmodel organisms are connected to humans and other organisms through genes,\ndiseases and phenotypes allowing for a broader understanding of genetic biology\nthan just one organism alone can provide. Utilizing resources such as the\nMonarch KG is a great way to reduce redundant experiments and find directions\npreviously unexplored."}
{"id": "2509.16405", "pdf": "https://arxiv.org/pdf/2509.16405", "abs": "https://arxiv.org/abs/2509.16405", "authors": ["Alexey Markin", "Tavis K. Anderson"], "title": "Ordered Leaf Attachment (OLA) Vectors can Identify Reticulation Events even in Multifurcated Trees", "categories": ["q-bio.PE", "cs.DS", "math.CO", "05C05, 68R10, 92B10", "F.2.2; G.2.1; G.2.2"], "comment": "18 pages, 4 figures", "summary": "Recently, a new vector encoding, Ordered Leaf Attachment (OLA), was\nintroduced that represents $n$-leaf phylogenetic trees as $n-1$ length integer\nvectors by recording the placement location of each leaf. Both encoding and\ndecoding of trees run in linear time and depend on a fixed ordering of the\nleaves. Here, we investigate the connection between OLA vectors and the maximum\nacyclic agreement forest (MAAF) problem. A MAAF represents an optimal breakdown\nof $k$ trees into reticulation-free subtrees, with the roots of these subtrees\nrepresenting reticulation events. We introduce a corrected OLA distance index\nover OLA vectors of $k$ trees, which is easily computable in linear time. We\nprove that the corrected OLA distance corresponds to the size of a MAAF, given\nan optimal leaf ordering that minimizes that distance. Additionally, a MAAF can\nbe easily reconstructed from optimal OLA vectors. We expand these results to\nmultifurcated trees: we introduce an $O(kn \\cdot m\\log m)$ algorithm that\noptimally resolves a set of multifurcated trees given a leaf-ordering, where\n$m$ is the size of a largest multifurcation, and show that trees resolved via\nthis algorithm also minimize the size of a MAAF. These results suggest a new\napproach to fast computation of phylogenetic networks and identification of\nreticulation events via random permutations of leaves. Additionally, in the\ncase of microbial evolution, a natural ordering of leaves is often given by the\nsample collection date, which means that under mild assumptions, reticulation\nevents can be identified in polynomial time on such datasets."}
{"id": "2509.16254", "pdf": "https://arxiv.org/pdf/2509.16254", "abs": "https://arxiv.org/abs/2509.16254", "authors": ["Sajim Ahmed", "Muhammad Zain Chaudhary", "Muhammad Zohaib Chaudhary", "Mahmoud Abbass", "Ahmed Sherif", "Mohammad Mahbubur Rahman Khan Mamun"], "title": "Imaging Modalities-Based Classification for Lung Cancer Detection", "categories": ["q-bio.TO", "cs.AI", "68T07, 92C55"], "comment": "Accepted at ICMI 2025", "summary": "Lung cancer continues to be the predominant cause of cancer-related mortality\nglobally. This review analyzes various approaches, including advanced image\nprocessing methods, focusing on their efficacy in interpreting CT scans, chest\nradiographs, and biological markers. Notably, we identify critical gaps in the\nprevious surveys, including the need for robust models that can generalize\nacross diverse populations and imaging modalities. This comprehensive synthesis\naims to serve as a foundational resource for researchers and clinicians,\nguiding future efforts toward more accurate and efficient lung cancer\ndetection. Key findings reveal that 3D CNN architectures integrated with CT\nscans achieve the most superior performances, yet challenges such as high false\npositives, dataset variability, and computational complexity persist across\nmodalities."}
{"id": "2509.16238", "pdf": "https://arxiv.org/pdf/2509.16238", "abs": "https://arxiv.org/abs/2509.16238", "authors": ["Xiaoqi Sheng", "Jiawen Liu", "Jiaming Liang", "Yiheng Zhang", "Hongmin Cai"], "title": "Evolvable Graph Diffusion Optimal Transport with Pattern-Specific Alignment for Brain Connectome Modeling", "categories": ["q-bio.NC", "cs.GR"], "comment": null, "summary": "Network analysis of human brain connectivity indicates that individual\ndifferences in cognitive abilities arise from neurobiological mechanisms\ninherent in structural and functional brain networks. Existing studies\nroutinely treat structural connectivity (SC) as optimal or fixed topological\nscaffolds for functional connectivity (FC), often overlooking higher-order\ndependencies between brain regions and limiting the modeling of complex\ncognitive processes. Besides, the distinct spatial organizations of SC and FC\ncomplicate direct integration, as naive alignment may distort intrinsic\nnonlinear patterns of brain connectivity. In this study, we propose a novel\nframework called Evolvable Graph Diffusion Optimal Transport with\nPattern-Specific Alignment (EDT-PA), designed to identify disease-specific\nconnectome patterns and classify brain disorders. To accurately model\nhigh-order structural dependencies, EDT-PA incorporates a spectrum of evolvable\nmodeling blocks to dynamically capture high-order dependencies across brain\nregions. Additionally, a Pattern-Specific Alignment mechanism employs optimal\ntransport to align structural and functional representations in a\ngeometry-aware manner. By incorporating a Kolmogorov-Arnold network for\nflexible node aggregation, EDT-PA is capable of modeling complex nonlinear\ninteractions among brain regions for downstream classification. Extensive\nevaluations on the REST-meta-MDD and ADNI datasets demonstrate that EDT-PA\noutperforms state-of-the-art methods, offering a more effective framework for\nrevealing structure-function misalignments and disorder-specific subnetworks in\nbrain disorders. The project of this work is released via this link."}
{"id": "2509.16629", "pdf": "https://arxiv.org/pdf/2509.16629", "abs": "https://arxiv.org/abs/2509.16629", "authors": ["Kaichen Xu", "Yihang Du", "Mianpeng Liu", "Zimu Yu", "Xiaobo Sun"], "title": "Causality-Induced Positional Encoding for Transformer-Based Representation Learning of Non-Sequential Features", "categories": ["cs.LG", "q-bio.QM"], "comment": "Accepted by NeurIPS 2025", "summary": "Positional encoding is essential for supplementing transformer with\npositional information of tokens. Existing positional encoding methods demand\npredefined token/feature order, rendering them unsuitable for real-world data\nwith non-sequential yet causally-related features. To address this limitation,\nwe propose CAPE, a novel method that identifies underlying causal structure\nover non-sequential features as a weighted directed acyclic graph (DAG) using\ngeneralized structural equation modeling. The DAG is then embedded in\nhyperbolic space where its geometric structure is well-preserved using a\nhyperboloid model-based approach that effectively captures two important causal\ngraph properties (causal strength & causal specificity). This step yields\ncausality-aware positional encodings for the features, which are converted into\ntheir rotary form for integrating with transformer's self-attention mechanism.\nTheoretical analysis reveals that CAPE-generated rotary positional encodings\npossess three valuable properties for enhanced self-attention, including causal\ndistance-induced attenuation, causal generality-induced attenuation, and\nrobustness to positional disturbances. We evaluate CAPE over both synthetic and\nreal-word datasets, empirically demonstrating its theoretical properties and\neffectiveness in enhancing transformer for data with non-sequential features.\nOur code is available at https://github.com/Catchxu/CAPE."}
{"id": "2509.16687", "pdf": "https://arxiv.org/pdf/2509.16687", "abs": "https://arxiv.org/abs/2509.16687", "authors": ["Uzzwal Kumar Mallick", "Jobayer Ahmed", "Khan Anik Islam", "Pulak Kundu"], "title": "Modeling the Effects of Over and Under Doses Antibiotic Treatment to Bacterial Resistance in Presence of Immune System", "categories": ["q-bio.PE", "37N25, 92B05"], "comment": null, "summary": "Antibiotic resistance presents a growing global health threat by diminishing\nthe effectiveness of treatments and allowing once-manageable bacterial\ninfections to persist. This study develops and analyzes an optimization-based\nmathematical model to investigate the impact of varying antibiotic dosages on\nbacterial resistance, incorporating the role of the immune system.\nAdditionally, to capture the effects of over and underdosing, a floor function\nis newly introduced into the model as a switch function. The model is examined\nboth analytically and numerically. As part of the analytical solution, the\nvalidity of the model through the existence and uniqueness theorem, stability\nat the equilibrium points, and characteristics of equilibrium points in\nrelation to state variables have been investigated. Numerical simulations,\nperformed using the Runge Kutta 4th order method, reveal that while antibiotics\neffectively reduce sensitive bacteria, they simultaneously increase resistant\nstrains and suppress immune cell levels. The results also demonstrate that\nunderdosing antibiotics increases the risk of resistance through bacterial\nmutation, while overdosing weakens the immune system by disrupting beneficial\nmicrobes. These findings emphasize that improper dosing whether below or above\nthe prescribed level can accelerate the development of antibiotic resistance,\nunderscoring the need for carefully regulated treatment strategies that\npreserve both antimicrobial effectiveness and immune system integrity."}
{"id": "2509.16255", "pdf": "https://arxiv.org/pdf/2509.16255", "abs": "https://arxiv.org/abs/2509.16255", "authors": ["Katerina Krejci", "Jiri Chmelik", "Sandrine BÃ©dard", "Falk Eippert", "Ulrike Horn", "Virginie Callot", "Julien Cohen-Adad", "Jan Valosek"], "title": "RootletSeg: Deep learning method for spinal rootlets segmentation across MRI contrasts", "categories": ["q-bio.TO", "eess.IV", "physics.med-ph"], "comment": "26 pages, 6 figures, 4 tables", "summary": "Purpose: To develop a deep learning method for the automatic segmentation of\nspinal nerve rootlets on various MRI scans. Material and Methods: This\nretrospective study included MRI scans from two open-access and one private\ndataset, consisting of 3D isotropic 3T TSE T2-weighted (T2w) and 7T MP2RAGE\n(T1-weighted [T1w] INV1 and INV2, and UNIT1) MRI scans. A deep learning model,\nRootletSeg, was developed to segment C2-T1 dorsal and ventral spinal rootlets.\nTraining was performed on 76 scans and testing on 17 scans. The Dice score was\nused to compare the model performance with an existing open-source method.\nSpinal levels derived from RootletSeg segmentations were compared with\nvertebral levels defined by intervertebral discs using Bland-Altman analysis.\nResults: The RootletSeg model developed on 93 MRI scans from 50 healthy adults\n(mean age, 28.70 years $\\pm$ 6.53 [SD]; 28 [56%] males, 22 [44%] females)\nachieved a mean $\\pm$ SD Dice score of 0.67 $\\pm$ 0.09 for T1w-INV2, 0.65 $\\pm$\n0.11 for UNIT1, 0.64 $\\pm$ 0.08 for T2w, and 0.62 $\\pm$ 0.10 for T1w-INV1\ncontrasts. Spinal-vertebral level correspondence showed a progressively\nincreasing rostrocaudal shift, with Bland-Altman bias ranging from 0.00 to 8.15\nmm (median difference between level midpoints). Conclusion: RootletSeg\naccurately segmented C2-T1 spinal rootlets across MRI contrasts, enabling the\ndetermination of spinal levels directly from MRI scans. The method is\nopen-source and can be used for a variety of downstream analyses, including\nlesion classification, neuromodulation therapy, and functional MRI group\nanalysis."}
{"id": "2509.16253", "pdf": "https://arxiv.org/pdf/2509.16253", "abs": "https://arxiv.org/abs/2509.16253", "authors": ["Andrei Khrennikov", "Makiko Yamada"], "title": "Quantum-like representation of neuronal networks' activity: modeling \"mental entanglement\"", "categories": ["q-bio.NC", "quant-ph"], "comment": null, "summary": "Quantum-like modeling (QLM) - quantum theory applications outside of physics\n- are intensively developed with applications in biology, cognition,\npsychology, and decision-making. For cognition, QLM should be distinguished\nfrom quantum reductionist models in the spirit of Hameroff and Penrose and well\nas Umezawa and Vitiello. QLM is not concerned with just quantum physical\nprocesses in the brain but also QL information processing by macroscopic\nneuronal structures. Although QLM of cognition and decision-making has seen\nsome success, it suffers from a knowledge gap that exists between oscillatory\nneuronal network functioning in the brain and QL behavioral patterns. Recently,\nsteps toward closing this gap have been taken using the generalized probability\ntheory and prequantum classical statistical field theory (PCSFT) - a random\nfield model beyond the complex Hilbert space formalism. PCSFT is used to move\nfrom the classical ``oscillatory cognition'' of the neuronal networks to QLM\nfor decision.making. In this study, we addressed the most difficult problem\nwithin this construction: QLM for entanglement generation by classical\nnetworks, i.e., mental entanglement. We started with the observational approach\nto entanglement based on operator algebras describing local observables and\nbringing into being the tensor product structure in the space of QL states.\nMoreover, we applied the standard states entanglement approach: entanglement\ngeneration by spatially separated networks in the brain. Finally, we discussed\npossible future experiments on mental entanglement detection using the EEG/MEG\ntechnique."}
{"id": "2509.17174", "pdf": "https://arxiv.org/pdf/2509.17174", "abs": "https://arxiv.org/abs/2509.17174", "authors": ["Kijung Yoon"], "title": "Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks", "categories": ["q-bio.NC", "cs.LG", "q-bio.QM"], "comment": "To appear in NeurIPS 2025", "summary": "Inferring synaptic connectivity from neural population activity is a\nfundamental challenge in computational neuroscience, complicated by partial\nobservability and mismatches between inference models and true circuit\ndynamics. In this study, we propose a graph-based neural inference model that\nsimultaneously predicts neural activity and infers latent connectivity by\nmodeling neurons as interacting nodes in a graph. The architecture features two\ndistinct modules: one for learning structural connectivity and another for\npredicting future spiking activity via a graph neural network (GNN). Our model\naccommodates unobserved neurons through auxiliary nodes, allowing for inference\nin partially observed circuits. We evaluate this approach using synthetic data\nfrom ring attractor networks and real spike recordings from head direction\ncells in mice. Across a wide range of conditions, including varying recurrent\nconnectivity, external inputs, and incomplete observations, our model\nconsistently outperforms standard baselines, resolving spurious correlations\nmore effectively and recovering accurate weight profiles. When applied to real\ndata, the inferred connectivity aligns with theoretical predictions of\ncontinuous attractor models. These results highlight the potential of GNN-based\nmodels to infer latent neural circuitry through self-supervised structure\nlearning, while leveraging the spike prediction task to flexibly link\nconnectivity and dynamics across both simulated and biological neural systems."}
{"id": "2509.17913", "pdf": "https://arxiv.org/pdf/2509.17913", "abs": "https://arxiv.org/abs/2509.17913", "authors": ["Ruixi Huang", "David Waxman"], "title": "Effective decoupling of mutations and the resulting loss of biodiversity caused by environmental change", "categories": ["q-bio.PE", "physics.bio-ph"], "comment": "83 pages consisting of manuscript (31 pages) and SI (52 pages) in a\n  single document", "summary": "Many biological populations exhibit diversity in their strategy for survival\nand reproduction in a given environment, and microbes are an example. We\nexplore the fate of different strategies under sustained environmental change\nby considering a mathematical model for a large population of asexual\norganisms. Fitness is a bimodal function of a quantitative trait, with two\nlocal optima, separated by a local minimum, i.e., a mixture of stabilising and\ndisruptive selection. The optima represent two locally `best' trait values. We\nconsider regimes where, when the environment is unchanging, the equilibrium\ndistribution of the trait is bimodal. A bimodal trait distribution generally\nrequires, for its existence, mutational coupling between the two peaks, and it\nindicates two coexisting clones with distinct survival and reproduction\nstrategies. When subject to persistent environmental change, the population\nadapts by utilising mutations that allow it to track the changing environment.\nThe faster the rate of change of the environment, the larger the effect of the\nmutations that are utilised. Under persistent environmental change, the\ndistribution of trait values takes two different forms. At low rates of change,\nthe distribution remains bimodal. At higher rates, the distribution becomes\nunimodal. This loss of a clone/biodiversity is driven by a novel mechanism\nwhere environmental change decouples a class of mutations."}
{"id": "2509.16328", "pdf": "https://arxiv.org/pdf/2509.16328", "abs": "https://arxiv.org/abs/2509.16328", "authors": ["Jyun-Ping Kao"], "title": "The Role of High-Performance GPU Resources in Large Language Model Based Radiology Imaging Diagnosis", "categories": ["q-bio.TO"], "comment": null, "summary": "Large-language models (LLMs) are rapidly being applied to radiology, enabling\nautomated image interpretation and report generation tasks. Their deployment in\nclinical practice requires both high diagnostic accuracy and low inference\nlatency, which in turn demands powerful hardware. High-performance graphical\nprocessing units (GPUs) provide the necessary compute and memory throughput to\nrun large LLMs on imaging data. We review modern GPU architectures (e.g. NVIDIA\nA100/H100, AMD Instinct MI250X/MI300) and key performance metrics of\nfloating-point throughput, memory bandwidth, VRAM capacity. We show how these\nhardware capabilities affect radiology tasks: for example, generating reports\nor detecting findings on CheXpert and MIMIC-CXR images is computationally\nintensive and benefits from GPU parallelism and tensor-core acceleration.\nEmpirical studies indicate that using appropriate GPU resources can reduce\ninference time and improve throughput. We discuss practical challenges\nincluding privacy, deployment, cost, power and optimization strategies:\nmixed-precision, quantization, compression, and multi-GPU scaling. Finally, we\nanticipate that next-generation features (8-bit tensor cores, enhanced\ninterconnect) will further enable on-premise and federated radiology AI.\nAdvancing GPU infrastructure is essential for safe, efficient LLM-based\nradiology diagnostics."}
{"id": "2509.16973", "pdf": "https://arxiv.org/pdf/2509.16973", "abs": "https://arxiv.org/abs/2509.16973", "authors": ["Behdad Khodabandehloo", "Reza Rajimehr"], "title": "Deep Learning Inductive Biases for fMRI Time Series Classification during Resting-state and Movie-watching", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Deep learning has advanced fMRI analysis, yet it remains unclear which\narchitectural inductive biases are most effective at capturing functional\npatterns in human brain activity. This issue is particularly important in\nsmall-sample settings, as most datasets fall into this category. We compare\nmodels with three major inductive biases in deep learning including\nconvolutional neural networks (CNNs), long short-term memory networks (LSTMs),\nand Transformers for the task of biological sex classification. These models\nare evaluated within a unified pipeline using parcellated multivariate fMRI\ntime series from the Human Connectome Project (HCP) 7-Tesla cohort, which\nincludes four resting-state runs and four movie-watching task runs. We assess\nperformance on Whole-brain, subcortex, and 12 functional networks. CNNs\nconsistently achieved the highest discrimination for sex classification in both\nresting-state and movie-watching, while LSTM and Transformer models\nunderperformed. Network-resolved analyses indicated that the Whole-brain,\nDefault Mode, Cingulo-Opercular, Dorsal Attention, and Frontoparietal networks\nwere the most discriminative. These results were largely similar between\nresting-state and movie-watching. Our findings indicate that, at this dataset\nsize, discriminative information is carried by local spatial patterns and\ninter-regional dependencies, favoring convolutional inductive bias. Our study\nprovides insights for selecting deep learning architectures for fMRI time\nseries classification."}
{"id": "2509.17305", "pdf": "https://arxiv.org/pdf/2509.17305", "abs": "https://arxiv.org/abs/2509.17305", "authors": ["Jiarui Li", "Zixiang Yin", "Zhengming Ding", "Samuel J. Landry", "Ramgopal R. Mettu"], "title": "Rational Multi-Modal Transformers for TCR-pMHC Prediction", "categories": ["cs.CE", "q-bio.QM"], "comment": "The 16th ACM Conference on Bioinformatics, Computational Biology, and\n  Health Informatics (ACM-BCB 2025)", "summary": "T cell receptor (TCR) recognition of peptide-MHC (pMHC) complexes is\nfundamental to adaptive immunity and central to the development of T cell-based\nimmunotherapies. While transformer-based models have shown promise in\npredicting TCR-pMHC interactions, most lack a systematic and explainable\napproach to architecture design. We present an approach that uses a new\npost-hoc explainability method to inform the construction of a novel\nencoder-decoder transformer model. By identifying the most informative\ncombinations of TCR and epitope sequence inputs, we optimize cross-attention\nstrategies, incorporate auxiliary training objectives, and introduce a novel\nearly-stopping criterion based on explanation quality. Our framework achieves\nstate-of-the-art predictive performance while simultaneously improving\nexplainability, robustness, and generalization. This work establishes a\nprincipled, explanation-driven strategy for modeling TCR-pMHC binding and\noffers mechanistic insights into sequence-level binding behavior through the\nlens of deep learning."}
{"id": "2509.18065", "pdf": "https://arxiv.org/pdf/2509.18065", "abs": "https://arxiv.org/abs/2509.18065", "authors": ["Parna Mandal", "Nigel J. Mottram", "Sean McGinty"], "title": "Mathematical modelling of nutrient-dependent biofilm growth on medical implants", "categories": ["q-bio.PE"], "comment": null, "summary": "Biofilm infections on medical implants are difficult to eradicate because\ninsufficient nutrient availability promotes antibiotic-tolerant persister cells\nthat survive treatment and reseed growth. Existing mathematical models usually\nomit nutrient-dependent phenotypic switching between proliferative and\npersister states. Without this mechanism, models cannot capture how\nenvironmental conditions control the balance between active growth and\ndormancy, which is central to biofilm persistence. We present a continuum model\nthat couples nutrient transport with the dynamics of proliferative bacteria,\npersisters, dead cells, and extracellular polymeric substances. The switching\nrates between proliferative and persister phenotypes depend on local nutrient\nconcentration through two thresholds, enabling adaptation across nutrient-poor,\nintermediate, and nutrient-rich regimes. Simulations show that nutrient\nlimitation produces a high and sustained proportion of persister cells even\nwhen biomass is reduced, whereas nutrient-rich conditions support reversion to\nproliferative growth and lead to greater biomass. The model also predicts that\npersister populations peak at times that vary with nutrient availability, and\nthese peaks coincide with turning points in biofilm growth, identifying\ncritical intervention windows. By directly linking nutrient availability to\nphenotypic switching, our model reveals mechanisms of biofilm persistence that\nearlier models could not capture, and it points toward strategies that target\nnutrient-driven adaptation as a means to improve the control of\nimplant-associated infections."}
{"id": "2509.17854", "pdf": "https://arxiv.org/pdf/2509.17854", "abs": "https://arxiv.org/abs/2509.17854", "authors": ["Duong Le"], "title": "Magnetically Guided Endothelial BioBots: A Next-Generation Strategy for Treating Complex Cerebral Aneurysms", "categories": ["q-bio.TO"], "comment": "18 pages, 2 figures, 1 table. Review/Technical Report. Currently\n  under journal peer review", "summary": "Cerebral aneurysms affect three to five percent of the population, and\nrupture remains a major cause of stroke-related death and disability. Current\ntherapies, surgical clipping, endovascular coiling, and flow diversion, have\nimproved outcomes but each carries limitations. Clipping is invasive and often\nunsuitable for deep or posterior lesions. Coiling is prone to recurrence from\ncompaction or incomplete occlusion, particularly in wide-neck or fusiform\naneurysms. Flow diverters offer improved durability but rely on rigid metallic\nscaffolds that may malappose in tortuous vessels, compromise branch arteries,\ndelay endothelialization, and necessitate long-term dual antiplatelet therapy.\nThese shortcomings highlight a gap in current management: devices primarily\nprovide mechanical occlusion but fail to conform to complex geometries or\nreliably promote rapid, complete endothelialization. As a result, aneurysm\nnecks may remain exposed to persistent flow, delayed healing, and thrombosis.\n  To address this, we propose magnetically guided endothelial BioBots as a\nnext-generation therapeutic strategy. BioBots are biodegradable hydrogel\ncarriers embedded with magnetic nanoparticles and coated with primed\nendothelial progenitor cells. Delivered through microcatheters and guided by\nexternal electromagnetic fields, they can assemble across aneurysm defects.\nOnce localized, they form a conformal, geometry-adaptive endothelial patch that\nprovides immediate antithrombotic protection and, as the hydrogel degrades,\nleaves behind a stable, functional endothelial lining. By integrating\nmicrorobotic navigation with regenerative vascular biology, BioBots may\novercome the central limitations of current devices and enable safer, more\ndurable treatment for complex aneurysms."}
{"id": "2509.17138", "pdf": "https://arxiv.org/pdf/2509.17138", "abs": "https://arxiv.org/abs/2509.17138", "authors": ["Zhaoyang Cao", "Lael Schooler", "Reza Zafarani"], "title": "Analyzing Memory Effects in Large Language Models through the lens of Cognitive Psychology", "categories": ["q-bio.NC"], "comment": null, "summary": "Memory, a fundamental component of human cognition, exhibits adaptive yet\nfallible characteristics as illustrated by Schacter's memory \"sins\".These\ncognitive phenomena have been studied extensively in psychology and\nneuroscience, but the extent to which artificial systems, specifically Large\nLanguage Models (LLMs), emulate these cognitive phenomena remains\nunderexplored. This study uses human memory research as a lens for\nunderstanding LLMs and systematically investigates human memory effects in\nstate-of-the-art LLMs using paradigms drawn from psychological research. We\nevaluate seven key memory phenomena, comparing human behavior to LLM\nperformance. Both people and models remember less when overloaded with\ninformation (list length effect) and remember better with repeated exposure\n(list strength effect). They also show similar difficulties when retrieving\noverlapping information, where storing too many similar facts leads to\nconfusion (fan effect). Like humans, LLMs are susceptible to falsely\n\"remembering\" words that were never shown but are related to others (false\nmemories), and they can apply prior learning to new, related situations\n(cross-domain generalization). However, LLMs differ in two key ways: they are\nless influenced by the order in which information is presented (positional\nbias) and more robust when processing random or meaningless material (nonsense\neffect). These results reveal both alignments and divergences in how LLMs and\nhumans reconstruct memory. The findings help clarify how memory-like behavior\nin LLMs echoes core features of human cognition, while also highlighting the\narchitectural differences that lead to distinct patterns of error and success."}
{"id": "2509.17891", "pdf": "https://arxiv.org/pdf/2509.17891", "abs": "https://arxiv.org/abs/2509.17891", "authors": ["Tahir Yusufaly", "Hamid Abdollahi", "Babak Saboury", "Arman Rahmim"], "title": "Quantitative and Computational Radiobiology for Precision Radiopharmaceutical Therapies", "categories": ["physics.med-ph", "q-bio.QM"], "comment": null, "summary": "This article reviews the evolving field of radiobiology, emphasizing the need\nfor advanced multiscale, mechanistic models to optimize radiopharmaceutical\ntherapies (RPT). While the traditional linear-quadratic (LQ) model underpins\nexternal beam radiation therapy (EBRT), RPT's unique biological and spatial\ncomplexities demand new approaches. First-principles simulations of DNA damage,\nrepair, and multicellular responses are crucial for understanding therapeutic\nefficacy and toxicity. The integration of these models into personalized,\ndigital twin frameworks promises transformative clinical applications, but\nprogress depends on deep mechanistic insights, experimental validation, and\nbalancing model complexity with practicality for clinical use."}
{"id": "2509.17147", "pdf": "https://arxiv.org/pdf/2509.17147", "abs": "https://arxiv.org/abs/2509.17147", "authors": ["Joy Das Bairagya", "Udipta Chakraborti", "Sumana Annagiri", "Sagar Chakraborty"], "title": "A game played by tandem-running ants: Hint of procedural rationality", "categories": ["nlin.AO", "econ.TH", "physics.bio-ph", "q-bio.PE"], "comment": null, "summary": "Navigation through narrow passages during colony relocation by the\ntandem-running ants, $\\textit{Diacamma}$ $\\textit{indicum}$, is a tour de force\nof biological traffic coordination. Even on one-lane paths, the ants tactfully\nmanage a bidirectional flow: Informed individuals (termed leaders) guide\nnest-mates (termed followers) from a suboptimal nest to a new optimal nest, and\nthen return to recruit additional followers. We propose that encounters between\nthe ants moving in opposite directions can be modelled within the framework of\ngame theory leading to an understanding of the mechanism behind observed\nbehaviours. Our experiments reveal that, upon encountering a tandem pair (a\nleader and its follower) on a narrow path, the returning leader reverses her\ndirection and proceeds toward the new nest again as if she becomes the leader\nguiding a follower. This observed behaviour is consistent with game-theoretic\npredictions, provided the assumption of perfect rationality is relaxed in\nfavour of bounded rationality -- specifically, procedural rationality. In other\nwords, the experimental outcomes are consistent with sampling equilibrium but\nnot with Nash equilibrium. Our work, which strives to induct the essence of\nbehavioural game theory into the world of ants, is first ever report of\nrealizing sampling equilibrium in scenarios not involving human players."}
{"id": "2509.16661", "pdf": "https://arxiv.org/pdf/2509.16661", "abs": "https://arxiv.org/abs/2509.16661", "authors": ["Liav Daraf", "Yael Lavi", "Areej Saleem", "Daniel Sevilla Sanchez", "Yuri Feldman", "Lior Atia"], "title": "Cycling and tensed cells interpenetrated by non-cycling and compressed cells form a critical epithelial reticulum", "categories": ["q-bio.CB", "cond-mat.soft", "nlin.AO", "physics.bio-ph", "q-bio.TO"], "comment": "Supplementary video links are available on the video description\n  pages", "summary": "With the completion of development and wound repair, as the epithelium\napproaches homeostasis, cell proliferation is reduced to a minimum. In\nparallel, cellular motion transitions from a migratory unjammed state to a\nquiescent jammed state. This quiescent state is commonly regarded as devoid of\nlarge-scale regional variations in cell-cycle re-entry and cellular mechanics.\nTo the contrary, here we report that during late maturation there arises a\nheretofore unanticipated epithelial reticulum that is supracellular and spans\nmultiple scales of length. This reticulum evolves dynamically and comprises two\ninterpenetrating networks: large regions of cycling and mechanically tensed\ncells, embedded with islands of non-cycling and mechanically compressed cells.\nThe islands of compressed cells emerge and grow in cell numbers, with gradual\njamming and with reduced cellular rearrangements. We show how island growth is\nboth reversible, by provoking unjamming, and detainable, by cell cycle arrest\ntreatment. Moreover, the distribution of island sizes was found to conform to a\npower-law, thus leading us to employ a computational model of percolating\ncritical networks. Together, the observations indicate that the newly\ndiscovered epithelial reticulum self-organizes close to but just shy of\ncriticality - thus avoiding mergers of compressed cell islands. This\nquasi-criticality reframes epithelial homeostasis as a dynamic regional balance\nof forces and proliferation."}
{"id": "2509.17174", "pdf": "https://arxiv.org/pdf/2509.17174", "abs": "https://arxiv.org/abs/2509.17174", "authors": ["Kijung Yoon"], "title": "Self-Supervised Discovery of Neural Circuits in Spatially Patterned Neural Responses with Graph Neural Networks", "categories": ["q-bio.NC", "cs.LG", "q-bio.QM"], "comment": "To appear in NeurIPS 2025", "summary": "Inferring synaptic connectivity from neural population activity is a\nfundamental challenge in computational neuroscience, complicated by partial\nobservability and mismatches between inference models and true circuit\ndynamics. In this study, we propose a graph-based neural inference model that\nsimultaneously predicts neural activity and infers latent connectivity by\nmodeling neurons as interacting nodes in a graph. The architecture features two\ndistinct modules: one for learning structural connectivity and another for\npredicting future spiking activity via a graph neural network (GNN). Our model\naccommodates unobserved neurons through auxiliary nodes, allowing for inference\nin partially observed circuits. We evaluate this approach using synthetic data\nfrom ring attractor networks and real spike recordings from head direction\ncells in mice. Across a wide range of conditions, including varying recurrent\nconnectivity, external inputs, and incomplete observations, our model\nconsistently outperforms standard baselines, resolving spurious correlations\nmore effectively and recovering accurate weight profiles. When applied to real\ndata, the inferred connectivity aligns with theoretical predictions of\ncontinuous attractor models. These results highlight the potential of GNN-based\nmodels to infer latent neural circuitry through self-supervised structure\nlearning, while leveraging the spike prediction task to flexibly link\nconnectivity and dynamics across both simulated and biological neural systems."}
{"id": "2509.17422", "pdf": "https://arxiv.org/pdf/2509.17422", "abs": "https://arxiv.org/abs/2509.17422", "authors": ["Qing Xu", "Shenshen Wang"], "title": "Adaptive mechanical proofreading toward faithful clonal selection", "categories": ["physics.bio-ph", "q-bio.CB", "q-bio.PE"], "comment": "13 pages, 7 figures", "summary": "To ensure faithful information transmission, cells utilize nonequilibrium\ndrives to reduce errors. Kinetic proofreading is a classic mechanism known to\nsharpen ligand discrimination by T lymphocytes. It remains an open question\nwhether the adaptive immune system relies solely on kinetic proofreading to\nboost fidelity. Here, we suggest an alternative: an enhanced form of mechanical\nproofreading (MPR) in which adaptive force exertion via dynamic cell-cell\ncontact allows faithful selection of high-affinity B lymphocytes. Using a\nminimal model validated with experiment, we show that adaptive MPR,\ncharacterized by mechanical feedback between force generation and contact\nformation, enables robust discrimination of receptor quality regardless of\nligand quantity. Although MPR generically balances the tradeoffs between speed\nand fidelity, a negative scaling of contact duration with ligand abundance\nindicates the presence of feedback. Due to its ability to modulate interactions\nof distinct ligands that share load at membrane contacts, adaptive MPR can be\nharnessed to mitigate autoimmunity or enhance multivalent vaccines. Overall,\nthis work suggests a generalization of the proofreading mechanism to encompass\ncellular designs that act across scales to enable competing functionalities."}
{"id": "2509.17924", "pdf": "https://arxiv.org/pdf/2509.17924", "abs": "https://arxiv.org/abs/2509.17924", "authors": ["Xiuqi Ge", "Zhibo Yao", "Yaosong Du"], "title": "Medical priority fusion: achieving dual optimization of sensitivity and interpretability in nipt anomaly detection", "categories": ["cs.LG", "q-bio.TO"], "comment": "24 pages, 47 figures, publish to BIBM", "summary": "Clinical machine learning faces a critical dilemma in high-stakes medical\napplications: algorithms achieving optimal diagnostic performance typically\nsacrifice the interpretability essential for physician decision-making, while\ninterpretable methods compromise sensitivity in complex scenarios. This paradox\nbecomes particularly acute in non-invasive prenatal testing (NIPT), where\nmissed chromosomal abnormalities carry profound clinical consequences yet\nregulatory frameworks mandate explainable AI systems. We introduce Medical\nPriority Fusion (MPF), a constrained multi-objective optimization framework\nthat resolves this fundamental trade-off by systematically integrating Naive\nBayes probabilistic reasoning with Decision Tree rule-based logic through\nmathematically-principled weighted fusion under explicit medical constraints.\nRigorous validation on 1,687 real-world NIPT samples characterized by extreme\nclass imbalance (43.4:1 normal-to-abnormal ratio) employed stratified 5-fold\ncross-validation with comprehensive ablation studies and statistical hypothesis\ntesting using McNemar's paired comparisons. MPF achieved simultaneous\noptimization of dual objectives: 89.3% sensitivity (95% CI: 83.9-94.7%) with\n80% interpretability score, significantly outperforming individual algorithms\n(McNemar's test, p < 0.001). The optimal fusion configuration achieved Grade A\nclinical deployment criteria with large effect size (d = 1.24), establishing\nthe first clinically-deployable solution that maintains both diagnostic\naccuracy and decision transparency essential for prenatal care. This work\ndemonstrates that medical-constrained algorithm fusion can resolve the\ninterpretability-performance trade-off, providing a mathematical framework for\ndeveloping high-stakes medical decision support systems that meet both clinical\nefficacy and explainability requirements."}
{"id": "2509.17260", "pdf": "https://arxiv.org/pdf/2509.17260", "abs": "https://arxiv.org/abs/2509.17260", "authors": ["Evgeniya Anisimova", "Sameer N. B. Alladin", "Styliani Tsamaz", "Edwin S. Dalmaijer"], "title": "A tutorial on electrogastrography using low-cost hardware and open-source software", "categories": ["q-bio.NC"], "comment": null, "summary": "Electrogastrography is the recording of changes in electric potential caused\nby the stomach's pacemaker region, typically through several cutaneous sensors\nplaced on the abdomen. It is a worthwhile technique in medical and\npsychological research, but also relatively niche. Here we present a tutorial\non the acquisition and analysis of the human electrogastrogram. Because\ndedicated equipment and software can be prohibitively expensive, we demonstrate\nhow data can be acquired using a low-cost OpenBCI Ganglion amplifier. We also\npresent a processing pipeline that minimises attrition, which is particularly\nhelpful for low-cost equipment but also applicable to top-of-the-line hardware.\nOur approach comprises outlier rejection, frequency filtering, movement\nfiltering, and noise reduction using independent component analysis. Where\ntraditional approaches include a subjective step in which only one channel is\nmanually selected for further analysis, our pipeline recomposes the\nelectrogastrogram from all recorded channels after automatic rejection of\nnuisance components. The main benefits of this approach are reduced attrition,\nretention of data from all recorded channels, and reduced influence of\nresearcher bias. In addition to our tutorial on the method, we offer a\nproof-of-principle in which our approach leads to reduced data rejection\ncompared to established methods. We aimed to describe each step in sufficient\ndetail to be implemented in any programming language. In addition, we made an\nopen-source Python package freely available for ease of use."}
{"id": "2509.17948", "pdf": "https://arxiv.org/pdf/2509.17948", "abs": "https://arxiv.org/abs/2509.17948", "authors": ["Dhruv Mittal", "FlÃ¡vio L. Pinheiro", "VÃ­tor V. Vasconcelos"], "title": "Social influence on complex networks as a perturbation to individual behavior", "categories": ["physics.soc-ph", "q-bio.PE"], "comment": null, "summary": "Cooperation is fundamental to the functioning of biological and social\nsystems in both human and animal populations, with the structure of\ninteractions playing a crucial role. Previous studies have used networks to\ndescribe interactions and explore the evolution of cooperation, but with\nlimited transposability to social settings due to biologically relevant\nassumptions. Exogenous processes -- that affect the individual and are not\nderived from social interactions -- even if unbiased, have a role in supporting\ncooperation over defection, and this role has been largely overlooked in the\ncontext of network-based interactions. Here, we show that selection can favor\neither cooperation or defection depending on the frequency of exogenous, even\nif neutral, processes in any population structure. Our framework allows for\nderiving analytically the conditions for favoring a specific behavior in any\nnetwork structure strongly affected by non-social environments (frequent\nexogenous forcing, FEF), which contrasts with previous computationally\nprohibitive methods. Our results demonstrate that the requirements for favoring\ncooperation under FEF do not match those in the rare-mutation limit,\nestablishing that underlying neutral processes can be considered a mechanism\nfor cooperation. We reveal that, under FEF, populations are less cooperative,\nand network heterogeneity can provide an advantage only if targeting specific\nnetwork properties, clarifying seemingly contradictory experimental results and\nevolutionary predictions. While focused on cooperation, our assumptions\ngeneralize to any decision-making process involving a choice between\nalternative options. Our framework is particularly applicable to\nnon-homogeneous human populations, offering a new perspective on cooperation\nscience in the context of cultural evolution, where neutral and biased\nprocesses within structured interactions are abundant."}
{"id": "2509.17280", "pdf": "https://arxiv.org/pdf/2509.17280", "abs": "https://arxiv.org/abs/2509.17280", "authors": ["Thomas Serre", "Ellie Pavlick"], "title": "From Prediction to Understanding: Will AI Foundation Models Transform Brain Science?", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "Generative pretraining (the \"GPT\" in ChatGPT) enables language models to\nlearn from vast amounts of internet text without human supervision. This\napproach has driven breakthroughs across AI by allowing deep neural networks to\nlearn from massive, unstructured datasets. We use the term foundation models to\nrefer to large pretrained systems that can be adapted to a wide range of tasks\nwithin and across domains, and these models are increasingly applied beyond\nlanguage to the brain sciences. These models achieve strong predictive\naccuracy, raising hopes that they might illuminate computational principles.\nBut predictive success alone does not guarantee scientific understanding. Here,\nwe outline how foundation models can be productively integrated into the brain\nsciences, highlighting both their promise and their limitations. The central\nchallenge is to move from prediction to explanation: linking model computations\nto mechanisms underlying neural activity and cognition."}
{"id": "2509.16803", "pdf": "https://arxiv.org/pdf/2509.16803", "abs": "https://arxiv.org/abs/2509.16803", "authors": ["Qiang Li", "Liang Ma", "Masoud Seraji", "Shujian Yu", "Yun Wang", "Jingyu Liu", "Vince D. Calhoun"], "title": "Efficient Brain Network Estimation with Sparse ICA in Non-Human Primate Neuroimaging", "categories": ["stat.AP", "q-bio.NC"], "comment": "Submitted to ICASSP 2026", "summary": "Independent component analysis (ICA) is widely used to separate mixed signals\nand recover statistically independent components. However, in non-human primate\nneuroimaging studies, most ICA-recovered spatial maps are often dense. To\nextract the most relevant brain activation patterns, post-hoc thresholding is\ntypically applied-though this approach is often imprecise and arbitrary. To\naddress this limitation, we employed the Sparse ICA method, which enforces both\nsparsity and statistical independence, allowing it to extract the most relevant\nactivation maps without requiring additional post-processing. Simulation\nexperiments demonstrate that Sparse ICA performs competitively against 11\nclassical linear ICA methods. We further applied Sparse ICA to real non-human\nprimate neuroimaging data, identifying several independent component networks\nspanning different brain networks. These spatial maps revealed clearly defined\nactivation areas, providing further evidence that Sparse ICA is effective and\nreliable in practical applications."}
{"id": "2509.16859", "pdf": "https://arxiv.org/pdf/2509.16859", "abs": "https://arxiv.org/abs/2509.16859", "authors": ["Fangfang Li", "Xiaojie Zhang"], "title": "The Principles of Human-like Conscious Machine", "categories": ["cs.AI", "q-bio.NC"], "comment": null, "summary": "Determining whether another system, biological or artificial, possesses\nphenomenal consciousness has long been a central challenge in consciousness\nstudies. This attribution problem has become especially pressing with the rise\nof large language models and other advanced AI systems, where debates about \"AI\nconsciousness\" implicitly rely on some criterion for deciding whether a given\nsystem is conscious. In this paper, we propose a substrate-independent,\nlogically rigorous, and counterfeit-resistant sufficiency criterion for\nphenomenal consciousness. We argue that any machine satisfying this criterion\nshould be regarded as conscious with at least the same level of confidence with\nwhich we attribute consciousness to other humans. Building on this criterion,\nwe develop a formal framework and specify a set of operational principles that\nguide the design of systems capable of meeting the sufficiency condition. We\nfurther argue that machines engineered according to this framework can, in\nprinciple, realize phenomenal consciousness. As an initial validation, we show\nthat humans themselves can be viewed as machines that satisfy this framework\nand its principles. If correct, this proposal carries significant implications\nfor philosophy, cognitive science, and artificial intelligence. It offers an\nexplanation for why certain qualia, such as the experience of red, are in\nprinciple irreducible to physical description, while simultaneously providing a\ngeneral reinterpretation of human information processing. Moreover, it suggests\na path toward a new paradigm of AI beyond current statistics-based approaches,\npotentially guiding the construction of genuinely human-like AI."}
{"id": "2509.16908", "pdf": "https://arxiv.org/pdf/2509.16908", "abs": "https://arxiv.org/abs/2509.16908", "authors": ["Sixtus Dakurah"], "title": "Discrete Heat Kernels on Simplicial Complexes and Its Application to Functional Brain Networks", "categories": ["q-bio.QM", "q-bio.NC"], "comment": null, "summary": "Networks constitute fundamental organizational structures across biological\nsystems, although conventional graph-theoretic analyses capture exclusively\npairwise interactions, thereby omitting the intricate higher-order\nrelationships that characterize network complexity. This work proposes a\nunified framework for heat kernel smoothing on simplicial complexes, extending\nclassical signal processing methodologies from vertices and edges to cycles and\nhigher-dimensional structures. Through Hodge Laplacian, a discrete heat kernel\non a finite simplicial complex $\\mathcal{K}$ is constructed to smooth signals\non $k$-simplices via the boundary operator $\\partial_k$. Computationally\nefficient sparse algorithms for constructing boundary operators are developed\nto implement linear diffusion processes on $k$-simplices. The methodology\ngeneralizes heat kernel smoothing to $k$-simplices, utilizing boundary\nstructure to localize topological features while maintaining homological\ninvariance. Simulation studies demonstrate qualitative signal enhancement\nacross vertex and edge domains following diffusion processes. Application to\nparcellated human brain functional connectivity networks reveals that\nsimplex-space smoothing attenuates spurious connections while amplifying\ncoherent anatomical architectures, establishing practical significance for\ncomputational neuroscience applications."}
