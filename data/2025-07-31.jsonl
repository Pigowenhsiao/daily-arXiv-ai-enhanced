{"id": "2507.22068", "pdf": "https://arxiv.org/pdf/2507.22068", "abs": "https://arxiv.org/abs/2507.22068", "authors": ["Chen Adar", "Yulia Baron", "Baruch Rofman", "Maya Bar-Dolev", "Liat Bahari", "Victor Yashunsky", "Vera Sirotinskaya", "Oded Shoseyov", "Ido Braslavsky"], "title": "Biomimetic Engineering of a Fortified Ice Composite with Enhanced Mechanical Properties", "categories": ["q-bio.BM", "cond-mat.mtrl-sci", "physics.bio-ph", "physics.med-ph"], "comment": null, "summary": "This work presents BioPykrete, a new sustainable bio-composite material\ncreated from ice, nano-crystalline cellulose (CNC), and a tailor-made chimera\nprotein designed to bind the two together. We developed and produced the\nchimera protein by linking AFPIII, an ice-binding protein, with CBM3a, a\nCNC-binding protein. As the suspension freezes, the CNC chains self-organize\ninto a reinforcing network between the ice crystals. This structural\nenhancement limits crack propagation to typical pore sizes, allowing BioPykrete\nto avoid the brittle and sudden failure commonly associated with ice. Instead,\nit exhibits an elastic-like response to stress, making it suitable for\nconstruction and engineering applications. With compressive strength comparable\nwith concrete, BioPykrete offers a sustainable and biodegradable alternative to\nconstruction materials suitable for the harsh arctic regions of the world where\ntraditional methods are ineffective, and resources are scarce. Engineering\nchimera proteins with specific affinity to more than a single material type may\nhelp improve or tailor the properties of other composite materials."}
{"id": "2507.22088", "pdf": "https://arxiv.org/pdf/2507.22088", "abs": "https://arxiv.org/abs/2507.22088", "authors": ["Dylan Hamitouche", "Tihare Zamorano", "Youcef Barkat", "Deven Parekh", "Lena Palaniyappan", "David Benrimoh"], "title": "Sleep and Activity Patterns as Transdiagnostic Behavioral Biomarkers in Psychiatry: Initial Insights from the DeeP-DD study", "categories": ["q-bio.QM"], "comment": null, "summary": "Background: Symptom rating scales in psychiatry are limited by reliance on\nself-report, and lack of predictive power. Actigraphy, a passive wearable-based\nmethod for measuring sleep and physical activity, offers objective,\nhigh-resolution behavioral data that may better reflect symptom fluctuations,\nbut most studies have focused on narrow diagnostic groups or fixed time\nwindows, limiting clinical translation. Objective: To examine whether\nactigraphy-derived sleep and activity features correlate with psychiatric\nsymptom severity in a transdiagnostic psychiatric sample, and to identify which\nfeatures are most clinically relevant across multiple temporal resolutions.\nMethods: We present a feasibility case series study with preliminary data from\neight outpatients enrolled in the DeeP-DD study, a transdiagnostic study of\ndigital phenotyping. Participants wore GENEActiv actigraphy devices and symptom\nseverity was measured using a variety of validated scales. We performed\nintra-individual Spearman correlations and inter-individual repeated measures\ncorrelations across daily, weekly, monthly, and full-duration averages.\nResults: Intra-individual analyses revealed that later rise times were\nsignificantly associated with higher weekly PHQ-9 scores in participant #7\n(\\r{ho} = 0.74, P=.0003) and participant #4 (\\r{ho} = 0.78, P=.022), as well as\nhigher weekly GAD-7 scores in participant #7 (\\r{ho} = 0.59, P=.026).\nInter-individual analyses showed that weeks with later average rise time\ncorrelated with higher PHQ-9 (r = 0.48, P=.0003) and GAD-7 scores (r = 0.38,\nP=.032). Increased light physical activity was linked to lower PHQ-9 scores\nweekly (r = -0.44, P=.001) and monthly (r = -0.53, P=.014). Conclusion:\nConsistent associations between actigraphy features and symptoms across\ntemporal scales and diagnostic groups underscore their potential utility for\nscalable, real-world clinical monitoring."}
{"id": "2507.22087", "pdf": "https://arxiv.org/pdf/2507.22087", "abs": "https://arxiv.org/abs/2507.22087", "authors": ["Mark P. Rast", "Luke I. Rast"], "title": "Determining disease attributes from epidemic trajectories", "categories": ["q-bio.PE"], "comment": null, "summary": "Effective public health decisions require early reliable inference of the\ninfectious disease properties. In this paper we assess the ability to infer\ninfectious disease attributes from population-level stochastic epidemic\ntrajectories. In particular, we construct stochastic Kermack-McKendrick model\ntrajectories, sample them with and without measurement error, and evaluate\ninversions for the population mean infectiousness as a function of time since\ninfection, the infection duration distribution, and its complementary\ncumulative distribution, the infection survival distribution. Based on an\nintegro-differential equation formulation we employ a natural regression\napproach to fit the corresponding integral kernels and show that these disease\nattributes are recoverable from both un-regularized multi-trajectory inversions\nand regularized single trajectory inversions. Moreover, we demonstrate that the\ninfection duration distributions (or alternatively the infection survival\ndistributions) and population mean infectiousness kernels recovered can be used\nto solve for the individual infectiousness profile, the infectiousness of an\nindividual over the duration of their infection. The work suggests that,\naggressive monitoring of the stochastic evolution of a novel infectious disease\noutbreak in a single local well-mixed population can allow determination of the\nunderlying disease attributes that characterize its spread."}
{"id": "2507.22067", "pdf": "https://arxiv.org/pdf/2507.22067", "abs": "https://arxiv.org/abs/2507.22067", "authors": ["Yuang Cao", "Jiachen Zou", "Chen Wei", "Quanying Liu"], "title": "Dimensions of Vulnerability in Visual Working Memory: An AI-Driven Approach to Perceptual Comparison", "categories": ["q-bio.NC", "cs.AI"], "comment": "6 pages, 4 figures, experimental results presented in the paper,\n  accepted for virtual poster presentation at CogSci 2025", "summary": "Human memory exhibits significant vulnerability in cognitive tasks and daily\nlife. Comparisons between visual working memory and new perceptual input (e.g.,\nduring cognitive tasks) can lead to unintended memory distortions. Previous\nstudies have reported systematic memory distortions after perceptual\ncomparison, but understanding how perceptual comparison affects memory\ndistortions in real-world objects remains a challenge. Furthermore, identifying\nwhat visual features contribute to memory vulnerability presents a novel\nresearch question. Here, we propose a novel AI-driven framework that generates\nnaturalistic visual stimuli grounded in behaviorally relevant object dimensions\nto elicit similarity-induced memory biases. We use two types of stimuli --\nimage wheels created through dimension editing and dimension wheels generated\nby dimension activation values -- in three visual working memory (VWM)\nexperiments. These experiments assess memory distortions under three\nconditions: no perceptual comparison, perceptual comparison with image wheels,\nand perceptual comparison with dimension wheels. The results show that similar\ndimensions, like similar images, can also induce memory distortions.\nSpecifically, visual dimensions are more prone to distortion than semantic\ndimensions, indicating that the object dimensions of naturalistic visual\nstimuli play a significant role in the vulnerability of memory."}
{"id": "2507.22092", "pdf": "https://arxiv.org/pdf/2507.22092", "abs": "https://arxiv.org/abs/2507.22092", "authors": ["Gianluca Carloni", "Biagio Brattoli", "Seongho Keum", "Jongchan Park", "Taebum Lee", "Chang Ho Ahn", "Sergio Pereira"], "title": "Pathology Foundation Models are Scanner Sensitive: Benchmark and Mitigation with Contrastive ScanGen Loss", "categories": ["q-bio.QM", "cs.AI", "cs.CV", "eess.IV", "q-bio.TO", "I.2; I.2.6; I.4; I.4.7; I.5; J.3; J.6"], "comment": "Accepted (Oral) in MedAGI 2025 International Workshop at MICCAI\n  Conference", "summary": "Computational pathology (CPath) has shown great potential in mining\nactionable insights from Whole Slide Images (WSIs). Deep Learning (DL) has been\nat the center of modern CPath, and while it delivers unprecedented performance,\nit is also known that DL may be affected by irrelevant details, such as those\nintroduced during scanning by different commercially available scanners. This\nmay lead to scanner bias, where the model outputs for the same tissue acquired\nby different scanners may vary. In turn, it hinders the trust of clinicians in\nCPath-based tools and their deployment in real-world clinical practices. Recent\npathology Foundation Models (FMs) promise to provide better domain\ngeneralization capabilities. In this paper, we benchmark FMs using a\nmulti-scanner dataset and show that FMs still suffer from scanner bias.\nFollowing this observation, we propose ScanGen, a contrastive loss function\napplied during task-specific fine-tuning that mitigates scanner bias, thereby\nenhancing the models' robustness to scanner variations. Our approach is applied\nto the Multiple Instance Learning task of Epidermal Growth Factor Receptor\n(EGFR) mutation prediction from H\\&E-stained WSIs in lung cancer. We observe\nthat ScanGen notably enhances the ability to generalize across scanners, while\nretaining or improving the performance of EGFR mutation prediction."}
{"id": "2507.22287", "pdf": "https://arxiv.org/pdf/2507.22287", "abs": "https://arxiv.org/abs/2507.22287", "authors": ["Ju Kang", "Yiyuan Niu", "Yuanzhi Li", "Chengjin Chu"], "title": "Self-organized biodiversity and species abundance distribution patterns in ecosystems with higher-order interactions", "categories": ["q-bio.PE", "nlin.CD", "physics.bio-ph"], "comment": "Main: 10 pages, 3 figures; SM: 17 pages, 15 figures", "summary": "Explaining the emergence of self-organized biodiversity and species abundance\ndistribution patterns remians a fundamental challenge in ecology. While\nclassical frameworks, such as neutral theory and models based on pairwise\nspecies interactions, have provided valuable insights, they often neglect\nhigher-order interactions (HOIs), whose role in stabilizing ecological\ncommunities is increasingly recognized. Here, we extend the Generalized\nLotka-Volterra framework to incorporate HOIs and demonstrate that these\ninteractions can enhance ecosystem stability and prevent collapse. Our model\nexhibits a diverse range of emergent dynamics, including self-sustained\noscillations, quasi-periodic (torus) trajectories, and intermittent chaos.\nRemarkably, it also reproduces empirical species abundance distributions\nobserved across diverse natural communities. These results underscore the\ncritical role of HOIs in structuring biodiversity and offer a broadly\napplicable theoretical framework for capturing complexity in ecological systems"}
{"id": "2507.22216", "pdf": "https://arxiv.org/pdf/2507.22216", "abs": "https://arxiv.org/abs/2507.22216", "authors": ["Andrew Kyle Lampinen", "Stephanie C. Y. Chan", "Yuxuan Li", "Katherine Hermann"], "title": "Representation biases: will we achieve complete understanding by analyzing representations?", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "A common approach in neuroscience is to study neural representations as a\nmeans to understand a system -- increasingly, by relating the neural\nrepresentations to the internal representations learned by computational\nmodels. However, a recent work in machine learning (Lampinen, 2024) shows that\nlearned feature representations may be biased to over-represent certain\nfeatures, and represent others more weakly and less-consistently. For example,\nsimple (linear) features may be more strongly and more consistently represented\nthan complex (highly nonlinear) features. These biases could pose challenges\nfor achieving full understanding of a system through representational analysis.\nIn this perspective, we illustrate these challenges -- showing how feature\nrepresentation biases can lead to strongly biased inferences from common\nanalyses like PCA, regression, and RSA. We also present homomorphic encryption\nas a simple case study of the potential for strong dissociation between\npatterns of representation and computation. We discuss the implications of\nthese results for representational comparisons between systems, and for\nneuroscience more generally."}
{"id": "2507.22210", "pdf": "https://arxiv.org/pdf/2507.22210", "abs": "https://arxiv.org/abs/2507.22210", "authors": ["Aviv Spinner", "Erika DeBenedictis", "Corey M. Hudson"], "title": "Scaling and Data Saturation in Protein Language Models", "categories": ["q-bio.QM"], "comment": "Presented at the GenBio Workshop, ICML 2025", "summary": "Data in biology is redundant, noisy, and sparse. How does the type and scale\nof available data impact model performance? In this work, we specifically\ninvestigate how protein language models (pLMs) scale with increasing\npretraining data. We investigate this relationship by measuring the performance\nof protein function prediction on a suite of pLMs pretrained on yearly\nsnapshots of UniRef100 from 2011 to 2024. We find no evidence of model\nsaturation on this task: performance improves--but not monotonically--with\nadded data, and this trend differs between unsupervised and supervised\nexperiments. Using a well-characterized Beta-Lactamase protein from E. coli, we\nfind that unsupervised model predictions get better year-over-year, though they\ndo not yet consistently perform better than the supervised baseline. Our\nresults underscore the need for targeted data acquisition and deeper study of\ndata scaling in protein modeling. All training, inference, analysis, and\nvisualization code is available at:\nhttps://github.com/Align-to-Innovate/data-saturation-and-scaling."}
{"id": "2507.22256", "pdf": "https://arxiv.org/pdf/2507.22256", "abs": "https://arxiv.org/abs/2507.22256", "authors": ["Jun Won Park", "Kangyu Zhao", "Sanket Rane"], "title": "Spatiodynamic inference using vision-based generative modelling", "categories": ["q-bio.QM", "q-bio.PE"], "comment": null, "summary": "Biological systems commonly exhibit complex spatiotemporal patterns whose\nunderlying generative mechanisms pose a significant analytical challenge.\nTraditional approaches to spatiodynamic inference rely on dimensionality\nreduction through summary statistics, which sacrifice complexity and\ninterdependent structure intrinsic to these data in favor of parameter\nidentifiability. This imposes a fundamental constraint on reliably extracting\nmechanistic insights from spatiotemporal data, highlighting the need for\nanalytical frameworks that preserve the full richness of these dynamical\nsystems. To address this, we developed a simulation-based inference framework\nthat employs vision transformer-driven variational encoding to generate compact\nrepresentations of the data, exploiting the inherent contextual dependencies.\nThese representations are subsequently integrated into a likelihood-free\nBayesian approach for parameter inference. The central idea is to construct a\nfine-grained, structured mesh of latent representations from simulated dynamics\nthrough systematic exploration of the parameter space. This encoded mesh of\nlatent embeddings then serves as a reference map for retrieving parameter\nvalues that correspond to observed data. By integrating generative modeling\nwith Bayesian principles, our approach provides a unified inference framework\nto identify both spatial and temporal patterns that manifest in multivariate\ndynamical systems."}
{"id": "2507.22313", "pdf": "https://arxiv.org/pdf/2507.22313", "abs": "https://arxiv.org/abs/2507.22313", "authors": ["Woojae Jeong", "Aditya Kommineni", "Kleanthis Avramidis", "Colin McDaniel", "Donald Berry", "Myzelle Hughes", "Thomas McGee", "Elsi Kaiser", "Dani Byrd", "Assal Habibi", "B. Rael Cahn", "Idan A. Blank", "Kristina Lerman", "Dimitrios Pantazis", "Sudarsana R. Kadiri", "Takfarinas Medani", "Shrikanth Narayanan", "Richard M. Leahy"], "title": "Decoding Neural Signatures of Semantic Evaluations in Depression and Suicidality", "categories": ["q-bio.NC", "cs.LG", "eess.SP"], "comment": null, "summary": "Depression and suicidality profoundly impact cognition and emotion, yet\nobjective neurophysiological biomarkers remain elusive. We investigated the\nspatiotemporal neural dynamics underlying affective semantic processing in\nindividuals with varying levels of clinical severity of depression and\nsuicidality using multivariate decoding of electroencephalography (EEG) data.\nParticipants (N=137) completed a sentence evaluation task involving emotionally\ncharged self-referential statements while EEG was recorded. We identified\nrobust, neural signatures of semantic processing, with peak decoding accuracy\nbetween 300-600 ms -- a window associated with automatic semantic evaluation\nand conflict monitoring. Compared to healthy controls, individuals with\ndepression and suicidality showed earlier onset, longer duration, and greater\namplitude decoding responses, along with broader cross-temporal generalization\nand increased activation of frontocentral and parietotemporal components. These\nfindings suggest altered sensitivity and impaired disengagement from\nemotionally salient content in the clinical groups, advancing our understanding\nof the neurocognitive basis of mental health and providing a principled basis\nfor developing reliable EEG-based biomarkers of depression and suicidality."}
{"id": "2507.22212", "pdf": "https://arxiv.org/pdf/2507.22212", "abs": "https://arxiv.org/abs/2507.22212", "authors": ["Levin M Moser", "Ahmad Kamal Hamid", "Esteban Miglietta", "Nodar Gogoberidze", "Beth A Cimini"], "title": "Evaluating Integrative Strategies for Incorporating Phenotypic Features in Spatial Transcriptomics", "categories": ["q-bio.QM"], "comment": null, "summary": "Spatial transcriptomics (ST) technologies not only offer an unprecedented\nopportunity to interrogate intact biological samples in a spatially informed\nmanner, but also set the stage for integration with other imaging-based\nmodalities. However, how to best exploit spatial context and integrate ST with\nimaging-based modalities remains an open question. To address this,\nparticularly under real-world experimental constraints such as limited dataset\nsize, class imbalance, and bounding-box-based segmentation, we used a publicly\navailable murine ileum MERFISH dataset to evaluate whether a minimally tuned\nvariational autoencoder (VAE) could extract informative low-dimensional\nrepresentations from cell crops of spot counts, nuclear stain, membrane stain,\nor a combination thereof. We assessed the resulting embeddings through\nPERMANOVA, cross-validated classification, and unsupervised Leiden clustering,\nand compared them to classical image-based feature vectors extracted via\nCellProfiler. While transcript counts (TC) generally outperformed other feature\nspaces, the VAE-derived latent spaces (LSs) captured meaningful biological\nvariation and enabled improved label recovery for specific cell types. LS2, in\nparticular, trained solely on morphological input, also exhibited moderate\npredictive power for a handful of genes in a ridge regression model. Notably,\ncombining TC with LSs through multiplex clustering led to consistent gains in\ncluster homogeneity, a trend that also held when augmenting only subsets of TC\nwith the stain-derived LS2. In contrast, CellProfiler-derived features\nunderperformed relative to LSs, highlighting the advantage of learned\nrepresentations over hand-crafted features. Collectively, these findings\ndemonstrate that even under constrained conditions, VAEs can extract\nbiologically meaningful signals from imaging data and constitute a promising\nstrategy for multi-modal integration."}
{"id": "2507.22785", "pdf": "https://arxiv.org/pdf/2507.22785", "abs": "https://arxiv.org/abs/2507.22785", "authors": ["Jayanth R Taranath", "Salim M'Jahad"], "title": "An Uncertainty Principle for Probabilistic Computation in the Retina", "categories": ["q-bio.NC"], "comment": null, "summary": "We introduce a probabilistic model of early visual processing, beginning with\nthe interaction between a light wavefront and the retina. We argue that\nperception originates not with deterministic transduction, but with\nprobabilistic threshold crossings shaped by quantum photon arrival statistics\nand biological variability. We formalize this with an uncertainty relation, \\(\n\\Delta \\alpha \\cdot \\Delta t \\geq \\eta \\), through the transformation of light\ninto symbolic neural code through the layered retinal architecture. Our model\nis supported by previous experimental results, which show intrinsic variability\nin retinal responses even under fixed stimuli. We contrast this with a\nclassical null hypothesis of deterministic encoding and propose experiments to\nfurther test our uncertainty relation. By re-framing the retina as a\nprobabilistic measurement device, we lay the foundation for future models of\ncortical dynamics rooted in quantum-like computation. We are not claiming that\nthe brain could be working as a quantum-system, but rather putting forth the\nargument that the brain as a classical system could still implement\nquantum-inspired computations. We define quantum-inspired computation as a\nscheme that includes both probabilistic and time-sensitive computation, clearly\nseparating it from classically implementable probabilistic systems."}
{"id": "2507.22256", "pdf": "https://arxiv.org/pdf/2507.22256", "abs": "https://arxiv.org/abs/2507.22256", "authors": ["Jun Won Park", "Kangyu Zhao", "Sanket Rane"], "title": "Spatiodynamic inference using vision-based generative modelling", "categories": ["q-bio.QM", "q-bio.PE"], "comment": null, "summary": "Biological systems commonly exhibit complex spatiotemporal patterns whose\nunderlying generative mechanisms pose a significant analytical challenge.\nTraditional approaches to spatiodynamic inference rely on dimensionality\nreduction through summary statistics, which sacrifice complexity and\ninterdependent structure intrinsic to these data in favor of parameter\nidentifiability. This imposes a fundamental constraint on reliably extracting\nmechanistic insights from spatiotemporal data, highlighting the need for\nanalytical frameworks that preserve the full richness of these dynamical\nsystems. To address this, we developed a simulation-based inference framework\nthat employs vision transformer-driven variational encoding to generate compact\nrepresentations of the data, exploiting the inherent contextual dependencies.\nThese representations are subsequently integrated into a likelihood-free\nBayesian approach for parameter inference. The central idea is to construct a\nfine-grained, structured mesh of latent representations from simulated dynamics\nthrough systematic exploration of the parameter space. This encoded mesh of\nlatent embeddings then serves as a reference map for retrieving parameter\nvalues that correspond to observed data. By integrating generative modeling\nwith Bayesian principles, our approach provides a unified inference framework\nto identify both spatial and temporal patterns that manifest in multivariate\ndynamical systems."}
{"id": "2507.22146", "pdf": "https://arxiv.org/pdf/2507.22146", "abs": "https://arxiv.org/abs/2507.22146", "authors": ["Joy Bose"], "title": "Pendulum Model of Spiking Neurons", "categories": ["cs.NE", "q-bio.NC", "C.1.3; I.5.1; I.6.3"], "comment": "5 pages, 2 figures, 1 table", "summary": "We propose a biologically inspired model of spiking neurons based on the\ndynamics of a damped, driven pendulum. Unlike traditional models such as the\nLeaky Integrate-and-Fire (LIF) neurons, the pendulum neuron incorporates\nsecond-order, nonlinear dynamics that naturally give rise to oscillatory\nbehavior and phase-based spike encoding. This model captures richer temporal\nfeatures and supports timing-sensitive computations critical for sequence\nprocessing and symbolic learning. We present an analysis of single-neuron\ndynamics and extend the model to multi-neuron layers governed by Spike-Timing\nDependent Plasticity (STDP) learning rules. We demonstrate practical\nimplementation with python code and with the Brian2 spiking neural simulator,\nand outline a methodology for deploying the model on neuromorphic hardware\nplatforms, using an approximation of the second-order equations. This framework\noffers a foundation for developing energy-efficient neural systems for\nneuromorphic computing and sequential cognition tasks."}
{"id": "2507.22587", "pdf": "https://arxiv.org/pdf/2507.22587", "abs": "https://arxiv.org/abs/2507.22587", "authors": ["Alexandre Durrmeyer", "Jean-Christophe Palauqui", "Philippe Andrey"], "title": "Deep learning of geometrical cell division rules", "categories": ["cs.LG", "q-bio.CB", "q-bio.QM", "I.2.6; I.6; J.3"], "comment": "44 pages, 6 figures, 1 supplementary table, 15 supplementary figures", "summary": "The positioning of new cellular walls during cell division plays a key role\nin shaping plant tissue organization. The influence of cell geometry on the\npositioning of division planes has been previously captured into various\ngeometrical rules. Accordingly, linking cell shape to division orientation has\nrelied on the comparison between observed division patterns and predictions\nunder specific rules. The need to define a priori the tested rules is a\nfundamental limitation of this hypothesis-driven approach. As an alternative,\nwe introduce a data-based approach to investigate the relation between cell\ngeometry and division plane positioning, exploiting the ability of deep neural\nnetwork to learn complex relationships across multidimensional spaces. Adopting\nan image-based cell representation, we show how division patterns can be\nlearned and predicted from mother cell geometry using a UNet architecture\nmodified to operate on cell masks. Using synthetic data and A. thaliana embryo\ncells, we evaluate the model performances on a wide range of diverse cell\nshapes and division patterns. We find that the trained model accounted for\nembryo division patterns that were previously irreconcilable under existing\ngeometrical rules. Our work shows the potential of deep networks to understand\ncell division patterns and to generate new hypotheses on the control of cell\ndivision positioning."}
{"id": "2507.22710", "pdf": "https://arxiv.org/pdf/2507.22710", "abs": "https://arxiv.org/abs/2507.22710", "authors": ["Filippo Utro", "Meltem Tolunay", "Kahn Rhrissorrakrai", "Tanvi P. Gujarati", "Jie Shi", "Sara Capponi", "Mirko Amico", "Nate Earnest-Noble", "Laxmi Parida"], "title": "Enhanced Prediction of CAR T-Cell Cytotoxicity with Quantum-Kernel Methods", "categories": ["cs.LG", "q-bio.QM", "quant-ph"], "comment": null, "summary": "Chimeric antigen receptor (CAR) T-cells are T-cells engineered to recognize\nand kill specific tumor cells. Through their extracellular domains, CAR T-cells\nbind tumor cell antigens which triggers CAR T activation and proliferation.\nThese processes are regulated by co-stimulatory domains present in the\nintracellular region of the CAR T-cell. Through integrating novel signaling\ncomponents into the co-stimulatory domains, it is possible to modify CAR T-cell\nphenotype. Identifying and experimentally testing new CAR constructs based on\nlibraries of co-stimulatory domains is nontrivial given the vast combinatorial\nspace defined by such libraries. This leads to a highly data constrained,\npoorly explored combinatorial problem, where the experiments undersample all\npossible combinations. We propose a quantum approach using a Projected Quantum\nKernel (PQK) to address this challenge. PQK operates by embedding classical\ndata into a high dimensional Hilbert space and employs a kernel method to\nmeasure sample similarity. Using 61 qubits on a gate-based quantum computer, we\ndemonstrate the largest PQK application to date and an enhancement in the\nclassification performance over purely classical machine learning methods for\nCAR T cytotoxicity prediction. Importantly, we show improved learning for\nspecific signaling domains and domain positions, particularly where there was\nlower information highlighting the potential for quantum computing in\ndata-constrained problems."}
