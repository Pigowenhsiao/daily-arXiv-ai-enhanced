{"id": "2511.16456", "pdf": "https://arxiv.org/pdf/2511.16456", "abs": "https://arxiv.org/abs/2511.16456", "authors": ["German Mino Galaz", "Javier Patino Baez", "Nicolas Mino Berdu", "Jose Gonzalez Suarez"], "title": "Entropy Transfer Throughout the Structure of PDZ-2 and TIM-Barrel Proteins. A Dynamic Gaussian Network Model Study", "categories": ["q-bio.BM"], "comment": "8 Figures", "summary": "This research reports the entropy transfer throughout the tridimensional structure of PDZ-2 and TIM barrel structures using the dynamic Gaussian Network Model. The model predicts the allocation of the allosteric pathways of the PDZ-2. Moreover. A visualization analysis reveals that entropy and information is transported towards the effector site in PDZ-2 and near to the catalytic site of the TIM-Barrel protein. The results suggest the presence of a functional hierarchy that determine information and entropy flow directionality."}
{"id": "2511.15906", "pdf": "https://arxiv.org/pdf/2511.15906", "abs": "https://arxiv.org/abs/2511.15906", "authors": ["Matthieu Kirchmeyer", "Pedro O. Pinheiro", "Emma Willett", "Karolis Martinkus", "Joseph Kleinhenz", "Emily K. Makowski", "Andrew M. Watkins", "Vladimir Gligorijevic", "Richard Bonneau", "Saeed Saremi"], "title": "Unified all-atom molecule generation with neural fields", "categories": ["cs.LG", "q-bio.BM"], "comment": "NeurIPS 2025", "summary": "Generative models for structure-based drug design are often limited to a specific modality, restricting their broader applicability. To address this challenge, we introduce FuncBind, a framework based on computer vision to generate target-conditioned, all-atom molecules across atomic systems. FuncBind uses neural fields to represent molecules as continuous atomic densities and employs score-based generative models with modern architectures adapted from the computer vision literature. This modality-agnostic representation allows a single unified model to be trained on diverse atomic systems, from small to large molecules, and handle variable atom/residue counts, including non-canonical amino acids. FuncBind achieves competitive in silico performance in generating small molecules, macrocyclic peptides, and antibody complementarity-determining region loops, conditioned on target structures. FuncBind also generated in vitro novel antibody binders via de novo redesign of the complementarity-determining region H3 loop of two chosen co-crystal structures. As a final contribution, we introduce a new dataset and benchmark for structure-conditioned macrocyclic peptide generation. The code is available at https://github.com/prescient-design/funcbind."}
{"id": "2511.15721", "pdf": "https://arxiv.org/pdf/2511.15721", "abs": "https://arxiv.org/abs/2511.15721", "authors": ["Laurinne J Balstad", "Joe Brennan", "Marissa L. Baskett", "Mattea K. Berglund", "Mei Z. Blundell", "Jessica A. Bolin", "Amy A. Briggs", "Mary C. Fisher", "Christopher M. Heggerud", "Madeline Jarvis-Cross", "Lauren Mossman", "Andrea N. Odell", "Jennifer Paige", "Sophia Pelletier", "Mikaela M. Provost"], "title": "10 simple rules for data-model integration in theoretical ecology", "categories": ["q-bio.PE"], "comment": null, "summary": "Theoretical ecologists have long leveraged empirical data in various forms to advance ecology. Recently increased volumes and access to ecological data present an expanding set of opportunities for theoreticians to inform model development, framing, and interpretation. Whereas statisticians have collective guidance on best practices for data use, theoreticians might lack formal education on how to integrate diverse types of data into a single ecological model. As a group of predominantly early-career theoretical ecologists, we have developed guiding principles and practical tips to support theoretical ecologists in synthesizing multiple types of data at different phases of the modeling process. Our rules fall into three overarching themes: iteration in the data-model integration process, leveraging multiple sources of data), and understanding uncertainty. Across these rules, we emphasize that the data-model integration requires transparent, justifiable, and defensible communication of modeling choices to support readers in appropriately contextualizing the model and its implications."}
{"id": "2511.15985", "pdf": "https://arxiv.org/pdf/2511.15985", "abs": "https://arxiv.org/abs/2511.15985", "authors": ["Gabriel Marghoti", "Thiago L. Prado", "Miguel A. F. Sanjuán", "Sergio R. Lopes"], "title": "Beat Frequency Induced Transitions in Synchronization Dynamics", "categories": ["q-bio.NC", "nlin.PS"], "comment": null, "summary": "In neurosciences, the brain processes information via the firing patterns of connected neurons operating across a spectrum of frequencies. To better understand the effects of these frequencies in the neuron dynamics, we have simulated a neuronal network of Izhikevich neurons to examine the interaction between frequency allocation and intermittent phase synchronization dynamics. As the synchronized population of neurons passes through a bifurcation, an additional frequency mode emerges, enabling a match in the mean frequency while retaining distinct most probable frequencies among neurons. Subsequently, the network intermittently transits between two patterns, one partially synchronized and the other unsynchronized. Through our analysis, we demonstrate that the frequency changes on the network lead to characteristic transition times between synchronization states. Moreover, these transitions adhere to beat frequency statistics when the neurons' frequencies differ by multiples of a frequency gap. Finally, our results can improve the performance in predicting transitions on problems where the beat frequency strongly influences the dynamics."}
{"id": "2511.15977", "pdf": "https://arxiv.org/pdf/2511.15977", "abs": "https://arxiv.org/abs/2511.15977", "authors": ["Daniel Mas Montserrat", "Ray Verma", "Míriam Barrabés", "Francisco M. de la Vega", "Carlos D. Bustamante", "Alexander G. Ioannidis"], "title": "Efficient Chromosome Parallelization for Precision Medicine Genomic Workflows", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF", "q-bio.GN"], "comment": "Accepted at AAAI 2026", "summary": "Large-scale genomic workflows used in precision medicine can process datasets spanning tens to hundreds of gigabytes per sample, leading to high memory spikes, intensive disk I/O, and task failures due to out-of-memory errors. Simple static resource allocation methods struggle to handle the variability in per-chromosome RAM demands, resulting in poor resource utilization and long runtimes. In this work, we propose multiple mechanisms for adaptive, RAM-efficient parallelization of chromosome-level bioinformatics workflows. First, we develop a symbolic regression model that estimates per-chromosome memory consumption for a given task and introduces an interpolating bias to conservatively minimize over-allocation. Second, we present a dynamic scheduler that adaptively predicts RAM usage with a polynomial regression model, treating task packing as a Knapsack problem to optimally batch jobs based on predicted memory requirements. Additionally, we present a static scheduler that optimizes chromosome processing order to minimize peak memory while preserving throughput. Our proposed methods, evaluated on simulations and real-world genomic pipelines, provide new mechanisms to reduce memory overruns and balance load across threads. We thereby achieve faster end-to-end execution, showcasing the potential to optimize large-scale genomic workflows."}
{"id": "2511.15839", "pdf": "https://arxiv.org/pdf/2511.15839", "abs": "https://arxiv.org/abs/2511.15839", "authors": ["Mohammed A. Y. Mohammed", "Hamed Karami", "Gerardo Chowell"], "title": "Comparing Bayesian and Frequentist Inference in Biological Models: A Comparative Analysis of Accuracy, Uncertainty, and Identifiability", "categories": ["q-bio.QM"], "comment": "59 pages, 19 figures, 29 tables", "summary": "Mathematical models support inference and forecasting in ecology and epidemiology, but results depend on the estimation framework. We compare Bayesian and Frequentist approaches across three biological models using four datasets: Lotka-Volterra predator-prey dynamics (Hudson Bay), a generalized logistic model (lung injury and 2022 U.S. mpox), and an SEIUR epidemic model (COVID-19 in Spain). Both approaches use a normal error structure to ensure a fair comparison.\n  We first assessed structural identifiability to determine which parameters can theoretically be recovered from the data. We then evaluated practical identifiability and forecasting performance using four metrics: mean absolute error (MAE), mean squared error (MSE), 95 percent prediction interval (PI) coverage, and weighted interval score (WIS). For the Lotka-Volterra model with both prey and predator data, we analyzed three scenarios: prey only, predator only, and both.\n  The Frequentist workflow used QuantDiffForecast (QDF) in MATLAB, which fits ODE models via nonlinear least squares and quantifies uncertainty through parametric bootstrap. The Bayesian workflow used BayesianFitForecast (BFF), which employs Hamiltonian Monte Carlo sampling via Stan to generate posterior distributions and diagnostics such as the Gelman-Rubin R-hat statistic.\n  Results show that Frequentist inference performs best when data are rich and fully observed, while Bayesian inference excels when latent-state uncertainty is high and data are sparse, as in the SEIUR COVID-19 model. Structural identifiability clarifies these patterns: full observability benefits both frameworks, while limited observability constrains parameter recovery. This comparison provides guidance for choosing inference frameworks based on data richness, observability, and uncertainty needs."}
{"id": "2511.16618", "pdf": "https://arxiv.org/pdf/2511.16618", "abs": "https://arxiv.org/abs/2511.16618", "authors": ["Haofeng Liu", "Ziyue Wang", "Sudhanshu Mishra", "Mingqi Gao", "Guanyi Qin", "Chang Han Low", "Alex Y. W. Kong", "Yueming Jin"], "title": "SAM2S: Segment Anything in Surgical Videos via Semantic Long-term Tracking", "categories": ["cs.CV", "eess.IV", "q-bio.TO"], "comment": "11 pages, 4 figures", "summary": "Surgical video segmentation is crucial for computer-assisted surgery, enabling precise localization and tracking of instruments and tissues. Interactive Video Object Segmentation (iVOS) models such as Segment Anything Model 2 (SAM2) provide prompt-based flexibility beyond methods with predefined categories, but face challenges in surgical scenarios due to the domain gap and limited long-term tracking. To address these limitations, we construct SA-SV, the largest surgical iVOS benchmark with instance-level spatio-temporal annotations (masklets) spanning eight procedure types (61k frames, 1.6k masklets), enabling comprehensive development and evaluation for long-term tracking and zero-shot generalization. Building on SA-SV, we propose SAM2S, a foundation model enhancing \\textbf{SAM2} for \\textbf{S}urgical iVOS through: (1) DiveMem, a trainable diverse memory mechanism for robust long-term tracking; (2) temporal semantic learning for instrument understanding; and (3) ambiguity-resilient learning to mitigate annotation inconsistencies across multi-source datasets. Extensive experiments demonstrate that fine-tuning on SA-SV enables substantial performance gains, with SAM2 improving by 12.99 average $\\mathcal{J}$\\&$\\mathcal{F}$ over vanilla SAM2. SAM2S further advances performance to 80.42 average $\\mathcal{J}$\\&$\\mathcal{F}$, surpassing vanilla and fine-tuned SAM2 by 17.10 and 4.11 points respectively, while maintaining 68 FPS real-time inference and strong zero-shot generalization. Code and dataset will be released at https://jinlab-imvr.github.io/SAM2S."}
{"id": "2511.15736", "pdf": "https://arxiv.org/pdf/2511.15736", "abs": "https://arxiv.org/abs/2511.15736", "authors": ["Fabio Rapallo", "Enrico Scalas", "Pietro Terna"], "title": "How many outbreaks before an epidemic?", "categories": ["q-bio.PE", "math.PR", "math.ST"], "comment": "19 pages, 4 figures", "summary": "In this work, we study the finite-population behaviour of the Reed-Frost epidemic model. Our analysis relies on the exact expression for the final epidemic size, replaced by Monte Carlo simulations in cases where the exact formula becomes numerically unstable. When the initial reproduction number is greater than a critical threshold, the distribution of the final size becomes bimodal. We therefore define the probabilities of small and large outbreaks, providing an intuitive answer to the question posed in the title through simple arguments based on the geometric distribution. Finally, an agent-based simulation confirms that the Reed-Frost model offers a good approximation in the case of the COVID-19 outbreak."}
{"id": "2511.16432", "pdf": "https://arxiv.org/pdf/2511.16432", "abs": "https://arxiv.org/abs/2511.16432", "authors": ["Claudius Gros"], "title": "From generative AI to the brain: five takeaways", "categories": ["cs.AI", "q-bio.NC"], "comment": "Frontiers in Computational Neuroscience, in press", "summary": "The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research."}
{"id": "2511.15932", "pdf": "https://arxiv.org/pdf/2511.15932", "abs": "https://arxiv.org/abs/2511.15932", "authors": ["Changin Oh", "Kathleen P. Wilkie"], "title": "How Mathematical Forms of Chemotherapy and Radiotherapy Bias Model-Optimized Predictions: Implications for Model Selection", "categories": ["q-bio.QM"], "comment": "38 pages, 15 figures, 4 tables", "summary": "The move towards personalized treatment and digital twins for cancer therapy requires a complete understanding of the mathematical models upon which these optimized simulation-based strategies are formulated. This study investigates the influence of mathematical model selection on the optimization of chemotherapy and radiotherapy protocols. By examining three chemotherapy models (log-kill, Norton-Simon, and Emax), and three radiotherapy models (linear-quadratic, proliferation saturation index, and continuous death-rate), we identify similarities and significant differences in the optimized protocols. We demonstrate how the assumptions built into the model formulations heavily influence optimal treatment dosing and sequencing, potentially leading to contradictory results. Further, we demonstrate how different model forms influence predictions in the adaptive therapy setting. As treatment decisions increasingly rely on simulation-based strategies, unexamined model assumptions can introduce bias, leading to model-dependent recommendations that may not be generalizable. This study highlights the importance of basing model selection on a full analysis of bias, sensitivity, practical parameter identifiability and/or inferred parameter posteriors, as a part of the uncertainty quantification process, rather than solely relying on information criterion. Understanding how model choice impacts predictions guiding personalized treatment planning with sufficient uncertainty quantification analysis, will lead to more robust and generalizable predictions."}
{"id": "2511.16179", "pdf": "https://arxiv.org/pdf/2511.16179", "abs": "https://arxiv.org/abs/2511.16179", "authors": ["Ihtisham Ul Haq", "Serge Richard"], "title": "Age-structured model of dengue transmission dynamics with time-varying parameters, and its application to Brazil", "categories": ["q-bio.PE", "math.AP"], "comment": null, "summary": "An age structured mathematical model with time dependent parameters is developed to investigate the dynamics of dengue transmission. Its properties are thoroughly analyzed in the first part of this work, as for example its disease free steady state, the corresponding effective reproduction numbers, its basic reproduction number (obtained via the Euler and Lotka equation and the next generation matrix approach). We also provide formulas for the time-varying effective reproduction number, and draw relations with the instantaneous growth rate. In the second part, we apply this model to Brazil and use weekly time series data from this country. Various medical parameters are firstly evaluated from these data, and an extensive numerical simulations for the period 2021 to 2024 is then carried out. Estimation of the transmission rates are derived both from epidemiological data and from environmental data such as temperature and humidity. The time-varying effective reproduction numbers are then estimated on these data, following the theoretical investigations performed in the first part. The sensitive parameters that significantly affect the model dynamics are presented graphically. Model predictions for following year by using different transmission rates are finally presented. Our findings show the importance of population age distribution, vector population dynamics, and climate, contributing to a deeper understanding of dengue transmission dynamics in Brazil."}
{"id": "2511.16465", "pdf": "https://arxiv.org/pdf/2511.16465", "abs": "https://arxiv.org/abs/2511.16465", "authors": ["Boshuo Wang", "Torge Worbs", "Minhaj A. Hussain", "Aman S. Aberra", "Axel Thielscher", "Warren M. Grill", "Angel V. Peterchev"], "title": "Mesoscale tissue properties and electric fields in brain stimulation - bridging the macroscopic and microscopic scales", "categories": ["physics.bio-ph", "physics.app-ph", "physics.med-ph", "q-bio.NC"], "comment": "16 pages, 1 main figure, 6 appendix figures and 4 appendix tables", "summary": "Accurate simulations of electric fields (E-fields) in brain stimulation depend on tissue conductivity representations that link macroscopic assumptions with underlying microscopic tissue structure. Mesoscale conductivity variations can produce meaningful changes in E-fields and neural activation thresholds but remain largely absent from standard macroscopic models. Recent microscopic models have suggested substantial local E-field perturbations and could, in principle, inform mesoscale conductivity. However, the quantitative validity of microscopic models is limited by fixation-related tissue distortion and incomplete extracellular-space reconstruction. We outline approaches that bridge macro- and microscales to derive consistent mesoscale conductivity distributions, providing a foundation for accurate multiscale models of E-fields and neural activation in brain stimulation."}
{"id": "2511.16113", "pdf": "https://arxiv.org/pdf/2511.16113", "abs": "https://arxiv.org/abs/2511.16113", "authors": ["Hongfu Lou"], "title": "ProtT-Affinity: Sequence-Based Protein-Protein Binding Affinity Prediction Using ProtT5 Embeddings", "categories": ["q-bio.QM"], "comment": "9 pages, 2 figures", "summary": "Predicting the binding affinity of protein protein complexes directly from sequence remains a challenging problem, particularly in the absence of reliable structural information. Here I present ProtT Affinity, a sequence only model that combines ProtT5 embeddings with a lightweight Transformer architecture. The model is trained and evaluated on homology filtered subsets of the PDBBind database following a curation protocol consistent with prior structure based work. Across two independent test sets,ProtT Affinity reaches Pearson correlation coefficients of 0.628 and 0.459, respectively.Although its performance does not match the strongest structure based methods, it is competitive with several widely used approaches and provides a practical alternative when structural data are missing or uncertain. The results suggest that large protein language models capture features relevant to binding energetics, and that these features can be exploited to approximate affinity trends at scale."}
{"id": "2511.16268", "pdf": "https://arxiv.org/pdf/2511.16268", "abs": "https://arxiv.org/abs/2511.16268", "authors": ["Erwan Dereure", "Robin Louiset", "Laura Parkkinen", "David A Menassa", "David Holcman"], "title": "Weakly Supervised Segmentation and Classification of Alpha-Synuclein Aggregates in Brightfield Midbrain Images", "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "comment": null, "summary": "Parkinson's disease (PD) is a neurodegenerative disorder associated with the accumulation of misfolded alpha-synuclein aggregates, forming Lewy bodies and neuritic shape used for pathology diagnostics. Automatic analysis of immunohistochemistry histopathological images with Deep Learning provides a promising tool for better understanding the spatial organization of these aggregates. In this study, we develop an automated image processing pipeline to segment and classify these aggregates in whole-slide images (WSIs) of midbrain tissue from PD and incidental Lewy Body Disease (iLBD) cases based on weakly supervised segmentation, robust to immunohistochemical labelling variability, with a ResNet50 classifier. Our approach allows to differentiate between major aggregate morphologies, including Lewy bodies and neurites with a balanced accuracy of $80\\%$. This framework paves the way for large-scale characterization of the spatial distribution and heterogeneity of alpha-synuclein aggregates in brightfield immunohistochemical tissue, and for investigating their poorly understood relationships with surrounding cells such as microglia and astrocytes."}
