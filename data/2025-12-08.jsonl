{"id": "2512.05245", "pdf": "https://arxiv.org/pdf/2512.05245", "abs": "https://arxiv.org/abs/2512.05245", "authors": ["Mehmet Efe Akça", "Gökçe Uludoğan", "Arzucan Özgür", "İnci M. Baytaş"], "title": "STAR-GO: Improving Protein Function Prediction by Learning to Hierarchically Integrate Ontology-Informed Semantic Embeddings", "categories": ["q-bio.BM", "cs.LG"], "comment": "14 pages, 2 figures, 6 tables", "summary": "Accurate prediction of protein function is essential for elucidating molecular mechanisms and advancing biological and therapeutic discovery. Yet experimental annotation lags far behind the rapid growth of protein sequence data. Computational approaches address this gap by associating proteins with Gene Ontology (GO) terms, which encode functional knowledge through hierarchical relations and textual definitions. However, existing models often emphasize one modality over the other, limiting their ability to generalize, particularly to unseen or newly introduced GO terms that frequently arise as the ontology evolves, and making the previously trained models outdated. We present STAR-GO, a Transformer-based framework that jointly models the semantic and structural characteristics of GO terms to enhance zero-shot protein function prediction. STAR-GO integrates textual definitions with ontology graph structure to learn unified GO representations, which are processed in hierarchical order to propagate information from general to specific terms. These representations are then aligned with protein sequence embeddings to capture sequence-function relationships. STAR-GO achieves state-of-the-art performance and superior zero-shot generalization, demonstrating the utility of integrating semantics and structure for robust and adaptable protein function prediction. Code is available at https://github.com/boun-tabi-lifelu/stargo."}
{"id": "2512.05190", "pdf": "https://arxiv.org/pdf/2512.05190", "abs": "https://arxiv.org/abs/2512.05190", "authors": ["Farshid Jafarpour"], "title": "Exactly Solvable Population Model with Square-Root Growth Noise and Cell-Size Regulation", "categories": ["q-bio.PE", "cond-mat.stat-mech", "math.PR"], "comment": null, "summary": "We analyze a size-structured branching process in which individual cells grow exponentially according to a Feller square-root process and divide under general size-control mechanisms. We obtain exact expressions for the asymptotic population growth rate, the steady-state snapshot distribution of cell sizes, and the fluctuations of the total cell number. Our first result is that the population growth rate is exactly equal to the mean single-cell growth rate, for all noise strengths and for all division and size-regulation schemes that maintain size homeostasis. Thus square-root growth noise is neutral with respect to long-term fitness, in sharp contrast to models with size-independent stochastic growth rates. Second, we show that the steady-state population cell-size distribution is obtained from the deterministic inverse-square-law solution by a one-sided exponential convolution with kernel width set by the strength of growth fluctuations. Third, the mean-rescaled population size $N_t/\\left\\langle N_t\\right\\rangle$ converges to a stationary compound Poisson-exponential distribution that depends only on growth noise. This distribution, and hence the long-time shape of population-size fluctuations, is unchanged by division-size noise or asymmetric partitioning. These results identify Feller-type exponential growth with square-root noise as an exactly solvable benchmark for stochastic growth in size-controlled populations and provide concrete signatures that distinguish it from models with size-independent growth-rate noise."}
{"id": "2512.05208", "pdf": "https://arxiv.org/pdf/2512.05208", "abs": "https://arxiv.org/abs/2512.05208", "authors": ["Alex Zhavoronkov", "Dominika Wilczok"], "title": "Peakspan: Defining, Quantifying and Extending the Boundaries of Peak Productive Lifespan", "categories": ["q-bio.QM", "econ.GN"], "comment": null, "summary": "The unprecedented extension of the human lifespan necessitates a parallel evolution in how we quantify the quality of aging and its socioeconomic impact. Traditional metrics focusing on Healthspan (years free of disease) overlook the gradual erosion of physiological capacity that occurs even in the absence of illness, leading to declines in productivity and eventual lack of capacity to work. To address this critical gap, we introduce Peakspan: the age interval during which an individual maintains at least 90% of their peak functional performance in a specific physiological or cognitive domain. Our multi-system analysis reveals a profound misalignment: most biological systems reach maximal capacity in early adulthood, resulting in a Peakspan that is remarkably short relative to the total lifespan. This dissociation means humans now spend the majority of their adult lives in a \"healthy but declined\" state, characterized by a significant functional gap. We argue that extending Peakspan and developing strategies to restore function in post-peak individuals is the functional manifestation of rejuvenative biomedical progress and is essential for sustained economic growth in aging societies. Recognizing and tracking Peakspan, increasingly facilitated by artificial intelligence and foundational models of biological aging, is crucial for developing strategies to compress functional morbidity and maximize human potential across the life course."}
{"id": "2512.05499", "pdf": "https://arxiv.org/pdf/2512.05499", "abs": "https://arxiv.org/abs/2512.05499", "authors": ["Yun Deng", "Shing H. Zhan", "Yulin Zhang", "Chao Zhang", "Bingjie Chen"], "title": "Tree Thinking in the Genomic Era: Unifying Models Across Cells, Populations, and Species", "categories": ["q-bio.PE"], "comment": null, "summary": "The ongoing explosion of genome sequence data is transforming how we reconstruct and understand the histories of biological systems. Across biological scales, from individual cells to populations and species, trees-based models provide a common framework for representing ancestry. Once limited to species phylogenetics, \"tree thinking\" now extends deeply to population genomics and cell biology, revealing the genealogical structure of genetic and phenotypic variation within and across organisms. Recently, there have been great methodological and computational advances on tree-based methods, including methods for inferring ancestral recombination graphs in populations, phylogenetic frameworks for comparative genomics, and lineage-tracing techniques in developmental and cancer biology. Despite differences in data types and biological contexts, these approaches share core statistical and algorithmic challenges: efficiently inferring branching histories from genomic information, integrating temporal and spatial signals, and connecting genealogical structures to evolutionary and functional processes. Recognizing these shared foundations opens opportunities for cross-fertilization between fields that are traditionally studied in isolation. By examining how tree-based methods are applied across cellular, population, and species scales, we identify the conceptual parallels that unite them and the distinct challenges that each domain presents. These comparisons offer new perspectives that can inform algorithmic innovations and lead to more powerful inference strategies across the full spectrum of biological systems."}
{"id": "2512.05649", "pdf": "https://arxiv.org/pdf/2512.05649", "abs": "https://arxiv.org/abs/2512.05649", "authors": ["Khayrul Islam", "Mehedi Hasan", "Yaling Liu"], "title": "Physics-Guided Surrogate Modeling for Machine Learning-Driven DLD Design Optimization", "categories": ["q-bio.QM"], "comment": "33 pages, 5 figures", "summary": "Sorting cells based on their mechanical properties is essential for applications in disease diagnostics, cell therapy, and biomedical research. Deterministic Lateral Displacement (DLD) devices provide a label-free method for achieving such sorting, but their performance is highly sensitive to cell size and deformability. Designing effective DLD geometries often demands extensive trial-and-error experimentation, as even small variations in cellular mechanical traits can cause significant changes in migration behavior. To address this challenge, we propose a simulation-driven machine learning (ML) framework that predicts suitable DLD design candidates for a given cell type. Our approach integrates high-fidelity particle-based simulations to model cell deformation and migration through microfluidic pillar arrays with supervised ML models trained to estimate optimal geometries. By mapping mechanical parameters such as bending rigidity and shear modulus to deformation index and migration angle, the framework enables rapid, data-informed design of DLD systems. We also demonstrate a deployable web interface to make this tool accessible for real-world device prototyping."}
{"id": "2512.05856", "pdf": "https://arxiv.org/pdf/2512.05856", "abs": "https://arxiv.org/abs/2512.05856", "authors": ["Jorge Hidalgo", "Lorenzo Fant", "Rafael Rubio de Casas", "Miguel A. Muñoz"], "title": "Fluctuating Environments Favor Extreme Dormancy Strategies and Penalize Intermediate Ones", "categories": ["q-bio.PE", "cond-mat.stat-mech", "physics.bio-ph"], "comment": "12 pages, 11 figures", "summary": "Dormancy is a widespread adaptive strategy that enables populations to persist in fluctuating environments, yet how its benefits depend on the temporal structure of environmental variability remains unclear. We examine how dormancy interacts with environmental correlation times using a delayed-logistic model in which dormant individuals reactivate after a fixed lag while birth rates fluctuate under temporally correlated stochasticity. Numerical simulations and analytical calculations show that the combination of demographic memory and colored multiplicative noise generates a strongly non-monotonic dependence of fitness on dormancy duration, with three distinct performance regimes. Very short dormancy maximizes linear growth but amplifies fluctuations and extinction risk. Very long dormancy buffers environmental variability, greatly increasing mean extinction times despite slower growth. Strikingly, we find a broad band of intermediate dormancy durations that is maladaptive, simultaneously reducing both growth and persistence due to a mismatch between delay times and environmental autocorrelation. An evolutionary agent-based model confirms bistability between short- and long-dormancy strategies, which avoid intermediate lag times and evolve toward stable extremes. These results show that dormancy duration is not merely a life-history parameter but an adaptive mechanism tuned to environmental timescales, and that intermediate \"dangerous middle\" strategies can be inherently disfavored. More broadly, this work identifies a generic mechanism by which demographic delays interacting with correlated environmental variability produce a non-monotonic fitness landscape that selects for extreme timing strategies."}
{"id": "2512.05247", "pdf": "https://arxiv.org/pdf/2512.05247", "abs": "https://arxiv.org/abs/2512.05247", "authors": ["Spencer Gibson", "Yun William Yu"], "title": "Incorporating indel channels into average-case analysis of seed-chain-extend", "categories": ["cs.DS", "q-bio.QM"], "comment": "25 pages (10 page main text + 2 page biblio + 13 page appendix); conference submission", "summary": "Given a sequence $s_1$ of $n$ letters drawn i.i.d. from an alphabet of size $σ$ and a mutated substring $s_2$ of length $m < n$, we often want to recover the mutation history that generated $s_2$ from $s_1$. Modern sequence aligners are widely used for this task, and many employ the seed-chain-extend heuristic with $k$-mer seeds. Previously, Shaw and Yu showed that optimal linear-gap cost chaining can produce a chain with $1 - O\\left(\\frac{1}{\\sqrt{m}}\\right)$ recoverability, the proportion of the mutation history that is recovered, in $O\\left(mn^{2.43θ} \\log n\\right)$ expected time, where $θ< 0.206$ is the mutation rate under a substitution-only channel and $s_1$ is assumed to be uniformly random. However, a gap remains between theory and practice, since real genomic data includes insertions and deletions (indels), and yet seed-chain-extend remains effective. In this paper, we generalize those prior results by introducing mathematical machinery to deal with the two new obstacles introduced by indel channels: the dependence of neighboring anchors and the presence of anchors that are only partially correct. We are thus able\n  to prove that the expected recoverability of an optimal chain is $\\ge 1 - O\\Bigl(\\frac{1}{\\sqrt{m}}\\Bigr)$ and the expected runtime is $O(mn^{3.15 \\cdot θ_T}\\log n)$, when the total mutation rate given by the sum of the substitution, insertion, and deletion mutation rates ($θ_T = θ_i + θ_d + θ_s$) is less than $0.159$."}
{"id": "2512.05889", "pdf": "https://arxiv.org/pdf/2512.05889", "abs": "https://arxiv.org/abs/2512.05889", "authors": ["Jiayi Li", "Zhihua Liu", "Zihan Wang"], "title": "The Effective Reproduction Number in the Kermack-McKendrick model with age of infection and reinfection", "categories": ["q-bio.PE"], "comment": null, "summary": "This study introduces a novel epidemiological model that expands upon the Kermack-McKendrick model by incorporating the age of infection and reinfection. By including infection age, we can classify participants, which enables a more targeted analysis within the modeling framework. The reinfection term addresses the real-world occurrences of secondary or recurrent viral infections. In the theoretical part, we apply the contraction mapping principle, the dominated convergence theorem, and the properties of Volterra integral equations to derive analytical expressions for the number of newly infected individuals denoted by $N(t)$. Then, we establish a Volterra integral equation for $N(t)$ and study its initial conditions for both a single cohort and multiple cohorts. From this equation, we derive a method for identifying the effective reproduction number, denoted as $\\mathcal{R}(t)$. In the practical aspect, we present two distinct methods and separately apply them to analyze the daily new infection cases from the 2003 SARS outbreak in Singapore and the cumulative number of deaths from the COVID-19 epidemic in China. This work effectively bridges theoretical epidemiology and computational modeling, providing a robust framework for analyzing infection dynamics influenced by infection-age-structured transmission and reinfection mechanisms."}
{"id": "2512.05256", "pdf": "https://arxiv.org/pdf/2512.05256", "abs": "https://arxiv.org/abs/2512.05256", "authors": ["Ivan Makohon", "Mohamad Najafi", "Jian Wu", "Mathias Brochhausen", "Yaohang Li"], "title": "Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4", "categories": ["cs.CL", "q-bio.QM"], "comment": null, "summary": "In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts."}
{"id": "2512.05305", "pdf": "https://arxiv.org/pdf/2512.05305", "abs": "https://arxiv.org/abs/2512.05305", "authors": ["Andrew P. Ingersoll"], "title": "The Great Oxidation Event (GOE): Biogeochemical Feedback and Tipping Points", "categories": ["physics.ao-ph", "q-bio.PE"], "comment": "15 pages, 3 figures", "summary": "Approximately 1.4 Ga after life first appeared, atmospheric oxygen suddenly jumped by more than an order of magnitude over a 20-50 Ma period. The contrast between these two timescales does not seem to be due to any sudden, large amplitude change in external forcing. However, it could be due to processes intrinsic to the geobiological system itself, namely, positive feedback between atmospheric oxygen and photosynthetic bacteria: More oxygen leads to more photosynthesis, which leads to more oxygen, and so on. Already-published feedbacks include buildup of an ozone shield and nutrient production by oxidative weathering. The feedback proposed here is the 15-fold greater efficiency of aerobic vs anaerobic respiration and the tight coupling of respiration and photosynthesis inside the cell. As in the climate system, feedback leads to tipping points, where a rapid, large amplitude change in the state of the system occurs. For the geobiological system, the GOE is the tipping point, and the long buildup before the GOE is the gradual oxidation of the crust and ocean, due either to burial of organic matter, oxidation of volcanic gases, or escape of hydrogen to space. The feedback hypothesis is a framework for interpreting observations leading to the GOE."}
{"id": "2512.05346", "pdf": "https://arxiv.org/pdf/2512.05346", "abs": "https://arxiv.org/abs/2512.05346", "authors": ["Neil H. Kim", "Xiao-Liu Chu", "Joseph B. DeGrandchamp", "Matthew R. Foreman"], "title": "Hypothesis-Based Particle Detection for Accurate Nanoparticle Counting and Digital Diagnostics", "categories": ["physics.comp-ph", "physics.med-ph", "physics.optics", "q-bio.QM"], "comment": "Main text (14 pages, 5 figures, 1 table) and supplementary information (5 pages, 3 figures, 2 tables). Supporting code at https://github.com/Optical-Theory-Group/Hypothesis-Test-Based-Particle-Detection", "summary": "Digital assays represent a shift from traditional diagnostics and enable the precise detection of low-abundance analytes, critical for early disease diagnosis and personalized medicine, through discrete counting of biomolecular reporters. Within this paradigm, we present a particle counting algorithm for nanoparticle based imaging assays, formulated as a multiple-hypothesis statistical test under an explicit image-formation model and evaluated using a penalized likelihood rule. In contrast to thresholding or machine learning methods, this approach requires no training data or empirical parameter tuning, and its outputs remain interpretable through direct links to imaging physics and statistical decision theory.\n  Through numerical simulations we demonstrate robust count accuracy across weak signals, variable backgrounds, magnification changes and moderate PSF mismatch. Particle resolvability tests further reveal characteristic error modes, including under-counting at very small separations and localized over-counting near the resolution limit. Practically, we also confirm the algorithm's utility, through application to experimental dark-field images comprising a nanoparticle-based assay for detection of DNA biomarkers derived from SARS-CoV-2. Statistically significant differences in particle count distributions are observed between control and positive samples. Full count statistics obtained further exhibit consistent over-dispersion, and provide insight into non-specific and target-induced particle aggregation. These results establish our method as a reliable framework for nanoparticle-based detection assays in digital molecular diagnostics."}
{"id": "2512.05365", "pdf": "https://arxiv.org/pdf/2512.05365", "abs": "https://arxiv.org/abs/2512.05365", "authors": ["Zag ElSayed", "Craig Erickson", "Ernest Pedapati"], "title": "MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare", "categories": ["cs.AI", "q-bio.QM"], "comment": "6 pages, 4 figures", "summary": "Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments."}
{"id": "2512.05462", "pdf": "https://arxiv.org/pdf/2512.05462", "abs": "https://arxiv.org/abs/2512.05462", "authors": ["Yan-Shiun Wu", "Nathan A. Morin"], "title": "Model Gateway: Model Management Platform for Model-Driven Drug Discovery", "categories": ["cs.SE", "cs.DC", "cs.LG", "q-bio.QM"], "comment": "7 pages, 7 figures", "summary": "This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools."}
{"id": "2512.05573", "pdf": "https://arxiv.org/pdf/2512.05573", "abs": "https://arxiv.org/abs/2512.05573", "authors": ["Fei Zhang", "Weixiong Zhang"], "title": "Refined HLA Linkage Disequilibrium Architectures of World Populations by a Novel Allelic Correlation Measure", "categories": ["q-bio.GN", "q-bio.QM"], "comment": null, "summary": "Numerous diseases, particularly autoimmune disorders, are associated with the human leukocyte antigen (HLA), a small genomic region located on human chromosome 6. Adequate characterization of linkage disequilibrium (LD) in the HLA across populations is crucial for identifying genetic markers associated with specific traits and phenotypes. However, current LD measures often fail to capture HLA's structural complexity due to methodological limitations and sensitivity to low-frequency variants, marginal allele frequencies, and haplotype composition. To address these challenges, we introduced the Conditional Informatics Correlation Coefficient (CICC), which integrates conditional probability, information content, and haplotype-aware XOR logic to quantify LD robustly. When applied to high-resolution haploid genomes from the Human Pangenome Reference Consortium (HPRC), CICC revealed 10 novel high-LD regions in HLA. Further analyses using the 1000 Genomes Project and Genome Asia datasets identified nine strongly linked regions shared across five global populations-five in Class I and four in Class II. These results demonstrate CICC's ability to capture complex HLA LD structures across populations, highlighting its broad potential for disease gene mapping, population genomics, and guiding precision medicine."}
{"id": "2512.05794", "pdf": "https://arxiv.org/pdf/2512.05794", "abs": "https://arxiv.org/abs/2512.05794", "authors": ["Rebonto Haque", "Oliver M. Turnbull", "Anisha Parsan", "Nithin Parsan", "John J. Yang", "Charlotte M. Deane"], "title": "Mechanistic Interpretability of Antibody Language Models Using SAEs", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required."}
