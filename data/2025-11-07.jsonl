{"id": "2511.04174", "pdf": "https://arxiv.org/pdf/2511.04174", "abs": "https://arxiv.org/abs/2511.04174", "authors": ["Guylaine Hoffner", "Philippe Djian"], "title": "Protein aggregation in Huntington's disease", "categories": ["q-bio.BM", "q-bio.NC"], "comment": null, "summary": "The presence of an expanded polyglutamine produces a toxic gain of function\nin huntingtin. Protein aggregation resulting from this gain of function is\nlikely to be the cause of neuronal death. Two main mechanisms of aggregation\nhave been proposed: hydrogen bonding by polar-zipper formation and covalent\nbonding by transglutaminase-catalyzed cross-linking. In cell culture models of\nHuntington's disease, aggregates are mostly stabilized by hydrogen bonds, but\ncovalent bonds are also likely to occur. Nothing is known about the nature of\nthe bonds that stabilize the aggregates in the brain of patients with\nHuntington's disease. It seems that the nature of the bond stabilizing the\naggregates is one of the most important questions, as the answer would\ncondition the therapeutic approach to Huntington's disease."}
{"id": "2511.04040", "pdf": "https://arxiv.org/pdf/2511.04040", "abs": "https://arxiv.org/abs/2511.04040", "authors": ["Xiaoling Luo", "Peng Chen", "Chengliang Liu", "Xiaopeng Jin", "Jie Wen", "Yumeng Liu", "Junsong Wang"], "title": "Enhancing Multimodal Protein Function Prediction Through Dual-Branch Dynamic Selection with Reconstructive Pre-Training", "categories": ["cs.LG", "cs.NE", "q-bio.BM"], "comment": null, "summary": "Multimodal protein features play a crucial role in protein function\nprediction. However, these features encompass a wide range of information,\nranging from structural data and sequence features to protein attributes and\ninteraction networks, making it challenging to decipher their complex\ninterconnections. In this work, we propose a multimodal protein function\nprediction method (DSRPGO) by utilizing dynamic selection and reconstructive\npre-training mechanisms. To acquire complex protein information, we introduce\nreconstructive pre-training to mine more fine-grained information with low\nsemantic levels. Moreover, we put forward the Bidirectional Interaction Module\n(BInM) to facilitate interactive learning among multimodal features.\nAdditionally, to address the difficulty of hierarchical multi-label\nclassification in this task, a Dynamic Selection Module (DSM) is designed to\nselect the feature representation that is most conducive to current protein\nfunction prediction. Our proposed DSRPGO model improves significantly in BPO,\nMFO, and CCO on human datasets, thereby outperforming other benchmark models."}
{"id": "2511.04637", "pdf": "https://arxiv.org/pdf/2511.04637", "abs": "https://arxiv.org/abs/2511.04637", "authors": ["Madison Caballero", "Behrang Mahjani"], "title": "Advancing Risk Gene Discovery Across the Allele Frequency Spectrum", "categories": ["q-bio.GN"], "comment": "Review; 31 pages", "summary": "The discovery of genetic risk factors has transformed human genetics, yet the\npace of new gene identification has slowed despite the exponential expansion of\nsequencing and biobank resources. Current approaches are optimized for the\nextremes of the allele frequency spectrum: rare, high-penetrance variants\nidentified through burden testing, and common, low-effect variants mapped by\ngenome-wide association studies. Between these extremes lies variants of\nintermediate frequency and effect size where statistical power is limited,\npathogenicity is often misclassified, and gene discovery lags behind empirical\nevidence of heritable contribution. This 'missing middle' represents a critical\nblind spot across disease areas, from neurodevelopmental and psychiatric\ndisorders to cancer and aging. In this review, we organize strategies for risk\ngene identification by variant frequency class, highlighting methodological\nstrengths and constraints at each scale. We draw on lessons across fields to\nillustrate how innovations in variant annotation, joint modeling, phenotype\nrefinement, and network-based inference can extend discovery into the\nintermediate range. By framing the frequency spectrum as a unifying axis, we\nprovide a conceptual map of current capabilities, their limitations, and\nemerging directions toward more comprehensive risk gene discovery."}
{"id": "2511.04047", "pdf": "https://arxiv.org/pdf/2511.04047", "abs": "https://arxiv.org/abs/2511.04047", "authors": ["Yoshiyuki Ohmura", "Yasuo Kuniyoshi"], "title": "Why Consciousness Should Explain Physical Phenomena: Toward a Testable Theory", "categories": ["q-bio.NC", "cs.NE"], "comment": null, "summary": "The reductionist approach commonly employed in scientific methods presupposes\nthat both macro and micro phenomena can be explained by micro-level laws alone.\nThis assumption implies intra-level causal closure, rendering all macro\nphenomena epiphenomenal. However, the integrative nature of consciousness\nsuggests that it is a macro phenomenon. To ensure scientific testability and\nreject epiphenomenalism, the reductionist assumption of intra-level causal\nclosure must be rejected. This implies that even neural-level behavior cannot\nbe explained by observable neural-level laws alone. Therefore, a new\nmethodology is necessary to acknowledge the causal efficacy of macro-level\nphenomena. We model the brain as operating under dual laws at different levels.\nThis model includes hypothetical macro-level psychological laws that are not\ndetermined solely by micro-level neural laws, as well as the causal effects\nfrom macro to micro levels. In this study, we propose a constructive approach\nthat explains both mental and physical phenomena through the interaction\nbetween these two sets of laws."}
{"id": "2511.04458", "pdf": "https://arxiv.org/pdf/2511.04458", "abs": "https://arxiv.org/abs/2511.04458", "authors": ["Akhil Ambekar", "Robert Zielinski", "Ani Eloyan"], "title": "TRAECR: A Tool for Preprocessing Positron Emission Tomography Imaging for Statistical Modeling", "categories": ["q-bio.TO", "stat.AP"], "comment": null, "summary": "Positron emission tomography (PET) imaging is widely used in a number of\nclinical applications, including cancer and Alzheimer's disease (AD) diagnosis,\nmonitoring of disease development, and treatment effect evaluation. Statistical\nmodeling of PET imaging is essential to address continually emerging scientific\nquestions in these research fields, including hypotheses related to evaluation\nof effects of disease modifying treatments on amyloid reduction in AD and\nassociations between amyloid reduction and cognitive function, among many\nothers. In this paper, we provide background information and tools for\nstatisticians interested in developing statistical models for PET imaging to\npre-process and prepare data for analysis. We introduce our novel\npre-processing and visualization tool TRAECR (Template registration, MRI-PET\nco-Registration, Anatomical brain Extraction and COMBAT/RAVEL harmonization) to\nfacilitate data preparation for statistical analysis."}
{"id": "2511.03897", "pdf": "https://arxiv.org/pdf/2511.03897", "abs": "https://arxiv.org/abs/2511.03897", "authors": ["Thomas J. Harris", "Prescott C. Alexander", "Anh B. D. Pham", "Joseph Tuccillo", "Nicholas Geard", "Cameron Zachreson"], "title": "Simulating the impact of perception bias on social contact surveys for infectious disease modelling", "categories": ["q-bio.PE"], "comment": null, "summary": "Social contact patterns are a key input to many infectious disease models.\nContact surveys, where participants are asked to provide information on their\nrecent close and casual contacts with others, are one of the standard methods\nto measure contact patterns in a population. Surveys that require detailed\nsociodemographic descriptions of contacts allow for the specification of\nfine-grained contact rates between subpopulations in models. However,\nperception biases affecting a surveyed person's ability to estimate\nsociodemographic attributes (e.g., age, race, socioeconomic status) of others\ncould affect contact rates derived from survey data. Here, we simulate contact\nsurveys using a synthetic contact network of New Mexico to investigate the\nimpact of these biases on survey accuracy and infectious disease model\nprojections. We found that perception biases affecting the estimation of\nanother individual's age and race substantially decreased the accuracy of the\nderived contact patterns. Using these biased patterns in a\nSusceptible-Infectious-Recovered compartmental model lead to an underestimation\nof cumulative incidence among older people (65+ years) and individuals\nidentifying as races other than White. Our study shows that perception biases\ncan impact contact patterns estimated from surveys in ways that systematically\nunderestimate disease burden in minority populations when used in transmission\nmodels."}
{"id": "2511.03751", "pdf": "https://arxiv.org/pdf/2511.03751", "abs": "https://arxiv.org/abs/2511.03751", "authors": ["Hossein Fathollahian", "Siyuan Zhao", "Nafiul Nipu", "G. Elisabeta Marai"], "title": "Attention-based ROI Discovery in 3D Tissue Images", "categories": ["q-bio.QM"], "comment": "2 pages, 3 figures;", "summary": "High-dimensional tissue imaging generates highly complex 3D data containing\nmultiple biomarkers, making it challenging to identify biologically relevant\nregions without an expert user specifying manual labels for regions of\ninterest. We introduce an approach to automatically identifying regions of\ninterest (ROIs) in the 3D microscopy data. Our approach is based on a novel\nself-supervised multi-layer graph attention network (SSGAT), coupled with a\nReact interactive interface wrapped around Vitessce. SSGAT employs an\nadversarial self-supervised learning objective to identify meaningful immune\nmicroenvironments through marker interactions. Our method reveals complex\nspatial bioreactions that can be visually assessed to assess their distribution\nacross tissue. Index Terms: Biomedical visualization, graph attention\nnetworks,self-supervised learning, spatial interaction analysis."}
{"id": "2511.03976", "pdf": "https://arxiv.org/pdf/2511.03976", "abs": "https://arxiv.org/abs/2511.03976", "authors": ["Xu Zou"], "title": "PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "preprint", "summary": "Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable\nevolutionary trajectory, characterized by the continual emergence of\nimmune-evasive variants. This poses persistent challenges to public health and\nvaccine development.\n  While large-scale generative pre-trained transformers (GPTs) have\nrevolutionized the modeling of sequential data, their direct applications to\nnoisy viral genomic sequences are limited. In this paper, we introduce\nPETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based\non evolutionary trajectories derived from phylogenetic trees rather than raw\nRNA sequences. This method effectively mitigates sequencing noise and captures\nthe hierarchical structure of viral evolution.\n  With a weighted training framework to address substantial geographical and\ntemporal imbalances in global sequence data, PETRA excels in predicting future\nSARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide\nmutations and 17.10\\% for spike amino-acid mutations, compared to 0.49% and\n6.64% respectively for the best baseline. PETRA also demonstrates its ability\nto aid in the real-time mutation prediction of major clades like 24F(XEC) and\n25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra"}
{"id": "2511.04455", "pdf": "https://arxiv.org/pdf/2511.04455", "abs": "https://arxiv.org/abs/2511.04455", "authors": ["Guillaume Etter"], "title": "The brain as a blueprint: a survey of brain-inspired approaches to learning in artificial intelligence", "categories": ["q-bio.NC"], "comment": "17 pages, 6 figures", "summary": "Inspired by key neuroscience principles, deep learning has driven exponential\nbreakthroughs in developing functional models of perception and other cognitive\nprocesses. A key to this success has been the implementation of crucial\nfeatures found in biological neural networks: neurons as units of information\ntransfer, non-linear activation functions that enable general function\napproximation, and complex architectures vital for attentional processes.\nHowever, standard deep learning models rely on biologically implausible error\npropagation algorithms and struggle to accumulate knowledge incrementally.\nWhile, the precise learning rule governing synaptic plasticity in biological\nsystems remains unknown, recent discoveries in neuroscience could fuel further\nprogress in AI. Here I examine successful implementations of brain-inspired\nprinciples in deep learning, current limitations, and promising avenues\ninspired by recent advances in neuroscience, including error computation,\npropagation, and integration via synaptic updates in biological neural\nnetworks."}
{"id": "2511.04097", "pdf": "https://arxiv.org/pdf/2511.04097", "abs": "https://arxiv.org/abs/2511.04097", "authors": ["James Austin Orgeron", "Malbor Asllani"], "title": "Habitat fragmentation promotes spatial scale separation under resource competition", "categories": ["q-bio.PE", "nlin.AO", "physics.soc-ph"], "comment": null, "summary": "Habitat fragmentation, often driven by human activities, alters ecological\nlandscapes by disrupting connectivity and reshaping species interactions. In\nsuch fragmented environments, habitats can be modeled as networks, where\nindividuals disperse across interconnected patches. We consider an\nintraspecific competition model, where individuals compete for space while\ndispersing according to a nonlinear random walk, capturing the heterogeneity of\nthe network. The interplay between asymmetric competition, dispersal dynamics,\nand spatial heterogeneity leads to nonuniform species distribution: individuals\nwith stronger competitive traits accumulate in central (hub) habitat patches,\nwhile those with weaker traits are displaced toward the periphery. We provide\nanalytical insights into this mechanism, supported by numerical simulations,\ndemonstrating how competition and spatial structure jointly influence species\nsegregation. In the large-network limit, this effect becomes extreme, with\ndominant individuals disappearing from peripheral patches and subordinate ones\nfrom central regions, establishing spatial segregation. This pattern may create\nfavorable conditions for speciation, as physical separation can reinforce\ndivergence within the population over time."}
{"id": "2511.03767", "pdf": "https://arxiv.org/pdf/2511.03767", "abs": "https://arxiv.org/abs/2511.03767", "authors": ["Adam M. Saunders", "Michael E. Kim", "Gaurav Rudravaram", "Lucas W. Remedios", "Chloe Cho", "Elyssa M. McMaster", "Daniel R. Gillis", "Yihao Liu", "Lianrui Zuo", "Bennett A. Landman", "Tonia S. Rex"], "title": "Phenotype discovery of traumatic brain injury segmentations from heterogeneous multi-site data", "categories": ["q-bio.QM", "eess.IV"], "comment": "13 pages, 7 figures. Accepted to SPIE Medical Imaging 2026: Image\n  Processing", "summary": "Traumatic brain injury (TBI) is intrinsically heterogeneous, and typical\nclinical outcome measures like the Glasgow Coma Scale complicate this\ndiversity. The large variability in severity and patient outcomes render it\ndifficult to link structural damage to functional deficits. The Federal\nInteragency Traumatic Brain Injury Research (FITBIR) repository contains\nlarge-scale multi-site magnetic resonance imaging data of varying resolutions\nand acquisition parameters (25 shared studies with 7,693 sessions that have\nage, sex and TBI status defined - 5,811 TBI and 1,882 controls). To reveal\nshared pathways of injury of TBI through imaging, we analyzed T1-weighted\nimages from these sessions by first harmonizing to a local dataset and\nsegmenting 132 regions of interest (ROIs) in the brain. After running quality\nassurance, calculating the volumes of the ROIs, and removing outliers, we\ncalculated the z-scores of volumes for all participants relative to the mean\nand standard deviation of the controls. We regressed out sex, age, and total\nbrain volume with a multivariate linear regression, and we found significant\ndifferences in 37 ROIs between subjects with TBI and controls (p < 0.05 with\nindependent t-tests with false discovery rate correction). We found that\ndifferences originated in 1) the brainstem, occipital pole and structures\nposterior to the orbit, 2) subcortical gray matter and insular cortex, and 3)\ncerebral and cerebellar white matter using independent component analysis and\nclustering the component loadings of those with TBI."}
{"id": "2511.04539", "pdf": "https://arxiv.org/pdf/2511.04539", "abs": "https://arxiv.org/abs/2511.04539", "authors": ["Subati Abulikemu", "Tiago Azevedo", "Michail Mamalakis", "John Suckling"], "title": "Unified Generative Latent Representation for Functional Brain Graphs", "categories": ["q-bio.NC", "cs.LG"], "comment": "NeurIPS 2025 Workshop on Symmetry and Geometry in Neural\n  Representations", "summary": "Functional brain graphs are often characterized with separate graph-theoretic\nor spectral descriptors, overlooking how these properties covary and partially\noverlap across brains and conditions. We anticipate that dense, weighted\nfunctional connectivity graphs occupy a low-dimensional latent geometry along\nwhich both topological and spectral structures display graded variations. Here,\nwe estimated this unified graph representation and enabled generation of dense\nfunctional brain graphs through a graph transformer autoencoder with latent\ndiffusion, with spectral geometry providing an inductive bias to guide\nlearning. This geometry-aware latent representation, although unsupervised,\nmeaningfully separated working-memory states and decoded visual stimuli, with\nperformance further enhanced by incorporating neural dynamics. From the\ndiffusion modeled distribution, we were able to sample biologically plausible\nand structurally grounded synthetic dense graphs."}
{"id": "2511.04276", "pdf": "https://arxiv.org/pdf/2511.04276", "abs": "https://arxiv.org/abs/2511.04276", "authors": ["Piyumi Chathurangika", "Tharushika Peiris", "Lakmini S. Premadasa", "S. S. N. Perera", "Kushani De Silva"], "title": "Vector Traits Shape Disease Persistence: A Predator Prey Approach to Dengue", "categories": ["q-bio.PE", "math.DS", "34-xx, 65-xx, 03B48, 92-08, 92D30, 49J15"], "comment": null, "summary": "Dengue continues to pose a major global threat, infecting nearly 390 million\npeople annually. Recognizing the pivotal role of vector competence (vc), recent\nresearch focuses on mosquito parameters to inform transmission modeling and\nvector control strategies.This study models interactions between Aedes vectors\nand dengue pathogens, highlighting vc as a key driver of within vector\ninfection dynamics and endemic persistence. Using a predator prey framework, we\nshow that endemic conditions emerge naturally from the biological interplay\nbetween the vectors strategies to pathogen pressure and we prove global\nstability of such conditions. Our results reveal that under tropical and\nsubtropical environmental pressures, the innate immune system of vectors cannot\noffset high vc during endemic outbreaks, highlighting a fundamental biological\ntrade off, vectors can evolve increased transmission potential but cannot\nenhance immune capacity. This constraint defines the limits of their\nevolutionary response to pathogen driven selection and drives instability in\ndisease transmission dynamics."}
{"id": "2511.03771", "pdf": "https://arxiv.org/pdf/2511.03771", "abs": "https://arxiv.org/abs/2511.03771", "authors": ["Alif Elham Khan"], "title": "Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Medical image labels are often organized by taxonomies (e.g., organ - tissue\n- subtype), yet standard self-supervised learning (SSL) ignores this structure.\nWe present a hierarchy-preserving contrastive framework that makes the label\ntree a first-class training signal and an evaluation target. Our approach\nintroduces two plug-in objectives: Hierarchy-Weighted Contrastive (HWC), which\nscales positive/negative pair strengths by shared ancestors to promote\nwithin-parent coherence, and Level-Aware Margin (LAM), a prototype margin that\nseparates ancestor groups across levels. The formulation is geometry-agnostic\nand applies to Euclidean and hyperbolic embeddings without architectural\nchanges. Across several benchmarks, including breast histopathology, the\nproposed objectives consistently improve representation quality over strong SSL\nbaselines while better respecting the taxonomy. We evaluate with metrics\ntailored to hierarchy faithfulness: HF1 (hierarchical F1), H-Acc\n(tree-distance-weighted accuracy), and parent-distance violation rate. We also\nreport top-1 accuracy for completeness. Ablations show that HWC and LAM are\neffective even without curvature, and combining them yields the most\ntaxonomy-aligned representations. Taken together, these results provide a\nsimple, general recipe for learning medical image representations that respect\nthe label tree and advance both performance and interpretability in\nhierarchy-rich domains."}
{"id": "2511.03988", "pdf": "https://arxiv.org/pdf/2511.03988", "abs": "https://arxiv.org/abs/2511.03988", "authors": ["Wenshuo Qin", "Leyla Isik"], "title": "Simple 3D Pose Features Support Human and Machine Social Scene Understanding", "categories": ["cs.CV", "q-bio.NC"], "comment": "28 pages, 6 figures", "summary": "Humans can quickly and effortlessly extract a variety of information about\nothers' social interactions from visual input, ranging from visuospatial cues\nlike whether two people are facing each other to higher-level information. Yet,\nthe computations supporting these abilities remain poorly understood, and\nsocial interaction recognition continues to challenge even the most advanced AI\nvision systems. Here, we hypothesized that humans rely on 3D visuospatial pose\ninformation to make social interaction judgments, which is absent in most AI\nvision models. To test this, we combined state-of-the-art pose and depth\nestimation algorithms to extract 3D joint positions of people in short video\nclips depicting everyday human actions and compared their ability to predict\nhuman social interaction judgments with current AI vision models. Strikingly,\n3D joint positions outperformed most current AI vision models, revealing that\nkey social information is available in explicit body position but not in the\nlearned features of most vision models, including even the layer-wise\nembeddings of the pose models used to extract joint positions. To uncover the\ncritical pose features humans use to make social judgments, we derived a\ncompact set of 3D social pose features describing only the 3D position and\ndirection of faces in the videos. We found that these minimal descriptors\nmatched the predictive strength of the full set of 3D joints and significantly\nimproved the performance of off-the-shelf AI vision models when combined with\ntheir embeddings. Moreover, the degree to which 3D social pose features were\nrepresented in each off-the-shelf AI vision model predicted the model's ability\nto match human social judgments. Together, our findings provide strong evidence\nthat human social scene understanding relies on explicit representations of 3D\npose and can be supported by simple, structured visuospatial primitives."}
{"id": "2511.04327", "pdf": "https://arxiv.org/pdf/2511.04327", "abs": "https://arxiv.org/abs/2511.04327", "authors": ["Philippe Jacquod"], "title": "Feasibility and Single Parameter Scaling of Extinctions in Multispecies Lotka-Volterra Ecosystems", "categories": ["q-bio.PE", "nlin.AO", "physics.bio-ph"], "comment": "5 pages with four figures; 6 pages appended supplemental material\n  with 2 additional figures", "summary": "Multispecies ecosystems modelled by generalized Lotka-Volterra equations\nexhibit stationary population abundances, where large number of species often\ncoexist. Understanding the precise conditions under which this is at all\nfeasible and what triggers species extinctions is a key, outstanding problem in\ntheoretical ecology. Using standard methods of random matrix theory, I show\nthat distributions of species abundances are Gaussian at equilibrium, in the\nweakly interacting regime. One consequence is that feasibility is generically\nbroken before stability, for large enough number of species. I further derive\nan analytic expression for the probability that $n=0,1,2,...$ species go\nextinct and conjecture that a single-parameter scaling law governs species\nextinctions. These results are corroborated by numerical simulations in a wide\nrange of system parameters."}
{"id": "2511.03826", "pdf": "https://arxiv.org/pdf/2511.03826", "abs": "https://arxiv.org/abs/2511.03826", "authors": ["Esha Sadia Nasir", "Behnaz Elhaminia", "Mark Eastwood", "Catherine King", "Owen Cain", "Lorraine Harper", "Paul Moss", "Dimitrios Chanouzas", "David Snead", "Nasir Rajpoot", "Adam Shephard", "Shan E Ahmed Raza"], "title": "CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for Multi-stain Image Alignment", "categories": ["q-bio.QM", "cs.AI"], "comment": null, "summary": "Accurate and efficient registration of whole slide images (WSIs) is essential\nfor high-resolution, nuclei-level analysis in multi-stained tissue slides. We\npropose a novel coarse-to-fine framework CORE for accurate nuclei-level\nregistration across diverse multimodal whole-slide image (WSI) datasets. The\ncoarse registration stage leverages prompt-based tissue mask extraction to\neffectively filter out artefacts and non-tissue regions, followed by global\nalignment using tissue morphology and ac- celerated dense feature matching with\na pre-trained feature extractor. From the coarsely aligned slides, nuclei\ncentroids are detected and subjected to fine-grained rigid registration using a\ncustom, shape-aware point-set registration model. Finally, non-rigid alignment\nat the cellular level is achieved by estimating a non-linear dis- placement\nfield using Coherent Point Drift (CPD). Our approach benefits from\nautomatically generated nuclei that enhance the accuracy of deformable\nregistra- tion and ensure precise nuclei-level correspondence across\nmodalities. The pro- posed model is evaluated on three publicly available WSI\nregistration datasets, and two private datasets. We show that CORE outperforms\ncurrent state-of-the-art methods in terms of generalisability, precision, and\nrobustness in bright-field and immunofluorescence microscopy WSIs"}
{"id": "2511.04174", "pdf": "https://arxiv.org/pdf/2511.04174", "abs": "https://arxiv.org/abs/2511.04174", "authors": ["Guylaine Hoffner", "Philippe Djian"], "title": "Protein aggregation in Huntington's disease", "categories": ["q-bio.BM", "q-bio.NC"], "comment": null, "summary": "The presence of an expanded polyglutamine produces a toxic gain of function\nin huntingtin. Protein aggregation resulting from this gain of function is\nlikely to be the cause of neuronal death. Two main mechanisms of aggregation\nhave been proposed: hydrogen bonding by polar-zipper formation and covalent\nbonding by transglutaminase-catalyzed cross-linking. In cell culture models of\nHuntington's disease, aggregates are mostly stabilized by hydrogen bonds, but\ncovalent bonds are also likely to occur. Nothing is known about the nature of\nthe bonds that stabilize the aggregates in the brain of patients with\nHuntington's disease. It seems that the nature of the bond stabilizing the\naggregates is one of the most important questions, as the answer would\ncondition the therapeutic approach to Huntington's disease."}
{"id": "2511.04417", "pdf": "https://arxiv.org/pdf/2511.04417", "abs": "https://arxiv.org/abs/2511.04417", "authors": ["Michal Pecho", "Josef Tkadlec", "Martin A. Nowak"], "title": "The selective advantage of neighborhood-aware mutants in Moran process", "categories": ["q-bio.PE"], "comment": null, "summary": "Evolution occurs in populations of reproducing individuals. In stochastic\ndescriptions of evolutionary dynamics, such as the Moran process, individuals\nare chosen randomly for birth and for death. If the same type is chosen for\nboth steps, then the reproductive event is wasted, because the composition of\nthe population remains unchanged. Here we introduce a new phenotype, which we\ncall a \\textit{replacer}. Replacers are efficient competitors. When a replacer\nis chosen for reproduction, the offspring will always replace an individual of\nanother type (if available). We determine the selective advantage of replacers\nin well-mixed populations and on one-dimensional lattices. We find that being a\nreplacer substantially boosts the fixation probability of neutral and\ndeleterious mutants. In particular, fixation probability of a single neutral\nreplacer who invades a well-mixed population of size $N$ is of the order of\n$1/\\sqrt N$ rather than the standard $1/N$. Even more importantly, replacers\nare much better protected against invasions once they have reached fixation.\nTherefore, replacers dominate the mutation selection equilibrium even if the\nphenotype of being a replacer comes at a substantial cost: curiously, for large\npopulation size and small mutation rate the relative fitness of a successful\nreplacer can be as low as $1/e$."}
{"id": "2511.04143", "pdf": "https://arxiv.org/pdf/2511.04143", "abs": "https://arxiv.org/abs/2511.04143", "authors": ["Luca Quaroni"], "title": "Infrared Microscopy of Biochemistry and Metabolism in Single Living Eukaryotic Cells", "categories": ["q-bio.QM"], "comment": null, "summary": "The turn of the millennium has seen a growing interest in the study of live\ncells by infrared (IR) spectroscopy, driven by the versatility, wealth of\nmolecular information, and potential for high-throughput screening of the\ntechnique. Measurements on individual cells, either isolated or within a\nmulti-cellular structure, provide information that is not available from\nensemble samples. The present review discusses the use of infrared (IR)\nmicroscopy to analyse live single cells from a biochemical perspective, seeking\ninformation on real-time processes. The emphasis is on the use of the technique\nto quantify metabolic turnover, with the aim of providing a complementary\nmethod for metabolomics, and for toxicological and pharmacological studies. The\npresent work highlights the methodological advances and proof-of-concept\nexperiments that took place over the past few years in this direction. It\ndiscusses current advantages and limitations of the technique, including the\npossibility of detecting specific biomolecules and their reactivity, and it\nconcludes with a brief outline of future perspectives."}
{"id": "2511.04292", "pdf": "https://arxiv.org/pdf/2511.04292", "abs": "https://arxiv.org/abs/2511.04292", "authors": ["Arne Van Den Kerchove", "Hakim Si-Mohammed", "FranÃ§ois Cabestaing", "Marc M. Van Hulle"], "title": "BTTDA: Block-Term Tensor Discriminant Analysis for Brain-Computer Interfacing", "categories": ["eess.SP", "q-bio.NC"], "comment": "This archive contains 26 pages, 7 figures, 2 tables, 3 appendices and\n  3 ancillary files (erp_results.csv, mi_results.csv, block_theta_results.csv).\n  Source code is available at https://github.com/arnevdk/bttda", "summary": "Brain-computer interfaces (BCIs) allow direct communication between the brain\nand external devices, frequently using electroencephalography (EEG) to record\nneural activity. Dimensionality reduction and structured regularization are\nessential for effectively classifying task-related brain signals, including\nevent-related potentials (ERPs) and motor imagery (MI) rhythms. Current\ntensor-based approaches, such as Tucker and PARAFAC decompositions, often lack\nthe flexibility needed to fully capture the complexity of EEG data. This study\nintroduces Block-Term Tensor Discriminant Analysis (BTTDA): a novel\ntensor-based and supervised feature extraction method designed to enhance\nclassification accuracy by providing flexible multilinear dimensionality\nreduction. Extending Higher Order Discriminant Analysis (HODA), BTTDA uses a\nnovel and interpretable forward model for HODA combined with a deflation scheme\nto iteratively extract discriminant block terms, improving feature\nrepresentation for classification. BTTDA and a sum-of-rank-1-terms variant\nPARAFACDA were evaluated on publicly available ERP (second-order tensors) and\nMI (third-order tensors) EEG datasets from the MOABB benchmarking framework.\nBenchmarking revealed that BTTDA and PARAFACDA significantly outperform the\ntraditional HODA method in ERP decoding, resulting in state-of-the art\nperformance (ROC-AUC = 91.25%). For MI, decoding results of HODA, BTTDA and\nPARAFACDA were subpar, but BTTDA still significantly outperformed HODA (64.52%\n> 61.00%). The block-term structure of BTTDA enables interpretable and more\nefficient dimensionality reduction without compromising discriminative power.\nThis offers a promising and adaptable approach for feature extraction in BCI\nand broader neuroimaging applications."}
{"id": "2511.04574", "pdf": "https://arxiv.org/pdf/2511.04574", "abs": "https://arxiv.org/abs/2511.04574", "authors": ["Derek Marsh"], "title": "Reproduction Numbers R_0, R_t for COVID-19 Infections with Gaussian Distribution of Generation Times, and of Serial Intervals including Presymptomatic Transmission", "categories": ["q-bio.PE"], "comment": null, "summary": "Basic and instantaneous reproduction numbers, \"R\" _\"0\" and \"R\" _\"t\" , are\nimportant metrics to assess progress of an epidemic and effectiveness of\npreventative interventions undertaken, and also to estimate coverage needed for\nvaccination. Reproduction numbers are related to the daily number of positive\ncases recorded by the national public health authorities, via the renewal\nequation. During periods of exponential growth or decay they are linked also to\nthe rate constants by the Lotka-Euler equation. For either application, we need\nthe distribution of generation times between primary and secondary infections.\nIn practice, we use instead the directly observable serial interval between\nsymptoms onset of infector and infectee. Pre-symptomatic transmission that\noccurs in COVID infection causes serial intervals to extend to negative values,\nwhich can be described with a Gaussian distribution. Consistent application of\nthe two approaches requires careful attention to lower limits imposed on the\ndistribution. Allowing Gaussian-distributed serial intervals to extend to minus\ninfinity with the Lotka-Euler equation, as commonly is done, results in lower\nreproduction numbers than predicted from the discretized renewal equation.\nHere, we formulate the Lotka-Euler equation for Gaussian distributions\nincluding an explicit lower cut-off, and use this to explore the consequences\nof presymptomatic transmission for COVID-19 infections."}
{"id": "2511.03819", "pdf": "https://arxiv.org/pdf/2511.03819", "abs": "https://arxiv.org/abs/2511.03819", "authors": ["Ozan Kanbertay", "Richard Vogg", "Elif Karakoc", "Peter M. Kappeler", "Claudia Fichtel", "Alexander S. Ecker"], "title": "SILVI: Simple Interface for Labeling Video Interactions", "categories": ["cs.CV", "q-bio.QM"], "comment": null, "summary": "Computer vision methods are increasingly used for the automated analysis of\nlarge volumes of video data collected through camera traps, drones, or direct\nobservations of animals in the wild. While recent advances have focused\nprimarily on detecting individual actions, much less work has addressed the\ndetection and annotation of interactions -- a crucial aspect for understanding\nsocial and individualized animal behavior. Existing open-source annotation\ntools support either behavioral labeling without localization of individuals,\nor localization without the capacity to capture interactions. To bridge this\ngap, we present SILVI, an open-source labeling software that integrates both\nfunctionalities. SILVI enables researchers to annotate behaviors and\ninteractions directly within video data, generating structured outputs suitable\nfor training and validating computer vision models. By linking behavioral\necology with computer vision, SILVI facilitates the development of automated\napproaches for fine-grained behavioral analyses. Although developed primarily\nin the context of animal behavior, SILVI could be useful more broadly to\nannotate human interactions in other videos that require extracting dynamic\nscene graphs. The software, along with documentation and download instructions,\nis available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app."}
{"id": "2511.04454", "pdf": "https://arxiv.org/pdf/2511.04454", "abs": "https://arxiv.org/abs/2511.04454", "authors": ["Hao Zhu", "Jasper Hoffmann", "Baohe Zhang", "Joschka Boedecker"], "title": "Fitting Reinforcement Learning Model to Behavioral Data under Bandits", "categories": ["cs.CE", "cs.LG", "math.OC", "q-bio.NC", "90C25, 90C59, 90C90"], "comment": null, "summary": "We consider the problem of fitting a reinforcement learning (RL) model to\nsome given behavioral data under a multi-armed bandit environment. These models\nhave received much attention in recent years for characterizing human and\nanimal decision making behavior. We provide a generic mathematical optimization\nproblem formulation for the fitting problem of a wide range of RL models that\nappear frequently in scientific research applications, followed by a detailed\ntheoretical analysis of its convexity properties. Based on the theoretical\nresults, we introduce a novel solution method for the fitting problem of RL\nmodels based on convex relaxation and optimization. Our method is then\nevaluated in several simulated bandit environments to compare with some\nbenchmark methods that appear in the literature. Numerical results indicate\nthat our method achieves comparable performance to the state-of-the-art, while\nsignificantly reducing computation time. We also provide an open-source Python\npackage for our proposed method to empower researchers to apply it in the\nanalysis of their datasets directly, without prior knowledge of convex\noptimization."}
{"id": "2511.03849", "pdf": "https://arxiv.org/pdf/2511.03849", "abs": "https://arxiv.org/abs/2511.03849", "authors": ["Phuc Nguyen", "Josiah Couch", "Rahul Bansal", "Alexandra Morgan", "Chris Tam", "Miao Li", "Rima Arnaout", "Ramy Arnaout"], "title": "Which Similarity-Sensitive Entropy?", "categories": ["cs.IT", "cs.LG", "math.IT", "q-bio.PE"], "comment": "21 pages, 8 figures", "summary": "A canonical step in quantifying a system is to measure its entropy. Shannon\nentropy and other traditional entropy measures capture only the information\nencoded in the frequencies of a system's elements. Recently, Leinster, Cobbold,\nand Reeve (LCR) introduced a method that also captures the rich information\nencoded in the similarities and differences among elements, yielding\nsimilarity-sensitive entropy. More recently, the Vendi score (VS) was\nintroduced as an alternative, raising the question of how LCR and VS compare,\nand which is preferable. Here we address these questions conceptually,\nanalytically, and experimentally, using 53 machine-learning datasets. We show\nthat LCR and VS can differ by orders of magnitude and can capture complementary\ninformation about a system, except in limiting cases. We demonstrate that both\nLCR and VS depend on how similarities are scaled and introduce the concept of\n``half distance'' to parameterize this dependence. We prove that VS provides an\nupper bound on LCR for several values of the R\\'enyi-Hill order parameter and\nconjecture that this bound holds for all values. We conclude that VS is\npreferable only when interpreting elements as linear combinations of a more\nfundamental set of ``ur-elements'' or when the system or dataset possesses a\nquantum-mechanical character. In the broader circumstance where one seeks\nsimply to capture the rich information encoded by similarity, LCR is favored;\nnevertheless, for certain half-distances the two methods can complement each\nother."}
{"id": "2511.03986", "pdf": "https://arxiv.org/pdf/2511.03986", "abs": "https://arxiv.org/abs/2511.03986", "authors": ["Ahmed A. Metwally", "Heyjun Park", "Yue Wu", "Tracey McLaughlin", "Michael P. Snyder"], "title": "Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes", "categories": ["cs.LG", "q-bio.QM"], "comment": "18 pages, 8 figures", "summary": "The classification of diabetes and prediabetes by static glucose thresholds\nobscures the pathophysiological dysglycemia heterogeneity, primarily driven by\ninsulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This\nreview demonstrates that continuous glucose monitoring and wearable\ntechnologies enable a paradigm shift towards non-invasive, dynamic metabolic\nphenotyping. We show evidence that machine learning models can leverage\nhigh-resolution glucose data from at-home, CGM-enabled oral glucose tolerance\ntests to accurately predict gold-standard measures of muscle IR and beta-cell\nfunction. This personalized characterization extends to real-world nutrition,\nwhere an individual's unique postprandial glycemic response (PPGR) to\nstandardized meals, such as the relative glucose spike to potatoes versus\ngrapes, could serve as a biomarker for their metabolic subtype. Moreover,\nintegrating wearable data reveals that habitual diet, sleep, and physical\nactivity patterns, particularly their timing, are uniquely associated with\nspecific metabolic dysfunctions, informing precision lifestyle interventions.\nThe efficacy of dietary mitigators in attenuating PPGR is also shown to be\nphenotype-dependent. Collectively, this evidence demonstrates that CGM can\ndeconstruct the complexity of early dysglycemia into distinct, actionable\nsubphenotypes. This approach moves beyond simple glycemic control, paving the\nway for targeted nutritional, behavioral, and pharmacological strategies\ntailored to an individual's core metabolic defects, thereby paving the way for\na new era of precision diabetes prevention."}
{"id": "2511.04593", "pdf": "https://arxiv.org/pdf/2511.04593", "abs": "https://arxiv.org/abs/2511.04593", "authors": ["Shaunak Bhandarkar", "James L. McClelland"], "title": "Neural Computation Without Slots: Steps Towards Biologically Plausible Memory and Attention in Natural and Artificial Intelligence", "categories": ["cs.NE", "q-bio.NC"], "comment": "19 main text pages, 7 main text figures; 33 supplementary pages, 13\n  supplementary figures", "summary": "Many models used in artificial intelligence and cognitive science rely on\nmulti-element patterns stored in \"slots\" - dedicated storage locations - in a\ndigital computer. As biological brains likely lack slots, we consider how they\nmight achieve similar functional outcomes without them by building on the\nneurally-inspired modern Hopfield network (MHN; Krotov & Hopfield, 2021), which\nstores patterns in the connection weights of an individual neuron. We propose\nextensions of this approach to increase its biological plausibility as a model\nof memory and to capture an important advantage of slot-based computation in\ncontemporary language models. For memory, neuroscience research suggests that\nthe weights of overlapping sparse ensembles of neurons, rather than a dedicated\nindividual neuron, are used to store a memory. We introduce the K-winner MHN,\nextending the approach to ensembles, and find that within a continual learning\nregime, the ensemble-based MHN exhibits greater retention of older memories, as\nmeasured by the graded sensitivity measure d', than a standard (one-neuron)\nMHN. Next, we consider the powerful use of slot-based memory in contemporary\nlanguage models. These models use slots to store long sequences of past inputs\nand their learned encodings, supporting later predictions and allowing error\nsignals to be transported backward in time to adjust weights underlying the\nlearned encodings of these past inputs. Inspired by these models' successes, we\nshow how the MHN can be extended to capture both of these important functional\noutcomes. Collectively, our modeling approaches constitute steps towards\nunderstanding how biologically plausible mechanisms can support computations\nthat have enabled AI systems to capture human-like abilities that no prior\nmodels have been able to achieve."}
