{"id": "2601.05531", "pdf": "https://arxiv.org/pdf/2601.05531", "abs": "https://arxiv.org/abs/2601.05531", "authors": ["Eliatan Niktab", "Hardip Patel"], "title": "DNATokenizer: A GPU-First Byte-to-Identifier Tokenizer for High-Throughput DNA Language Models", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Tokenization sits at the boundary between high-throughput genomic input and GPU compute, posing challenges in both algorithm design and system throughput. Overlapping k-mer tokenization can introduce information leakage under masked language modeling (MLM) and may degrade downstream accuracy. Single-nucleotide tokenization avoids leakage and preserves per-base fidelity, but it greatly increases sequence length for attention-based architectures. Non-overlapping k-mers and byte-pair encoding (BPE) provide compression and avoid leakage, at the cost of boundary sensitivity or reduced interpretability. Empirically, the choice of tokenization interacts strongly with model architecture and task requirements. At the system level, however, standard string tokenizers and host-bound vocabulary lookups dominate wall-clock time once inputs reach billions of bases, regardless of the tokenization algorithm. We present DNATok, a high-performance, GPU-first tokenization system that replaces general-purpose string processing with byte lookup table (LUT)-based identifier streaming and an overlapped host-to-device (H2D)/compute pipeline using pinned memory and architectural parallelism. DNATok is vocabulary-agnostic: it accelerates single-nucleotide, non-overlapping k-mer, and BPE tokenization, and integrates as a drop-in systems layer beneath genomic foundation models. DNATok achieves 84-95x higher encoding throughput than optimized Hugging Face baselines and up to 1.9x higher H2D throughput. End-to-end streaming reaches 1.27-1.84e8 tokens/s depending on configuration, effectively removing tokenization as a bottleneck for production-scale training and inference."}
{"id": "2601.05648", "pdf": "https://arxiv.org/pdf/2601.05648", "abs": "https://arxiv.org/abs/2601.05648", "authors": ["Haoran Wang", "Xuanyi Zhang", "Shuangsang Fang", "Longke Ran", "Ziqing Deng", "Yong Zhang", "Yuxiang Li", "Shaoshuai Li"], "title": "Open World Knowledge Aided Single-Cell Foundation Model with Robust Cross-Modal Cell-Language Pre-training", "categories": ["q-bio.GN", "cs.AI", "cs.CL", "cs.LG"], "comment": "41 pages", "summary": "Recent advancements in single-cell multi-omics, particularly RNA-seq, have provided profound insights into cellular heterogeneity and gene regulation. While pre-trained language model (PLM) paradigm based single-cell foundation models have shown promise, they remain constrained by insufficient integration of in-depth individual profiles and neglecting the influence of noise within multi-modal data. To address both issues, we propose an Open-world Language Knowledge-Aided Robust Single-Cell Foundation Model (OKR-CELL). It is built based on a cross-modal Cell-Language pre-training framework, which comprises two key innovations: (1) leveraging Large Language Models (LLMs) based workflow with retrieval-augmented generation (RAG) enriches cell textual descriptions using open-world knowledge; (2) devising a Cross-modal Robust Alignment (CRA) objective that incorporates sample reliability assessment, curriculum learning, and coupled momentum contrastive learning to strengthen the model's resistance to noisy data. After pretraining on 32M cell-text pairs, OKR-CELL obtains cutting-edge results across 6 evaluation tasks. Beyond standard benchmarks such as cell clustering, cell-type annotation, batch-effect correction, and few-shot annotation, the model also demonstrates superior performance in broader multi-modal applications, including zero-shot cell-type annotation and bidirectional cell-text retrieval."}
{"id": "2601.05277", "pdf": "https://arxiv.org/pdf/2601.05277", "abs": "https://arxiv.org/abs/2601.05277", "authors": ["Alexander Serov"], "title": "Evolving Cognitive Architectures", "categories": ["q-bio.NC", "cs.AI", "cs.NE"], "comment": null, "summary": "This article proposes a research and development direction that would lead to the creation of next-generation intelligent technical systems. A distinctive feature of these systems is their ability to undergo evolutionary change. Cognitive architectures are now one of the most promising ways to create Artificial General Intelligence systems. One of the main problems of modern cognitive architectures is an excessively schematic approach to modeling the processes of cognitive activity. It does not allow the creation of a universal architecture that would be capable of reproducing higher nervous functions without using a predetermined set of perception patterns. Our paper proposes an evolutionary approach to creating a cognitive architecture. The basis of this approach is the use of a functional core, which consistently generates the intellectual functions of an autonomous agent. We are considering a cognitive architecture that includes components, the interaction of which ensures the evolution of the agent. The discussion of the development of intelligence is carried out using the conceptual apparatus of semiotics. This allows us to consider the task of developing cognitive functions as a problem of establishing a connection between the Merkwelt and the Werkwelt through the creation of the Innenwelt. The problem of early postnatal ontogenesis is investigated on the basis of the theory of constructivism: we discuss the requirements for the functional core and its composition, as well as the mechanism that initiates the process of cognition."}
{"id": "2601.05367", "pdf": "https://arxiv.org/pdf/2601.05367", "abs": "https://arxiv.org/abs/2601.05367", "authors": ["Parul Johri", "Fanny Pouyet", "Brian Charlesworth"], "title": "The rights and wrongs of rescaling in population genetics simulations", "categories": ["q-bio.PE"], "comment": null, "summary": "Computer simulations of complex population genetic models are an essential tool for making sense of the large-scale datasets of multiple genome sequences from a single species that are becoming increasingly available. A widely used approach for reducing computing time is to simulate populations that are much smaller than the natural populations that they are intended to represent, by using parameters such as selection coefficients and mutation rates, whose products with the population size correspond to those of the natural populations. This approach has come to be known as rescaling, and is justified by the theory of the genetics of finite populations. Recently, however, there have been criticisms of this practice, which have brought to light situations in which it can lead to erroneous conclusions. This paper reviews the theoretical basis for rescaling, and relates it to current practice in population genetics simulations. It shows that some population genetic statistics are scaleable while others are not. Additionally, it shows that there are likely to be problems with rescaling when simulating large chromosomal regions, due to the non-linear relation between the physical distance between a pair of separate nucleotide sites and the frequency of recombination between them. Other difficulties with rescaling can arise in connection with simulations of selection on complex traits, and with populations that reproduce partly by self-fertilization or asexual reproduction. A number of recommendations are made for good practice in relation to rescaling."}
{"id": "2601.05605", "pdf": "https://arxiv.org/pdf/2601.05605", "abs": "https://arxiv.org/abs/2601.05605", "authors": ["Yue Hu", "YingChao Liu"], "title": "AntibodyDesignBFN: High-Fidelity Fixed-Backbone Antibody Design via Discrete Bayesian Flow Networks", "categories": ["q-bio.QM"], "comment": "4 pages, 1 table, 4 equations", "summary": "The computational design of antibodies with high specificity and affinity is a cornerstone of modern therapeutic development. While deep generative models, particularly Denoising Diffusion Probabilistic Models (DDPMs), have demonstrated the ability to generate realistic antibody structures, they often suffer from high computational costs and the difficulty of modeling discrete variables like amino acid sequences. In this work, we present AntibodyDesignBFN, a novel framework for fixed-backbone antibody design based on Discrete Bayesian Flow Networks(BFN). Unlike standard diffusion models that rely on Gaussian noise removal or complex discrete corruption processes, BFNs operate directly on the parameters of the data distribution, enabling a continuous-time, fully differentiable generative process on the probability simplex. While recent pioneering works like IgCraft and AbBFN have introduced BFNs to the domain of antibody sequence generation and inpainting, our work focuses specifically on the inverse folding task-designing sequences that fold into a fixed 3D backbone. By integrating a lightweight Geometric Transformer utilizing Invariant Point Attention (IPA) and a resource-efficient training strategy with gradient accumulation, our model achieves superior performance. Evaluations on a rigorous 2025 temporal test set reveal that AntibodyDesignBFN achieves a remarkable 48.1% Amino Acid Recovery (AAR) on H-CDR3, demonstrating that BFNs, when conditioned on 3D geometric constraints, offer a robust mathematical framework for high-fidelity antibody design$.$Code and model checkpoints are available at https://github.com/YueHuLab/AntibodyDesignBFN and https://huggingface.co/YueHuLab/AntibodyDesignBFN, respectively."}
{"id": "2601.05284", "pdf": "https://arxiv.org/pdf/2601.05284", "abs": "https://arxiv.org/abs/2601.05284", "authors": ["Kaiyue Shi", "Christopher W. Lynn"], "title": "Irreversible behavior drives neural flows in the hippocampus", "categories": ["q-bio.NC", "physics.bio-ph"], "comment": null, "summary": "In the brain, neural activity undergoes directed flows between states, thus breaking time-reversal symmetry. At the same time, animals also exhibit irreversible flows between behavioral states. Yet it remains unclear whether -- and how -- irreversibility in the brain relates to irreversibility in behavior. Here, we explore this connection in the hippocampus, where neural activity encodes physical location. We show that hippocampal irreversibility can be quantified using the time-delayed cross-correlations between neurons. As a mouse moves along a virtual track, we find that physical flows through the animal's environment generate neural flows through its cognitive map. Strikingly, this neural irreversibility is explained by a minimal model with only three parameters: the average velocity of the mouse, the variance in this velocity, and the resolution of the neural encoding. Together, these results provide a mechanistic understanding of irreversibility in the hippocampus and shed light on the links between symmetry breaking in the brain and behavior."}
{"id": "2601.05921", "pdf": "https://arxiv.org/pdf/2601.05921", "abs": "https://arxiv.org/abs/2601.05921", "authors": ["Philip Gerlee", "Torbjörn Lundh", "Anna Saxne Jöud", "Henrik Thorén"], "title": "Evaluating infectious disease forecasts in a cost-loss situation", "categories": ["q-bio.QM"], "comment": null, "summary": "In order for epidemiological forecasts to be useful for decision-makers the forecasts need to be properly validated and evaluated. Although several metrics fore evaluation have been proposed and used none of them account for the potential costs and losses that the decision-maker faces. We have adapted a decision-theoretic framework to an epidemiological context which assigns a Value Score (VS) to each model by comparing the expected expense of the decision-maker when acting on the model forecast to the expected expense obtained from acting on historical event probabilities. The VS depends on the cost-loss ratio and a positive VS implies added value for the decision-maker whereas a negative VS means that historical event probabilities outperform the model forecasts. We apply this framework to a subset of model forecasts of influenza peak intensity from the FluSight Challenge and show that most models exhibit a positive VS for some range of cost-loss ratios. However, there is no clear relationship between the VS and the original ranking of the model forecasts obtained using a modified log score. This is in part explained by the fact that the VS is sensitive to over- vs. under-prediction, which is not the case for standard evaluation metrics. We believe that this type of context-sensitive evaluation will lead to improved utilisation of epidemiological forecasts by decision-makers."}
{"id": "2601.05893", "pdf": "https://arxiv.org/pdf/2601.05893", "abs": "https://arxiv.org/abs/2601.05893", "authors": ["Jérémie Sibille", "Kai Lun Teh", "Alexandra Tzilivaki", "Dietmar Schmitz", "Paula T. Kuokkanen"], "title": "An outlook on extracellular waveforms produced by the three neuronal compartments", "categories": ["q-bio.NC"], "comment": "40 pages, 4 figures, 2 boxes", "summary": "The brain is composed of billions of neurons with virtually endless morphologies and ion channel compositions, resulting in unique extracellular waveforms. Nevertheless, almost all neuronal morphologies can be reduced to a simple architecture made of three principal compartments: 1) the soma and nearby axonal hillock, 2) axonal projections ending in arbors or single synaptic contacts, and 3) dendrites. This review offers a perspective on how these three ubiquitous neuronal compartments can be identified and how they shape the extracellularly recorded waveforms, when spatial considerations are taken into account. This outlook utilizes biophysical modelling to complement existing experimental observations. Modeling has predicted a rich landscape of putative extracellular waveforms based on morphology, channel density, and sequential temporal activation. Recent advances in extracellular in vivo recording, combining low noise with high spatial density of recording sites, have improved the precision of extracellular waveform measurements, particularly in capturing waveforms beyond the classical somatic spikes, and in some cases, combinations originating from different compartments. This review aims to reorganize extracellular waveform heterogeneity by separating signals stemming from three neuronal compartments using three dimensions: amplitude, duration, and spatial extent or footprint. In doing so, we argue for a change of perspective, looking beyond somatic spikes to include spatiality and waveform combinations."}
{"id": "2601.05356", "pdf": "https://arxiv.org/pdf/2601.05356", "abs": "https://arxiv.org/abs/2601.05356", "authors": ["Brian Hsu", "Priyanka V Setty", "Rory M Butler", "Ryan Lewis", "Casey Stone", "Rebecca Weinberg", "Thomas Brettin", "Rick Stevens", "Ian Foster", "Arvind Ramanathan"], "title": "PRISM: Protocol Refinement through Intelligent Simulation Modeling", "categories": ["cs.RO", "cs.AI", "cs.MA", "q-bio.QM"], "comment": "43 pages, 8 figures, submitted to RSC Digital Discovery. Equal contribution: B. Hsu, P.V. Setty, R.M. Butler. Corresponding author: A. Ramanathan", "summary": "Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution."}
{"id": "2601.05842", "pdf": "https://arxiv.org/pdf/2601.05842", "abs": "https://arxiv.org/abs/2601.05842", "authors": ["Jonathan F. Kunst", "Killian A. C. Melsen", "Willem Kruijer", "José Crossa", "Chris Maliepaard", "Fred A. van Eeuwijk", "Carel F. W. Peeters"], "title": "A latent factor approach to hyperspectral time series data for multivariate genomic prediction of grain yield in wheat", "categories": ["stat.AP", "q-bio.QM", "stat.ME"], "comment": "20 pages, 8 figures", "summary": "High-dimensional time series phenotypic data is becoming increasingly common within plant breeding programmes. However, analysing and integrating such data for genetic analysis and genomic prediction remains difficult. Here we show how factor analysis with Procrustes rotation on the genetic correlation matrix of hyperspectral secondary phenotype data can help in extracting relevant features for within-trial prediction. We use a subset of Centro Internacional de Mejoramiento de Maíz y Trigo (CIMMYT) elite yield wheat trial of 2014-2015, consisting of 1,033 genotypes. These were measured across three irrigation treatments at several timepoints during the season, using manned airplane flights with hyperspectral sensors capturing 62 bands in the spectrum of 385-850 nm. We perform multivariate genomic prediction using latent variables to improve within-trial genomic predictive ability (PA) of wheat grain yield within three distinct watering treatments. By integrating latent variables of the hyperspectral data in a multivariate genomic prediction model, we are able to achieve an absolute gain of .1 to .3 (on the correlation scale) in PA compared to univariate genomic prediction. Furthermore, we show which timepoints within a trial are important and how these relate to plant growth stages. This paper showcases how domain knowledge and data-driven approaches can be combined to increase PA and gain new insights from sensor data of high-throughput phenotyping platforms."}
{"id": "2601.05923", "pdf": "https://arxiv.org/pdf/2601.05923", "abs": "https://arxiv.org/abs/2601.05923", "authors": ["E. Middell", "L. Carlton", "S. Moradi", "T. Codina", "T. Fischer", "J. Cutler", "S. Kelley", "J. Behrendt", "T. Dissanayake", "N. Harmening", "M. A. Yücel", "D. A. Boas", "A. von Lühmann"], "title": "Cedalion Tutorial: A Python-based framework for comprehensive analysis of multimodal fNIRS & DOT from the lab to the everyday world", "categories": ["eess.SP", "cs.AI", "cs.LG", "eess.IV", "q-bio.QM"], "comment": "33 pages main manuscript, 180 pages Supplementary Tutorial Notebooks, 12 figures, 6 tables, under review in SPIE Neurophotonics", "summary": "Functional near-infrared spectroscopy (fNIRS) and diffuse optical tomography (DOT) are rapidly evolving toward wearable, multimodal, and data-driven, AI-supported neuroimaging in the everyday world. However, current analytical tools are fragmented across platforms, limiting reproducibility, interoperability, and integration with modern machine learning (ML) workflows. Cedalion is a Python-based open-source framework designed to unify advanced model-based and data-driven analysis of multimodal fNIRS and DOT data within a reproducible, extensible, and community-driven environment. Cedalion integrates forward modelling, photogrammetric optode co-registration, signal processing, GLM Analysis, DOT image reconstruction, and ML-based data-driven methods within a single standardized architecture based on the Python ecosystem. It adheres to SNIRF and BIDS standards, supports cloud-executable Jupyter notebooks, and provides containerized workflows for scalable, fully reproducible analysis pipelines that can be provided alongside original research publications. Cedalion connects established optical-neuroimaging pipelines with ML frameworks such as scikit-learn and PyTorch, enabling seamless multimodal fusion with EEG, MEG, and physiological data. It implements validated algorithms for signal-quality assessment, motion correction, GLM modelling, and DOT reconstruction, complemented by modules for simulation, data augmentation, and multimodal physiology analysis. Automated documentation links each method to its source publication, and continuous-integration testing ensures robustness. This tutorial paper provides seven fully executable notebooks that demonstrate core features. Cedalion offers an open, transparent, and community extensible foundation that supports reproducible, scalable, cloud- and ML-ready fNIRS/DOT workflows for laboratory-based and real-world neuroimaging."}
