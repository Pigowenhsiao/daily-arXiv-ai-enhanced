{"id": "2511.13916", "pdf": "https://arxiv.org/pdf/2511.13916", "abs": "https://arxiv.org/abs/2511.13916", "authors": ["Karthik Venuturimilli", "Yang Ha"], "title": "Structural Flexibility of the TCF7L2-DNA Complex with the Type 2 Diabetes SNP rs7903146", "categories": ["q-bio.BM"], "comment": "10 pages, 6 figures. Accepted to the 2025 IEEE International Conference on E-Health and Bioengineering (EHB); conference proceedings to be indexed/published by Springer Nature", "summary": "The single nucleotide polymorphism (SNP) rs7903146 in the TCF7L2 gene has been determined as one of the strongest common genetic risk factors for Type 2 Diabetes (T2D). The location of the SNP in a non-coding region suggests a regulatory mechanism, meaning the SNP doesn't change the protein's own structure but rather affects how the TCF7L2 protein binds to DNA to control other genes. This binding, however, is highly dependent on the shape and flexibility of the DNA. This study aims to reveal the atomic-level effects of the SNP's cytosine-to-thymine substitution on the TCF7L2-DNA complex. We first utilized AlphaFold to generate individual high-confidence structures of the TCF7L2 protein and two 15-base pair DNA duplexes: one containing the reference C allele and one containing the variant T allele. These structures were then used as inputs for Neurosnap's Boltz2 deep learning model to generate two complete protein-DNA complexes of the TCF7L2 HMG-box bound to each DNA variant. Using the iMODS server, we conducted a Normal Mode Analysis (NMA) to predict and compare large-scale flexibility and differences in interactions between the complexes. The protein-DNA interface was dissected using PDBsum to locate atomic contacts, clefts, and interaction maps. Overall, our results show that the T allele variant exhibits increased global stiffness with a higher eigenvalue and reduced flexibility, suggesting that the SNP disrupts the mechanism and biomechanical balance needed for efficient TCF7L2-DNA binding, thus affecting downstream gene regulation."}
{"id": "2511.14559", "pdf": "https://arxiv.org/pdf/2511.14559", "abs": "https://arxiv.org/abs/2511.14559", "authors": ["Xinzhe Zheng", "Shiyu Jiang", "Gustavo Seabra", "Chenglong Li", "Yanjun Li"], "title": "Apo2Mol: 3D Molecule Generation via Dynamic Pocket-Aware Diffusion Models", "categories": ["q-bio.BM", "cs.AI", "cs.LG", "q-bio.QM"], "comment": "Accepted by AAAI 2026", "summary": "Deep generative models are rapidly advancing structure-based drug design, offering substantial promise for generating small molecule ligands that bind to specific protein targets. However, most current approaches assume a rigid protein binding pocket, neglecting the intrinsic flexibility of proteins and the conformational rearrangements induced by ligand binding, limiting their applicability in practical drug discovery. Here, we propose Apo2Mol, a diffusion-based generative framework for 3D molecule design that explicitly accounts for conformational flexibility in protein binding pockets. To support this, we curate a dataset of over 24,000 experimentally resolved apo-holo structure pairs from the Protein Data Bank, enabling the characterization of protein structure changes associated with ligand binding. Apo2Mol employs a full-atom hierarchical graph-based diffusion model that simultaneously generates 3D ligand molecules and their corresponding holo pocket conformations from input apo states. Empirical studies demonstrate that Apo2Mol can achieve state-of-the-art performance in generating high-affinity ligands and accurately capture realistic protein pocket conformational changes."}
{"id": "2511.14663", "pdf": "https://arxiv.org/pdf/2511.14663", "abs": "https://arxiv.org/abs/2511.14663", "authors": ["Xiaoqiong Xia", "Cesar de la Fuente-Nunez"], "title": "ApexGen: Simultaneous design of peptide binder sequence and structure for target proteins", "categories": ["q-bio.BM"], "comment": null, "summary": "Peptide-based drugs can bind to protein interaction sites that small molecules often cannot, and are easier to produce than large protein drugs. However, designing effective peptide binders is difficult. A typical peptide has an enormous number of possible sequences, and only a few of these will fold into the right 3D shape to match a given protein target. Existing computational methods either generate many candidate sequences without considering how they will fold, or build peptide backbones and then find suitable sequences afterward. Here we introduce ApexGen, a new AI-based framework that simultaneously designs a peptide's amino-acid sequence and its three-dimensional structure to fit a given protein target. For each target, ApexGen produces a full all-atom peptide model in a small number of deterministic integration steps. In tests on hundreds of protein targets, the peptides designed by ApexGen fit tightly onto their target surfaces and cover nearly the entire binding site. These peptides have shapes similar to those found in natural protein-peptide complexes, and they show strong predicted binding affinity in computational experiments. Because ApexGen couples sequence and structure design at every step of Euler integration within a flow-matching sampler, it is much faster and more efficient than prior approaches. This unified method could greatly accelerate the discovery of new peptide-based therapeutics."}
{"id": "2511.14676", "pdf": "https://arxiv.org/pdf/2511.14676", "abs": "https://arxiv.org/abs/2511.14676", "authors": ["Yiyang Xu", "Ziyou Shen", "Yanqing Lv", "Shutong Tan", "Chun Sun", "Juan Zhang"], "title": "Exploring AlphaFold 3 for CD47 Antibody-Antigen Binding Affinity: An Unexpected Discovery of Reverse docking", "categories": ["q-bio.BM"], "comment": "15 pages,4 figures, submitted to ACS Omega", "summary": "AlphaFold 3 (AF3) is a powerful biomolecular structure-predicting tool based on the latest deep learning algorithms and revolutionized AI model architectures. A few of papers have already investigated its accuracy in predicting different biomolecular structures. However, the potential applications of AF3 beyond basic structure prediction have not been fully explored. In our study, we firstly focused on structure predictions of antibody-antigen (CD47) complexes, which is believed to be challenge for AF3 due to limited resolved cognate crystallographic structures. Furtherly, we aimed to the potentiality of AF3 in performing pre-screening for potent antibody candidates as an auxiliary work through binding affinity analysis compared to other molecular docking modules of commercial software, which would greatly benefit the lead identification or optimization process in the drug development. In essence, this is not limited to antibody-antigen binding affinity, but many other chemical or physical properties of any drug candidate based on AF3's accurate predicting structures that are extremely close to the reality. According to our experimental results, AF3 is a very promising competitor, which can efficiently produce highly reliable molecular structures and subsequent binding energy predictions for most subjects. Surprisingly, an unexpected and nonrandom phenomenon \"reverse docking\" was observed for two of our antibody subjects, suggesting new issues arising from the architectural revolution of AF3. Our analysis and error correction experiments show that this phenomenon is likely to be caused by revolutionized AI model architectures, which provides important experience and reminders for the optimization and design direction of AI for structural prediction. All software copyrights belong to the China Pharmaceutical University (CPU) and its affiliated School of Pharmacy and School of Science."}
{"id": "2511.13790", "pdf": "https://arxiv.org/pdf/2511.13790", "abs": "https://arxiv.org/abs/2511.13790", "authors": ["Lukas Picek", "César Leblanc", "Alexis Joly", "Pierre Bonnet", "Rémi Palard", "Maximilien Servajean"], "title": "GeoPl@ntNet: A Platform for Exploring Essential Biodiversity Variables", "categories": ["q-bio.QM", "cs.AI"], "comment": "4 pages, 5 figures, and 2 tables", "summary": "This paper describes GeoPl@ntNet, an interactive web application designed to make Essential Biodiversity Variables accessible and understandable to everyone through dynamic maps and fact sheets. Its core purpose is to allow users to explore high-resolution AI-generated maps of species distributions, habitat types, and biodiversity indicators across Europe. These maps, developed through a cascading pipeline involving convolutional neural networks and large language models, provide an intuitive yet information-rich interface to better understand biodiversity, with resolutions as precise as 50x50 meters. The website also enables exploration of specific regions, allowing users to select areas of interest on the map (e.g., urban green spaces, protected areas, or riverbanks) to view local species and their coverage. Additionally, GeoPl@ntNet generates comprehensive reports for selected regions, including insights into the number of protected species, invasive species, and endemic species."}
{"id": "2511.13786", "pdf": "https://arxiv.org/pdf/2511.13786", "abs": "https://arxiv.org/abs/2511.13786", "authors": ["Yue Ling", "Peiqi Zhang", "Zhenyi Zhang", "Peijie Zhou"], "title": "CellStream: Dynamical Optimal Transport Informed Embeddings for Reconstructing Cellular Trajectories from Snapshots Data", "categories": ["q-bio.GN", "cs.LG"], "comment": "Published as a conference paper at AAAI 2026 (oral)", "summary": "Single-cell RNA sequencing (scRNA-seq), especially temporally resolved datasets, enables genome-wide profiling of gene expression dynamics at single-cell resolution across discrete time points. However, current technologies provide only sparse, static snapshots of cell states and are inherently influenced by technical noise, complicating the inference and representation of continuous transcriptional dynamics. Although embedding methods can reduce dimensionality and mitigate technical noise, the majority of existing approaches typically treat trajectory inference separately from embedding construction, often neglecting temporal structure. To address this challenge, here we introduce CellStream, a novel deep learning framework that jointly learns embedding and cellular dynamics from single-cell snapshot data by integrating an autoencoder with unbalanced dynamical optimal transport. Compared to existing methods, CellStream generates dynamics-informed embeddings that robustly capture temporal developmental processes while maintaining high consistency with the underlying data manifold. We demonstrate CellStream's effectiveness on both simulated datasets and real scRNA-seq data, including spatial transcriptomics. Our experiments indicate significant quantitative improvements over state-of-the-art methods in representing cellular trajectories with enhanced temporal coherence and reduced noise sensitivity. Overall, CellStream provides a new tool for learning and representing continuous streams from the noisy, static snapshots of single-cell gene expression."}
{"id": "2511.13901", "pdf": "https://arxiv.org/pdf/2511.13901", "abs": "https://arxiv.org/abs/2511.13901", "authors": ["Tomas Ascoli", "Dhruba Pariyar Damay", "Jing Li", "Angela Peace", "Gregory D. Mayer", "Rebecca A. Everett"], "title": "Stoichiometric ontogenetic development influences population dynamics: Stage-structured model under nutrient co-limitations", "categories": ["q-bio.PE", "math.DS"], "comment": null, "summary": "Ecological processes depend on the flow and balance of essential elements such as carbon (C) and phosphorus (P), and changes in these elements can cause adverse effects to ecosystems. The theory of Ecological Stoichiometry offers a conceptual framework to investigate the impact of elemental imbalances on structured populations while simultaneously considering how ecological structures regulate nutrient cycling and ecosystem processes. While there have been significant advances in the development of stoichiometric food web models, these efforts often consider a homogeneous population and neglect stage-structure. The development of stage-structured population models has significantly contributed to understanding energy flow and population dynamics of ecological systems. However, stage structure models fail to consider food quality in addition to food quantity. We develop a stoichiometric stage-structure producer-grazer model that considers co-limitation of nutrients, and parameterize the model for an algae-Daphnia food chain. Our findings emphasize the impact of stoichiometric constraints on structured population dynamics. By incorporating both food quantity and quality into maturation rates, we demonstrate how stage-structured dynamics can influence outcomes in variable environments. Stage-specific parameters, such as juvenile growth and ingestion rates can drive shifts in equilibria, limit cycles, and bifurcation points. These effects are especially significant in high-light environments where nutrient limitations are most pronounced."}
{"id": "2511.13739", "pdf": "https://arxiv.org/pdf/2511.13739", "abs": "https://arxiv.org/abs/2511.13739", "authors": ["Byung-Kwan Ko", "Soowon Kim", "Seo-Hyun Lee"], "title": "Subject-Independent Imagined Speech Detection via Cross-Subject Generalization and Calibration", "categories": ["q-bio.NC", "cs.AI", "cs.SD"], "comment": "4 pages, 2 figures, Name of Conference: International Conference on Brain-Computer Interface", "summary": "Achieving robust generalization across individuals remains a major challenge in electroencephalogram based imagined speech decoding due to substantial variability in neural activity patterns. This study examined how training dynamics and lightweight subject specific adaptation influence cross subject performance in a neural decoding framework. A cyclic inter subject training approach, involving shorter per subject training segments and frequent alternation among subjects, led to modest yet consistent improvements in decoding performance across unseen target data. Furthermore, under the subject calibrated leave one subject out scheme, incorporating only 10 % of the target subjects data for calibration achieved an accuracy of 0.781 and an AUC of 0.801, demonstrating the effectiveness of few shot adaptation. These findings suggest that integrating cyclic training with minimal calibration provides a simple and effective strategy for developing scalable, user adaptive brain computer interface systems that balance generalization and personalization."}
{"id": "2511.14523", "pdf": "https://arxiv.org/pdf/2511.14523", "abs": "https://arxiv.org/abs/2511.14523", "authors": ["Sunday A. Adetunji"], "title": "Teaching Longitudinal Linear Mixed Models End-to-End: A Reproducible Case Study in Mouse Body-Weight Growth", "categories": ["stat.ME", "q-bio.OT"], "comment": "42 pages, 5 figures, 7 tables. Includes fully reproducible R code and teaching materials for longitudinal linear mixed models using a mouse body-weight case study", "summary": "Background: Linear mixed-effects models are central for analyzing longitudinal continuous data, yet many learners meet them as scattered formulas or software output rather than as a coherent workflow. There is a need for a single, reproducible case study that links questions, model building, diagnostics, and interpretation.\n  Methods: We reanalyze a published mouse body-weight experiment with 31 mice in three groups weighed weekly for 12 weeks. After reshaping the data to long format and using profile plots to motivate linear time trends, we fit three random-intercept linear mixed models: a common-slope model, a fully interacted group-by-time model, and a parsimonious model with group-specific intercepts, a shared slope for two groups, and an extra slope for the third. Models are compared using maximum likelihood, AIC, BIC, and likelihood ratio tests, and linear contrasts are used to estimate group differences in weekly means and 12 week gains.\n  Results: The parsimonious model fits as well as the fully interacted model and clearly outperforms the common-slope model, revealing small and similar gains in two groups and much steeper growth in the third, with highly significant contrasts for excess weight gain.\n  Interpretation: This case study gives a complete, executable workflow for longitudinal linear mixed modeling, from raw data and exploratory plots through model selection, diagnostics, and targeted contrasts. By making explicit the mapping from scientific questions to model terms and estimable contrasts, and by providing R code and a stepwise checklist, it serves as a practical template for teaching and applied work in biostatistics, epidemiology, and related fields"}
{"id": "2511.13791", "pdf": "https://arxiv.org/pdf/2511.13791", "abs": "https://arxiv.org/abs/2511.13791", "authors": ["Pratik Chakraborty", "Aryan Bhargava"], "title": "XAI-Driven Deep Learning for Protein Sequence Functional Group Classification", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "8 pages, 4 figures", "summary": "Proteins perform essential biological functions, and accurate classification of their sequences is critical for understanding structure-function relationships, enzyme mechanisms, and molecular interactions. This study presents a deep learning-based framework for functional group classification of protein sequences derived from the Protein Data Bank (PDB). Four architectures were implemented: Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), CNN-BiLSTM hybrid, and CNN with Attention. Each model was trained using k-mer integer encoding to capture both local and long-range dependencies. Among these, the CNN achieved the highest validation accuracy of 91.8%, demonstrating the effectiveness of localized motif detection. Explainable AI techniques, including Grad-CAM and Integrated Gradients, were applied to interpret model predictions and identify biologically meaningful sequence motifs. The discovered motifs, enriched in histidine, aspartate, glutamate, and lysine, represent amino acid residues commonly found in catalytic and metal-binding regions of transferase enzymes. These findings highlight that deep learning models can uncover functionally relevant biochemical signatures, bridging the gap between predictive accuracy and biological interpretability in protein sequence analysis."}
{"id": "2511.14694", "pdf": "https://arxiv.org/pdf/2511.14694", "abs": "https://arxiv.org/abs/2511.14694", "authors": ["Rui Zhu", "Xiaopu Zhou", "Haixu Tang", "Stephen W. Scherer", "Lucila Ohno-Machado"], "title": "Near-Lossless Model Compression Enables Longer Context Inference in DNA Large Language Models", "categories": ["q-bio.GN", "cs.AI", "cs.LG", "q-bio.PE"], "comment": null, "summary": "Trained on massive cross-species DNA corpora, DNA large language models (LLMs) learn the fundamental \"grammar\" and evolutionary patterns of genomic sequences. This makes them powerful priors for DNA sequence modeling, particularly over long ranges. However, two major constraints hinder their use in practice: the quadratic computational cost of self-attention and the growing memory required for key-value (KV) caches during autoregressive decoding. These constraints force the use of heuristics such as fixed-window truncation or sliding windows, which compromise fidelity on ultra-long sequences by discarding distant information. We introduce FOCUS (Feature-Oriented Compression for Ultra-long Self-attention), a progressive context-compression module that can be plugged into pretrained DNA LLMs. FOCUS combines the established k-mer representation in genomics with learnable hierarchical compression: it inserts summary tokens at k-mer granularity and progressively compresses attention key and value activations across multiple Transformer layers, retaining only the summary KV states across windows while discarding ordinary-token KV. A shared-boundary windowing scheme yields a stationary cross-window interface that propagates long-range information with minimal loss. We validate FOCUS on an Evo-2-based DNA LLM fine-tuned on GRCh38 chromosome 1 with self-supervised training and randomized compression schedules to promote robustness across compression ratios. On held-out human chromosomes, FOCUS achieves near-lossless fidelity: compressing a 1 kb context into only 10 summary tokens (about 100x) shifts the average per-nucleotide probability by only about 0.0004. Compared to a baseline without compression, FOCUS reduces KV-cache memory and converts effective inference scaling from O(N^2) to near-linear O(N), enabling about 100x longer inference windows on commodity GPUs with near-lossless fidelity."}
{"id": "2511.14090", "pdf": "https://arxiv.org/pdf/2511.14090", "abs": "https://arxiv.org/abs/2511.14090", "authors": ["Luke Piszkin", "Dervis C. Vural"], "title": "Evolutionary Hysteresis: Cycling about in a Rugged Landscape", "categories": ["q-bio.PE"], "comment": "12 pages, 5 figures", "summary": "In this work, we integrate theoretical modeling, molecular simulation, and empirical analysis to identify and characterize evolutionary hysteresis. We first show how epistatic interactions create bistable fitness landscapes and structural hysteresis in a two-locus Wright-Fisher model, revealing two distinct hysteresis regimes under cyclic and noisy selection. Notably, an epistatically constrained population achieves maximal average fitness at an intermediate level of environmental stochasticity. We then extend this framework to more complex systems, demonstrating robust hysteresis loops in both a disordered multi-locus model and in biophysically realistic simulation of protein structural flexibility. Finally, we present direct empirical evidence of evolutionary hysteresis. By analyzing two decades of metagenomic time-series data from freshwater C. Nanopelagicaceae experiencing strong seasonal temperature cycles, we find that approximately 65% of seasonally oscillating alleles exhibit statistically significant hysteresis. Together, these results establish hysteresis as a general, measurable feature of evolution and a potential probe of complex fitness landscapes."}
{"id": "2511.13899", "pdf": "https://arxiv.org/pdf/2511.13899", "abs": "https://arxiv.org/abs/2511.13899", "authors": ["Chengrui Li", "Yunmiao Wang", "Yule Wang", "Weihan Li", "Dieter Jaeger", "Anqi Wu"], "title": "A Disentangled Low-Rank RNN Framework for Uncovering Neural Connectivity and Dynamics", "categories": ["q-bio.NC", "cs.CE", "cs.LG"], "comment": null, "summary": "Low-rank recurrent neural networks (lrRNNs) are a class of models that uncover low-dimensional latent dynamics underlying neural population activity. Although their functional connectivity is low-rank, it lacks disentanglement interpretations, making it difficult to assign distinct computational roles to different latent dimensions. To address this, we propose the Disentangled Recurrent Neural Network (DisRNN), a generative lrRNN framework that assumes group-wise independence among latent dynamics while allowing flexible within-group entanglement. These independent latent groups allow latent dynamics to evolve separately, but are internally rich for complex computation. We reformulate the lrRNN under a variational autoencoder (VAE) framework, enabling us to introduce a partial correlation penalty that encourages disentanglement between groups of latent dimensions. Experiments on synthetic, monkey M1, and mouse voltage imaging data show that DisRNN consistently improves the disentanglement and interpretability of learned neural latent trajectories in low-dimensional space and low-rank connectivity over baseline lrRNNs that do not encourage partial disentanglement."}
{"id": "2511.13797", "pdf": "https://arxiv.org/pdf/2511.13797", "abs": "https://arxiv.org/abs/2511.13797", "authors": ["Zhaoxuan Wang", "Weichen Kang", "Yutian Han", "Lingyuan Zhao", "Bo Li"], "title": "MAT-MPNN: A Mobility-Aware Transformer-MPNN Model for Dynamic Spatiotemporal Prediction of HIV Diagnoses in California, Florida, and New England", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "21 pages, 20 figures,1 table. Preprint", "summary": "Human Immunodeficiency Virus (HIV) has posed a major global health challenge for decades, and forecasting HIV diagnoses continues to be a critical area of research. However, capturing the complex spatial and temporal dependencies of HIV transmission remains challenging. Conventional Message Passing Neural Network (MPNN) models rely on a fixed binary adjacency matrix that only encodes geographic adjacency, which is unable to represent interactions between non-contiguous counties. Our study proposes a deep learning architecture Mobility-Aware Transformer-Message Passing Neural Network (MAT-MPNN) framework to predict county-level HIV diagnosis rates across California, Florida, and the New England region. The model combines temporal features extracted by a Transformer encoder with spatial relationships captured through a Mobility Graph Generator (MGG). The MGG improves conventional adjacency matrices by combining geographic and demographic information. Compared with the best-performing hybrid baseline, the Transformer MPNN model, MAT-MPNN reduced the Mean Squared Prediction Error (MSPE) by 27.9% in Florida, 39.1% in California, and 12.5% in New England, and improved the Predictive Model Choice Criterion (PMCC) by 7.7%, 3.5%, and 3.9%, respectively. MAT-MPNN also achieved better results than the Spatially Varying Auto-Regressive (SVAR) model in Florida and New England, with comparable performance in California. These results demonstrate that applying mobility-aware dynamic spatial structures substantially enhances predictive accuracy and calibration in spatiotemporal epidemiological prediction."}
{"id": "2511.13762", "pdf": "https://arxiv.org/pdf/2511.13762", "abs": "https://arxiv.org/abs/2511.13762", "authors": ["Jiaxin Qi", "Yan Cui", "Jianqiang Huang", "Gaogang Xie"], "title": "Gene Incremental Learning for Single-Cell Transcriptomics", "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "comment": "Accepted by AAAI 2026", "summary": "Classes, as fundamental elements of Computer Vision, have been extensively studied within incremental learning frameworks. In contrast, tokens, which play essential roles in many research fields, exhibit similar characteristics of growth, yet investigations into their incremental learning remain significantly scarce. This research gap primarily stems from the holistic nature of tokens in language, which imposes significant challenges on the design of incremental learning frameworks for them. To overcome this obstacle, in this work, we turn to a type of token, gene, for a large-scale biological dataset--single-cell transcriptomics--to formulate a pipeline for gene incremental learning and establish corresponding evaluations. We found that the forgetting problem also exists in gene incremental learning, thus we adapted existing class incremental learning methods to mitigate the forgetting of genes. Through extensive experiments, we demonstrated the soundness of our framework design and evaluations, as well as the effectiveness of our method adaptations. Finally, we provide a complete benchmark for gene incremental learning in single-cell transcriptomics."}
{"id": "2511.14694", "pdf": "https://arxiv.org/pdf/2511.14694", "abs": "https://arxiv.org/abs/2511.14694", "authors": ["Rui Zhu", "Xiaopu Zhou", "Haixu Tang", "Stephen W. Scherer", "Lucila Ohno-Machado"], "title": "Near-Lossless Model Compression Enables Longer Context Inference in DNA Large Language Models", "categories": ["q-bio.GN", "cs.AI", "cs.LG", "q-bio.PE"], "comment": null, "summary": "Trained on massive cross-species DNA corpora, DNA large language models (LLMs) learn the fundamental \"grammar\" and evolutionary patterns of genomic sequences. This makes them powerful priors for DNA sequence modeling, particularly over long ranges. However, two major constraints hinder their use in practice: the quadratic computational cost of self-attention and the growing memory required for key-value (KV) caches during autoregressive decoding. These constraints force the use of heuristics such as fixed-window truncation or sliding windows, which compromise fidelity on ultra-long sequences by discarding distant information. We introduce FOCUS (Feature-Oriented Compression for Ultra-long Self-attention), a progressive context-compression module that can be plugged into pretrained DNA LLMs. FOCUS combines the established k-mer representation in genomics with learnable hierarchical compression: it inserts summary tokens at k-mer granularity and progressively compresses attention key and value activations across multiple Transformer layers, retaining only the summary KV states across windows while discarding ordinary-token KV. A shared-boundary windowing scheme yields a stationary cross-window interface that propagates long-range information with minimal loss. We validate FOCUS on an Evo-2-based DNA LLM fine-tuned on GRCh38 chromosome 1 with self-supervised training and randomized compression schedules to promote robustness across compression ratios. On held-out human chromosomes, FOCUS achieves near-lossless fidelity: compressing a 1 kb context into only 10 summary tokens (about 100x) shifts the average per-nucleotide probability by only about 0.0004. Compared to a baseline without compression, FOCUS reduces KV-cache memory and converts effective inference scaling from O(N^2) to near-linear O(N), enabling about 100x longer inference windows on commodity GPUs with near-lossless fidelity."}
{"id": "2511.13954", "pdf": "https://arxiv.org/pdf/2511.13954", "abs": "https://arxiv.org/abs/2511.13954", "authors": ["Nilay Kumar", "Priyansh Bhandari", "G. Maragatham"], "title": "A Brain Wave Encodes a Thousand Tokens: Modeling Inter-Cortical Neural Interactions for Effective EEG-based Emotion Recognition", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Human emotions are difficult to convey through words and are often abstracted in the process; however, electroencephalogram (EEG) signals can offer a more direct lens into emotional brain activity. Recent studies show that deep learning models can process these signals to perform emotion recognition with high accuracy. However, many existing approaches overlook the dynamic interplay between distinct brain regions, which can be crucial to understanding how emotions unfold and evolve over time, potentially aiding in more accurate emotion recognition. To address this, we propose RBTransformer, a Transformer-based neural network architecture that models inter-cortical neural dynamics of the brain in latent space to better capture structured neural interactions for effective EEG-based emotion recognition. First, the EEG signals are converted into Band Differential Entropy (BDE) tokens, which are then passed through Electrode Identity embeddings to retain spatial provenance. These tokens are processed through successive inter-cortical multi-head attention blocks that construct an electrode x electrode attention matrix, allowing the model to learn the inter-cortical neural dependencies. The resulting features are then passed through a classification head to obtain the final prediction. We conducted extensive experiments, specifically under subject-dependent settings, on the SEED, DEAP, and DREAMER datasets, over all three dimensions, Valence, Arousal, and Dominance (for DEAP and DREAMER), under both binary and multi-class classification settings. The results demonstrate that the proposed RBTransformer outperforms all previous state-of-the-art methods across all three datasets, over all three dimensions under both classification settings. The source code is available at: https://github.com/nnilayy/RBTransformer."}
{"id": "2511.13799", "pdf": "https://arxiv.org/pdf/2511.13799", "abs": "https://arxiv.org/abs/2511.13799", "authors": ["Hirokuni Miyamoto", "Kenta Suzuki", "Shigeharu Moriya", "Makiko Matsuura", "Naoko Tsuji", "Teruno Nakaguma", "Chitose Ishii", "Takayuki Nagatsuka", "Takashi Satoh", "Wataru Suda", "Tamotsu Kato", "Chie Shindo", "Atsushi Kurotani", "Hiroaki Kodama", "Hiroshi Masuya", "Satoshi Wada", "Nobuhiro Kawachi", "Hisashi Miyamoto", "Yukinari Tsuruda", "Yohei Shimasaki", "Shouzo Ogizo", "Nobuo Suzuki", "Tomoharu Yuge", "Toshio Takahashi", "Tomohito Ojima", "Toshio Furota", "Akio Sakamoto", "Keiichi Takimoto", "Kozo Kugimiya", "Takehiro Tanaka", "Takashi Kimura", "Yuuji Oshima", "Jun Kikuchi", "Hiroshi Ohno"], "title": "Symbiotic causal network of seagrass-bacteria-alga-diatom interactions", "categories": ["q-bio.QM"], "comment": "11 pages, 36 figures (5 main figures)", "summary": "Seagrass meadows contribute to the conservation of marine ecosystems, reduction in global warming impacts and pathogen controls. However, the decline in seagrass habitats due to environmental loads has become an urgent global issue. One way to address this issue is to better understand healthy seagrass habitats. Here, we estimate the structural characteristics of symbiotic and metabolic systems in sediments from eight coastal regions of Japan, with each region containing both seagrass-covered areas and adjacent unvegetated areas. Notably, seagrasses commonly maintain a balanced symbiotic relationship characterized by a positive association with cable bacteria (Desulfobulbaceae), nitrogen-cycling bacteria (Hyphomonadaceae), and coral alga (Corallinophycidae) and a negative association with diatoms (Diatomea). Furthermore, seagrass growth conditions influence metabolic pathways by activating nitrogen-related metabolism while attenuating methanogenesis. Our findings highlight the crucial roles of marine plants and their symbiotic systems in ensuring environmental conservation within the context of blue carbon storage across environmental gradients."}
{"id": "2511.14065", "pdf": "https://arxiv.org/pdf/2511.14065", "abs": "https://arxiv.org/abs/2511.14065", "authors": ["Felipe A. Torres", "Alejandro Weinstein", "Jesus M. Cortes", "Wael El-Deredy"], "title": "Intrinsic Resonance depends on Network Size of Coupled-Delayed Interacting Oscillators", "categories": ["q-bio.NC", "eess.SY"], "comment": "16 pages, 3 figures: 2 figures in the main text and 1 figure in the appendix", "summary": "The collective frequency that emerges from synchronized neuronal populations--the network resonance--shows a systematic relationship with brain size: whole-brain's large networks oscillate slowly, whereas finer parcellations of fixed volume exhibit faster rhythms. This resonance-size scaling has been reported in delayed neural mass models and human neuroimaging, yet the physical mechanism remained unresolved. Here we show that size-dependent resonance follows directly from propagation delays in delay-coupled phase oscillators. Starting from a Kuramoto model with heterogeneous delays, we linearize around the near-synchronous solution and obtain a closed-form approximation linking the resonance $Ω$ to the mean delay and the effective coupling field. The analysis predicts a generic scaling law: $Ω\\approx (\\sum_j c_{ij} τ)^{-1}$, so resonance is delay-limited and therefore depends systematically on geometric size or parcellation density. We evaluate four growth scenarios--expanding geometry, fixed-volume parcellation, constant geometry, and an unphysical reference case--and show that only geometry-consistent scaling satisfies the analytical prediction. Numerical simulations with heterogeneous delays validate the law and quantify its error as a function of delay dispersion. These results identify a minimal physical mechanism for size-dependent cortical resonance and provide an analytical framework that unifies numeric simulation outputs."}
{"id": "2511.14083", "pdf": "https://arxiv.org/pdf/2511.14083", "abs": "https://arxiv.org/abs/2511.14083", "authors": ["Zhonghao Liu", "Hanxue Gu", "Qihang Li", "Michael Fox", "Jay M. Levin", "Maciej A. Mazurowski", "Brian C. Lau"], "title": "Automated glenoid bone loss measurement and segmentation in CT scans for pre-operative planning in shoulder instability", "categories": ["cs.CV", "cs.AI", "q-bio.QM"], "comment": null, "summary": "Reliable measurement of glenoid bone loss is essential for operative planning in shoulder instability, but current manual and semi-automated methods are time-consuming and often subject to interreader variability. We developed and validated a fully automated deep learning pipeline for measuring glenoid bone loss on three-dimensional computed tomography (CT) scans using a linear-based, en-face view, best-circle method. Shoulder CT images of 91 patients (average age, 40 years; range, 14-89 years; 65 men) were retrospectively collected along with manual labels including glenoid segmentation, landmarks, and bone loss measurements. The multi-stage algorithm has three main stages: (1) segmentation, where we developed a U-Net to automatically segment the glenoid and humerus; (2) anatomical landmark detection, where a second network predicts glenoid rim points; and (3) geometric fitting, where we applied principal component analysis (PCA), projection, and circle fitting to compute the percentage of bone loss. The automated measurements showed strong agreement with consensus readings and exceeded surgeon-to-surgeon consistency (intraclass correlation coefficient (ICC) 0.84 vs 0.78), including in low- and high-bone-loss subgroups (ICC 0.71 vs 0.63 and 0.83 vs 0.21, respectively; P < 0.001). For classifying patients into low, medium, and high bone-loss categories, the pipeline achieved a recall of 0.714 for low and 0.857 for high severity, with no low cases misclassified as high or vice versa. These results suggest that our method is a time-efficient and clinically reliable tool for preoperative planning in shoulder instability and for screening patients with substantial glenoid bone loss. Code and dataset are available at https://github.com/Edenliu1/Auto-Glenoid-Measurement-DL-Pipeline."}
{"id": "2511.14188", "pdf": "https://arxiv.org/pdf/2511.14188", "abs": "https://arxiv.org/abs/2511.14188", "authors": ["Jinhao Yang", "Shaojiong Zhou", "Zhibin Wang", "Jiahua Xu", "Jia Chen", "Zhouqian Yin", "Tao Wei", "Chaofan Geng", "Xiaoduo Liu", "Xiang Li", "Xiaoyu Zhou", "Kun Li", "Ruolei Gu", "Raymond Dolan", "Yi Tang", "Yunzhe Liu"], "title": "A region-specific brain dysfunction underlies cognitive impairment in long COVID brain fog", "categories": ["q-bio.NC"], "comment": "58 pages, 6 figures", "summary": "Long COVID \"brain fog\" is a common and debilitating subjective syndrome often associated with persistent cognitive impairment after COVID-19 infection. Here we identify a specific regional brain dysfunction that mediates this cognitive impairment and provide evidence that targeted neuromodulation improves this deficit. In 120 patients with long COVID brain fog, we found an aberrant perceptual processing pattern. Patients with more severe brain fog committed significantly more false alarms (impulsive responses to non-signals) despite preserved overall accuracy. Both high-density (128-channel) EEG and structural MRI analyses provided converging evidence of a right inferior insula deficit, characterized by a blunted neural monitoring signal and cortical atrophy. We confirmed this deficit in a separate 796-participant UK Biobank longitudinal COVID re-imaging cohort, where COVID-19 survivors also showed selective impairment on a perceptual processing task and corresponding longitudinal atrophy of the right inferior insula compared with healthy controls. Finally, in a proof-of-principle randomized, sham-controlled trial (n = 40), a non-invasive, excitatory theta-burst ultrasound stimulation protocol targeting the right inferior insula rescued the perceptual deficit by reducing false alarms. These findings provide evidence of a causal role for right inferior insula dysfunction in long COVID-related perceptual impairment and show that modulation of this region can rescue the deficit, establishing it as a novel therapeutic target for long COVID cognitive impairment."}
{"id": "2511.14388", "pdf": "https://arxiv.org/pdf/2511.14388", "abs": "https://arxiv.org/abs/2511.14388", "authors": ["Oriol Cabanas-Tirapu", "Sergio Cobo-Lopez", "Savannah E. Sanchez", "Forest L. Rohwer", "Marta Sales-Pardo", "Roger Guimerà"], "title": "Integral Bayesian symbolic regression for optimal discovery of governing equations from scarce and noisy data", "categories": ["physics.data-an", "math.DS", "physics.bio-ph", "q-bio.QM"], "comment": null, "summary": "Understanding how systems evolve over time often requires discovering the differential equations that govern their behavior. Automatically learning these equations from experimental data is challenging when the data are noisy or limited, and existing approaches struggle, in particular, with the estimation of unobserved derivatives. Here, we introduce an integral Bayesian symbolic regression method that learns governing equations directly from raw time-series data, without requiring manual assumptions or error-prone derivative estimation. By sampling the space of symbolic differential equations and evaluating them via numerical integration, our method robustly identifies governing equations even from noisy or scarce data. We show that this approach accurately recovers ground-truth models in synthetic benchmarks, and that it makes quasi-optimal predictions of system dynamics for all noise regimes. Applying this method to bacterial growth experiments across multiple species and substrates, we discover novel growth equations that outperform classical models in accurately capturing all phases of microbial proliferation, including lag, exponential, and saturation. Unlike standard approaches, our method reveals subtle shifts in growth dynamics, such as double ramp-ups or non-canonical transitions, offering a deeper, data-driven understanding of microbial physiology."}
{"id": "2511.14453", "pdf": "https://arxiv.org/pdf/2511.14453", "abs": "https://arxiv.org/abs/2511.14453", "authors": ["Peilun Song", "Shuguang Yang", "Xiujuan Geng", "Zhenzhong Gan", "Suiping Wang", "Gangyi Feng"], "title": "Multi-network Topology Underlying Individual Language Learning Success", "categories": ["q-bio.NC"], "comment": null, "summary": "Adult language learning varies greatly among individuals. Traditionally associated with frontotemporal language regions, this variability is increasingly seen as stemming from distributed brain networks. However, the role of these networks and their topological organization in explaining these differences remains unclear. We hypothesize that graph-theory-based network analysis of intrinsic multimodal connectivities across multiple networks explains overall and component-specific variations in language learning. We tested this in 101 healthy adults who underwent resting-state fMRI, structural MRI, and diffusion tensor imaging before seven days of six artificial language training tasks. We identified one dominant general learning component shared across tasks and five task-specific ones. Cross-validated predictive models used multimodal multi-network graph-theoretic metrics to predict final learning outcomes (LO) and rates (LR). We significantly predicted the LO and LR of the general component, which were primarily contributed by dorsal attention and frontoparietal networks. Nodal local efficiency was the most consistent predictor, with additional contributions from node clustering coefficient and network centrality for LR, highlighting local robustness, mesoscale network segregation, and global influence in explaining individual differences. Only task-specific word learning LO was predictable, relying on default mode and frontoparietal hubs with high betweenness centrality and efficiency. These findings demonstrate that intrinsic network topologies underlie differences in language learning success, supporting a multiple-systems hypothesis in which attentional-control networks interact with default and subcortical systems to shape learning trajectories. This advances mechanistic understanding and paves the way for personalized language education."}
{"id": "2511.14559", "pdf": "https://arxiv.org/pdf/2511.14559", "abs": "https://arxiv.org/abs/2511.14559", "authors": ["Xinzhe Zheng", "Shiyu Jiang", "Gustavo Seabra", "Chenglong Li", "Yanjun Li"], "title": "Apo2Mol: 3D Molecule Generation via Dynamic Pocket-Aware Diffusion Models", "categories": ["q-bio.BM", "cs.AI", "cs.LG", "q-bio.QM"], "comment": "Accepted by AAAI 2026", "summary": "Deep generative models are rapidly advancing structure-based drug design, offering substantial promise for generating small molecule ligands that bind to specific protein targets. However, most current approaches assume a rigid protein binding pocket, neglecting the intrinsic flexibility of proteins and the conformational rearrangements induced by ligand binding, limiting their applicability in practical drug discovery. Here, we propose Apo2Mol, a diffusion-based generative framework for 3D molecule design that explicitly accounts for conformational flexibility in protein binding pockets. To support this, we curate a dataset of over 24,000 experimentally resolved apo-holo structure pairs from the Protein Data Bank, enabling the characterization of protein structure changes associated with ligand binding. Apo2Mol employs a full-atom hierarchical graph-based diffusion model that simultaneously generates 3D ligand molecules and their corresponding holo pocket conformations from input apo states. Empirical studies demonstrate that Apo2Mol can achieve state-of-the-art performance in generating high-affinity ligands and accurately capture realistic protein pocket conformational changes."}
{"id": "2511.14466", "pdf": "https://arxiv.org/pdf/2511.14466", "abs": "https://arxiv.org/abs/2511.14466", "authors": ["Hadi Barati", "Ali Nayerifar", "Mehdi Fardmanesh"], "title": "Effect of Dopamine in Enhancement of SNR of Cortico-Striatal-Thalamo-Cortical Loop Spiking", "categories": ["q-bio.NC"], "comment": "9 pages", "summary": "In this work, the effects of dopamine neurotransmitter within the Cortico-Striatal-Thalamo-Cortical (CSTC) loop. Simulations confirmed dopamine facilitates movement via thalamic disinhibition. Analysis of its impact on the signal-to-noise ratio (SNR) revealed a complex, region-specific outcome: SNR increased in some regions (e.g., D2 Striatum: 3.41 dB to 6.25 dB), decreased in others (e.g., Thalamus VL: 6.24 dB to 3.93 dB), and remained stable elsewhere (e.g., M1: 3.16 dB to 3.13 dB). This heterogeneity stems from dopamine increasing the excitability of D1-receptor-expressing neurons, which amplifies channel conductance noise and reduces SNR in specific circuits. Thus, dopamine acts not as a uniform signal enhancer, but as a complex modulator that critically balances facilitation and noise within the CSTC loop."}
{"id": "2511.14555", "pdf": "https://arxiv.org/pdf/2511.14555", "abs": "https://arxiv.org/abs/2511.14555", "authors": ["Alexander Olza", "Roberto Santana", "David Soto"], "title": "DecNefLab: A Modular and Interpretable Simulation Framework for Decoded Neurofeedback", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "Decoded Neurofeedback (DecNef) is a flourishing non-invasive approach to brain modulation with wide-ranging applications in neuromedicine and cognitive neuroscience. However, progress in DecNef research remains constrained by subject-dependent learning variability, reliance on indirect measures to quantify progress, and the high cost and time demands of experimentation.\n  We present DecNefLab, a modular and interpretable simulation framework that formalizes DecNef as a machine learning problem. Beyond providing a virtual laboratory, DecNefLab enables researchers to model, analyze and understand neurofeedback dynamics. Using latent variable generative models as simulated participants, DecNefLab allows direct observation of internal cognitive states and systematic evaluation of how different protocol designs and subject characteristics influence learning.\n  We demonstrate how this approach can (i) reproduce empirical phenomena of DecNef learning, (ii) identify conditions under which DecNef feedback fails to induce learning, and (iii) guide the design of more robust and reliable DecNef protocols in silico before human implementation.\n  In summary, DecNefLab bridges computational modeling and cognitive neuroscience, offering a principled foundation for methodological innovation, robust protocol design, and ultimately, a deeper understanding of DecNef-based brain modulation."}
{"id": "2511.13733", "pdf": "https://arxiv.org/pdf/2511.13733", "abs": "https://arxiv.org/abs/2511.13733", "authors": ["Wenchao Yang", "Weidong Yan", "Wenkang Liu", "Yulan Ma", "Yang Li"], "title": "THD-BAR: Topology Hierarchical Derived Brain Autoregressive Modeling for EEG Generic Representations", "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "comment": null, "summary": "Large-scale pre-trained models hold significant potential for learning universal EEG representations. However, most existing methods, particularly autoregressive (AR) frameworks, primarily rely on straightforward temporal sequencing of multi-channel EEG data, which fails to capture the rich physiological characteristics inherent to EEG signals. Moreover, their time-centered modeling approach also limits the effective representation of the dynamic spatial topology of brain activity. To address these challenges and fully exploit the potential of large-scale EEG models, we propose a novel Topology Hierarchical Derived Brain Autoregressive Modeling (THD-BAR) for EEG generic representations. The core innovation of THD-BAR lies in the introduction of the Brain Topology Hierarchy (BTH), which establishes a multi-scale spatial order for EEG channels. This hierarchical structure enables a redefinition of autoregressive learning as a \"next-scale-time prediction\" problem, effectively capturing both spatial and temporal dynamics. Based on BTH, we design a Topology-Hierarchical Vector Quantized-Variational Autoencoder (THVQ-VAE) for multi-scale tokenization and develop an enhanced Brain Autoregressive (BAR) module with specialized masking strategies for prediction. Through extensive large-scale pre-training on 17 datasets, followed by rigorous validation on 10 downstream datasets spanning 5 distinct tasks, THD-BAR consistently outperforms existing methods. These results highlight the superior generalization and modeling capabilities of our proposed approach."}
