{"id": "2509.25479", "pdf": "https://arxiv.org/pdf/2509.25479", "abs": "https://arxiv.org/abs/2509.25479", "authors": ["Zhenfeng Deng", "Ruijie Hou", "Ningrui Xie", "Mike Tyers", "Micha≈Ç Koziarski"], "title": "Discontinuous Epitope Fragments as Sufficient Target Templates for Efficient Binder Design", "categories": ["q-bio.BM", "cs.AI"], "comment": "Accepted by NeurIPS2025-AI4Science", "summary": "Recent advances in structure-based protein design have accelerated de novo\nbinder generation, yet interfaces on large domains or spanning multiple domains\nremain challenging due to high computational cost and declining success with\nincreasing target size. We hypothesized that protein folding neural networks\n(PFNNs) operate in a ``local-first'' manner, prioritizing local interactions\nwhile displaying limited sensitivity to global foldability.Guided by this\nhypothesis, we propose an epitope-only strategy that retains only the\ndiscontinuous surface residues surrounding the binding site. Compared to\nintact-domain workflows, this approach improves in silico success rates by up\nto 80% and reduces the average time per successful design by up to forty-fold,\nenabling binder design against previously intractable targets such as ClpP and\nALS3. Building on this foundation, we further developed a tailored pipeline\nthat incorporates a Monte Carlo-based evolution step to overcome local minima\nand a position-specific biased inverse folding step to refine sequence\npatterns. Together, these advances not only establish a generalizable framework\nfor efficient binder design against structurally large and otherwise\ninaccessible targets, but also support the broader ``local-first'' hypothesis\nas a guiding principle for PFNN-based design."}
{"id": "2509.25872", "pdf": "https://arxiv.org/pdf/2509.25872", "abs": "https://arxiv.org/abs/2509.25872", "authors": ["Yan Wang", "Hao Wu", "Simon Olsson"], "title": "Marginal Girsanov Reweighting: Stable Variance Reduction via Neural Ratio Estimation", "categories": ["q-bio.QM", "q-bio.BM"], "comment": null, "summary": "Recovering unbiased properties from biased or perturbed simulations is a\ncentral challenge in rare-event sampling. Classical Girsanov Reweighting (GR)\noffers a principled solution by yielding exact pathwise probability ratios\nbetween perturbed and reference processes. However, the variance of GR weights\ngrows rapidly with time, rendering it impractical for long-horizon reweighting.\nWe introduce Marginal Girsanov Reweighting (MGR), which mitigates variance\nexplosion by marginalizing over intermediate paths, producing stable and\nscalable weights for long-timescale dynamics. Experiments demonstrate that MGR\n(i) accurately recovers kinetic properties from umbrella-sampling trajectories\nin molecular dynamics, and (ii) enables efficient Bayesian parameter inference\nfor stochastic differential equations with temporally sparse observations."}
{"id": "2509.26566", "pdf": "https://arxiv.org/pdf/2509.26566", "abs": "https://arxiv.org/abs/2509.26566", "authors": ["JunJie Wee", "Faisal Suwayyid", "Mushal Zia", "Hongsong Feng", "Yuta Hozumi", "Guo-Wei Wei"], "title": "Commutative algebra neural network reveals genetic origins of diseases", "categories": ["q-bio.QM", "math.AC", "q-bio.BM"], "comment": null, "summary": "Genetic mutations can disrupt protein structure, stability, and solubility,\ncontributing to a wide range of diseases. Existing predictive models often lack\ninterpretability and fail to integrate physical and chemical interactions\ncritical to molecular mechanisms. Moreover, current approaches treat disease\nassociation, stability changes, and solubility alterations as separate tasks,\nlimiting model generalizability. In this study, we introduce a unified\nframework based on multiscale commutative algebra to capture intrinsic physical\nand chemical interactions for the first time. Leveraging Persistent\nStanley-Reisner Theory, we extract multiscale algebraic invariants to build a\nCommutative Algebra neural Network (CANet). Integrated with transformer\nfeatures and auxiliary physical features, we apply CANet to tackle three key\ndomains for the first time: disease-associated mutations, mutation-induced\nprotein stability changes, and solubility changes upon mutations. Across six\nbenchmark tasks, CANet and its gradient boosting tree counterpart, CATree,\nconsistently attain state-of-the-art performance, achieving up to 7.5%\nimprovement in predictive accuracy. Our approach offers multiscale,\nmechanistic, interpretable,and generalizable models for predicting\ndisease-mutation associations."}
{"id": "2509.25485", "pdf": "https://arxiv.org/pdf/2509.25485", "abs": "https://arxiv.org/abs/2509.25485", "authors": ["Bryan Bailey-Feliciano", "George VanVeckhoven", "Youngmin Park", "Yongchen Tai", "Jing Pan"], "title": "A Mathematical Model of Hematopoiesis during Systemic Infection", "categories": ["q-bio.CB"], "comment": null, "summary": "Chronic critical illness (CCI) is a disease state in which, following an\ninitial insult, a patient neither recovers nor dies but instead remains in a\nstate of critical illness. CCI is characterized by prolonged organ dysfunction,\nweight loss, and persistent increased vulnerability to infection. Recent data\nhas shown that patients with CCI generally exhibit persistent immune\ndysfunction, characterized by prolonged elevation of specific pro-inflammatory\ncytokines. In this paper, we introduce a host response model that couples\nhematopoiesis dynamics with immune response to infection. Specifically, we\nincorporate the reactions between pro-inflammatory and anti-inflammatory\nsignals with specific hematopoietic stem cell compartments with a reduced model\nof acute inflammation. We found that a maladaptive hematopoietic response to\npathogenic insult is able to qualitatively reproduce similar behavior to that\nseen in CCI patients, namely the presence of a persistent, elevated level of\npro-inflammatory cytokines. This suggests that maladaptive hematopoietic\nresponses in vivo may play a role in the development of CCI."}
{"id": "2509.25291", "pdf": "https://arxiv.org/pdf/2509.25291", "abs": "https://arxiv.org/abs/2509.25291", "authors": ["Liban Ismail", "Yahyeh Souleiman", "Saraless Nadarajah", "Abdisalam Hassan"], "title": "Mathematical Framework for Epidemic Dynamics: Optimal Control and Global Sensitivity Analysis", "categories": ["q-bio.PE", "math.DS"], "comment": null, "summary": "This study develops and analyzes an extended Susceptible, Infected,\nHospitalized and Recovered (SIHR) model incorporating time dependent control\nfunctions to capture preventive measures (e.g., distancing, mask use) and\nresource limited therapeutic interventions. This formulation provides a\nrealistic mathematical framework for modeling public health responses beyond\nclassical uncontrolled epidemic models. The control design is integrated into\nthe model via an optimal control framework, solved numerically using the\nForward Backward Sweep method, enabling the exploration of intervention\nstrategies on epidemic dynamics, including infection prevalence,\nhospitalization burden, and the effective reproduction number. To assess the\nrobustness of these strategies under uncertainty, we employ Polynomial Chaos\nExpansion combined with Sobol sensitivity indices, quantifying the influence of\nkey epidemiological parameters (transmission, recovery, hospitalization rates)\non model outcomes. Numerical simulations, calibrated to Djiboutian COVID 19\ndata, show that combined preventive and therapeutic interventions substantially\nmitigate epidemic burden, though their effectiveness depends critically on\ntransmission related uncertainties. The originality of this work lies in\ncombining optimal control theory with global sensitivity analysis, thus\nbridging numerical methods, optimization, and epidemic modeling. This\nintegrated approach offers a general mathematical framework for designing and\nevaluating control strategies in infectious disease outbreaks, with\napplications to low resource settings and beyond."}
{"id": "2509.25501", "pdf": "https://arxiv.org/pdf/2509.25501", "abs": "https://arxiv.org/abs/2509.25501", "authors": ["Yamnesh Agrawal", "Masoud Zamani", "James R. Thunes", "Spandan Maiti", "Anne M. Robertson"], "title": "Load Transfer along Continuous Collagen Fibers Reduces the Importance of Wall Thickness Variations", "categories": ["q-bio.TO"], "comment": null, "summary": "The mechanical response of biological soft tissues is influenced by wall\nheterogeneity, including spatial variations in wall thickness. Traditional\nmodels for homogeneous soft tissues under uniaxial loading predict higher\nstretch and stress in thinner regions. In fact, large gradients in stretch and\nstress are predicted to be induced by spatial variations in wall thickness. In\nprior studies, the role of collagen fibers in regions of thickness transition\nhas been largely neglected or only considered in terms of their effect on\nanisotropy. Here, we explore the role of collagen fibers as primary\nload-bearing components across regions of varying wall thickness, using a\nthree-dimensional representative volume element (RVE) model incorporating\nexplicit collagen fiber architecture and a gradual thickness gradient. We\nexamined two distinct collagen fiber configurations across the thickness\ntransition: one featuring abrupt fiber termination and another with fiber\ncontinuity. Finite element analysis (FEA) under uniaxial tension revealed that\nload transfer by continuous fibers across the specimen markedly reduced the\nimportance of the change in wall thickness, with stretch differentials dropping\nfrom ~20% (fiber-termination network) to 0.68% (continuous fibers) and stress\ndifferentials dropping from ~65% (fiber-termination network) to 2.3%\n(continuous fibers). Fiber tortuosity delayed the point at which mechanical\nresponse was governed by fiber structure. These findings demonstrate the\ncritical role of fiber continuity in reducing stretch and stress gradients\nacross regions of varying wall thickness and clarify the importance of\naccurately representing fiber architecture when modeling soft tissues with\nheterogeneous wall thickness."}
{"id": "2509.25274", "pdf": "https://arxiv.org/pdf/2509.25274", "abs": "https://arxiv.org/abs/2509.25274", "authors": ["Darren King", "Yaser Atlasi", "Gholamreza Rafiee"], "title": "DNABERT-2: Fine-Tuning a Genomic Language Model for Colorectal Gene Enhancer Classification", "categories": ["q-bio.GN", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures, 2 tables", "summary": "Gene enhancers control when and where genes switch on, yet their sequence\ndiversity and tissue specificity make them hard to pinpoint in colorectal\ncancer. We take a sequence-only route and fine-tune DNABERT-2, a transformer\ngenomic language model that uses byte-pair encoding to learn variable-length\ntokens from DNA. Using assays curated via the Johnston Cancer Research Centre\nat Queen's University Belfast, we assembled a balanced corpus of 2.34 million 1\nkb enhancer sequences, applied summit-centered extraction and rigorous\nde-duplication including reverse-complement collapse, and split the data\nstratified by class. With a 4096-term vocabulary and a 232-token context chosen\nempirically, the DNABERT-2-117M classifier was trained with Optuna-tuned\nhyperparameters and evaluated on 350742 held-out sequences. The model reached\nPR-AUC 0.759, ROC-AUC 0.743, and best F1 0.704 at an optimized threshold\n(0.359), with recall 0.835 and precision 0.609. Against a CNN-based EnhancerNet\ntrained on the same data, DNABERT-2 delivered stronger threshold-independent\nranking and higher recall, although point accuracy was lower. To our knowledge,\nthis is the first study to apply a second-generation genomic language model\nwith BPE tokenization to enhancer classification in colorectal cancer,\ndemonstrating the feasibility of capturing tumor-associated regulatory signals\ndirectly from DNA sequence alone. Overall, our results show that\ntransformer-based genomic models can move beyond motif-level encodings toward\nholistic classification of regulatory elements, offering a novel path for\ncancer genomics. Next steps will focus on improving precision, exploring hybrid\nCNN-transformer designs, and validating across independent datasets to\nstrengthen real-world utility."}
{"id": "2509.25453", "pdf": "https://arxiv.org/pdf/2509.25453", "abs": "https://arxiv.org/abs/2509.25453", "authors": ["Vasilii Tiselko", "Alexander Gorsky", "Yuri Dabaghian"], "title": "Neural Receptive Fields, Stimulus Space Embedding and Effective Geometry of Scale-Free Networks", "categories": ["q-bio.NC"], "comment": "21 pages, 9 figures", "summary": "Understanding how neuronal dynamics couple with stimuli space and how\nreceptive fields emerge and organize within brain networks remains a\nfundamental challenge in neuroscience. Several models attempted to explain\nthese phenomena, often by adjusting the network to empirical manifestations,\nbut struggled to achieve biological plausibility. Here, we propose a\nphysiologically grounded model in which receptive fields and population-level\nattractor dynamics emerge naturally from the effective hyperbolic geometry of\nscale-free networks. In particular, we associate stimulus space with the\nboundary of a hyperbolic embedding, and study the resulting neural dynamics in\nboth rate-based and spiking implementations. The resulting localized attractors\nfaithfully reflect the structure of the stimulus space and capture key\nproperties of the receptive fields without fine-tuning of local connectivity,\nexhibiting a direct relation between a neuron's connectivity degree and the\ncorresponding receptive field size. The model generalizes to stimulus spaces of\narbitrary dimensionality and scale, encompassing various modalities, such as\norientation and place selectivity. We also provide direct experimental evidence\nin support of these results, based on analyses of hippocampal place fields\nrecorded on a linear track. Overall, our framework offers a novel organizing\nprinciple for receptive field formation and establishes a direct link between\nnetwork structure, stimulus space encoding, and neural dynamics."}
{"id": "2509.25872", "pdf": "https://arxiv.org/pdf/2509.25872", "abs": "https://arxiv.org/abs/2509.25872", "authors": ["Yan Wang", "Hao Wu", "Simon Olsson"], "title": "Marginal Girsanov Reweighting: Stable Variance Reduction via Neural Ratio Estimation", "categories": ["q-bio.QM", "q-bio.BM"], "comment": null, "summary": "Recovering unbiased properties from biased or perturbed simulations is a\ncentral challenge in rare-event sampling. Classical Girsanov Reweighting (GR)\noffers a principled solution by yielding exact pathwise probability ratios\nbetween perturbed and reference processes. However, the variance of GR weights\ngrows rapidly with time, rendering it impractical for long-horizon reweighting.\nWe introduce Marginal Girsanov Reweighting (MGR), which mitigates variance\nexplosion by marginalizing over intermediate paths, producing stable and\nscalable weights for long-timescale dynamics. Experiments demonstrate that MGR\n(i) accurately recovers kinetic properties from umbrella-sampling trajectories\nin molecular dynamics, and (ii) enables efficient Bayesian parameter inference\nfor stochastic differential equations with temporally sparse observations."}
{"id": "2509.25554", "pdf": "https://arxiv.org/pdf/2509.25554", "abs": "https://arxiv.org/abs/2509.25554", "authors": ["Michael J. Plank", "Matthew J. Simpson"], "title": "Continuum models describing probabilistic motion of tagged agents in exclusion processes", "categories": ["q-bio.PE"], "comment": null, "summary": "Lattice-based random walk models are widely used to study populations of\nmigrating cells with motility bias and proliferation. Crowding is typically\nrepresented by volume exclusion, where each lattice site can be occupied by at\nmost one agent and conflicting moves are aborted. This framework enables\nsimulations that yield both population-level spatiotemporal agent density\nprofiles and individual agent trajectories, comparable to experimental\ncell-tracking data. Previous continuum models for tagged-agent trajectories\ncaptured trajectory information only, and overlooked any measure of\nvariability. This is an important limitation since trajectory data is\ninherently variable. To address this limitation, here we derive partial\ndifferential equations for the probability density function of tagged-agent\ntrajectories. This continuum description has a clear physical interpretation,\nagrees well with distributional data from stochastic simulations, reveals the\nrole of stochasticity in different contexts, and generalises to multiple\nsubpopulations of distinct agents."}
{"id": "2509.25573", "pdf": "https://arxiv.org/pdf/2509.25573", "abs": "https://arxiv.org/abs/2509.25573", "authors": ["David Laub", "Ethan Armand", "Arda Pekis", "Zekai Chen", "Irsyad Adam", "Shaun Porwal", "Bing Ren", "Kevin Brown", "Hannah Carter"], "title": "GenVarFormer: Predicting gene expression from long-range mutations in cancer", "categories": ["q-bio.GN"], "comment": null, "summary": "Distinguishing the rare \"driver\" mutations that fuel cancer progression from\nthe vast background of \"passenger\" mutations in the non-coding genome is a\nfundamental challenge in cancer biology. A primary mechanism that non-coding\ndriver mutations contribute to cancer is by affecting gene expression,\npotentially from millions of nucleotides away. However, existing predictors of\ngene expression from mutations are unable to simultaneously handle interactions\nspanning millions of base pairs, the extreme sparsity of somatic mutations, and\ngeneralize to unseen genes. To overcome these limitations, we introduce\nGenVarFormer (GVF), a novel transformer-based architecture designed to learn\nmutation representations and their impact on gene expression. GVF efficiently\npredicts the effect of mutations up to 8 million base pairs away from a gene by\nonly considering mutations and their local DNA context, while omitting the vast\nintermediate sequence. Using data from 864 breast cancer samples from The\nCancer Genome Atlas, we demonstrate that GVF predicts gene expression with\n26-fold higher correlation across samples than current models. In addition, GVF\nis the first model of its kind to generalize to unseen genes and samples\nsimultaneously. Finally, we find that GVF patient embeddings are more\ninformative than ground-truth gene expression for predicting overall patient\nsurvival in the most prevalent breast cancer subtype, luminal A. GVF embeddings\nand gene expression yielded concordance indices of $0.706^{\\pm0.136}$ and\n$0.573^{\\pm0.234}$, respectively. Our work establishes a new state-of-the-art\nfor modeling the functional impact of non-coding mutations in cancer and\nprovides a powerful new tool for identifying potential driver events and\nprognostic biomarkers."}
{"id": "2509.25640", "pdf": "https://arxiv.org/pdf/2509.25640", "abs": "https://arxiv.org/abs/2509.25640", "authors": ["Denizhan Pak", "Quan Le Thien", "Christopher J. Agostino"], "title": "Analysis of a Spatialized Brain-Body-Environment System", "categories": ["q-bio.NC", "cs.NE"], "comment": "9 pages, 7 figures, Artificial Life Conference 2025, selected for\n  talk", "summary": "The brain-body-environment framework studies adaptive behavior through\nembodied and situated agents, emphasizing interactions between brains,\nbiomechanics, and environmental dynamics. However, many models often treat the\nbrain as a network of coupled ordinary differential equations (ODEs),\nneglecting finer spatial properties which can not only increase model\ncomplexity but also constrain observable neural dynamics. To address this\nlimitation, we propose a spatially extended approach using partial differential\nequations (PDEs) for both the brain and body. As a case study, we revisit a\npreviously developed model of a child swinging, now incorporating spatial\ndynamics. By considering the spatio-temporal properties of the brain and body,\nwe analyze how input location and propagation along a PDE influence behavior.\nThis approach offers new insights into the role of spatial organization in\nadaptive behavior, bridging the gap between abstract neural models and the\nphysical constraints of embodied systems. Our results highlight the importance\nof spatial dynamics in understanding brain-body-environment interactions."}
{"id": "2509.26566", "pdf": "https://arxiv.org/pdf/2509.26566", "abs": "https://arxiv.org/abs/2509.26566", "authors": ["JunJie Wee", "Faisal Suwayyid", "Mushal Zia", "Hongsong Feng", "Yuta Hozumi", "Guo-Wei Wei"], "title": "Commutative algebra neural network reveals genetic origins of diseases", "categories": ["q-bio.QM", "math.AC", "q-bio.BM"], "comment": null, "summary": "Genetic mutations can disrupt protein structure, stability, and solubility,\ncontributing to a wide range of diseases. Existing predictive models often lack\ninterpretability and fail to integrate physical and chemical interactions\ncritical to molecular mechanisms. Moreover, current approaches treat disease\nassociation, stability changes, and solubility alterations as separate tasks,\nlimiting model generalizability. In this study, we introduce a unified\nframework based on multiscale commutative algebra to capture intrinsic physical\nand chemical interactions for the first time. Leveraging Persistent\nStanley-Reisner Theory, we extract multiscale algebraic invariants to build a\nCommutative Algebra neural Network (CANet). Integrated with transformer\nfeatures and auxiliary physical features, we apply CANet to tackle three key\ndomains for the first time: disease-associated mutations, mutation-induced\nprotein stability changes, and solubility changes upon mutations. Across six\nbenchmark tasks, CANet and its gradient boosting tree counterpart, CATree,\nconsistently attain state-of-the-art performance, achieving up to 7.5%\nimprovement in predictive accuracy. Our approach offers multiscale,\nmechanistic, interpretable,and generalizable models for predicting\ndisease-mutation associations."}
{"id": "2509.25615", "pdf": "https://arxiv.org/pdf/2509.25615", "abs": "https://arxiv.org/abs/2509.25615", "authors": ["Kevin Hudnall", "Raissa D'Souza"], "title": "What does the tree of life look like as it grows? Evolution and the multifractality of time", "categories": ["q-bio.PE", "math.DS", "math.PR", "physics.bio-ph", "60J80, 28A80, 37F35, 92Bxx"], "comment": "28 pages, 12 figures", "summary": "By unifying three foundational principles of modern biology, we develop a\nmathematical framework to analyze the growing tree of life. Contrary to the\nstatic case, where the analogy between phylogenetic trees and the tree that\ngrows in soil is drawn, our framework shows that the living tree of life is\nanalogous to a Cantor dust where each branch is a distinct fractal curve. The\nsystem as a whole is therefore multifractal in the sense that it consists of\nmany unique fractals. The three foundational principles for the mathematical\nframework are that phylogeny is nested, phylogeny is dualistic (i.e.,\ntransitive between singularities and populations), and phylogeny is stochastic.\nIntegrating these three principles, we model the dynamic (i.e., living) tree of\nlife as a random iterated function system that generates unique convexly\nrelated sequences of branching random variables (visualized in Animation 1).\nThe multifractal nature of this dynamic tree of life implies that, for any two\nliving entities, the time interval from their last common ancestor to the\npresent moment is a distinct fractal curve for each. Thus, the length of a time\ninterval along each distinct branch is unique, so that time is also\nmultifractal and not an ultrametric on the tree of life."}
{"id": "2509.25884", "pdf": "https://arxiv.org/pdf/2509.25884", "abs": "https://arxiv.org/abs/2509.25884", "authors": ["Ping Xu", "Zaitian Wang", "Zhirui Wang", "Pengjiang Li", "Ran Zhang", "Gaoyang Li", "Hanyu Xie", "Jiajia Wang", "Yuanchun Zhou", "Pengfei Wang"], "title": "scUnified: An AI-Ready Standardized Resource for Single-Cell RNA Sequencing Analysis", "categories": ["q-bio.GN", "cs.AI"], "comment": null, "summary": "Single-cell RNA sequencing (scRNA-seq) technology enables systematic\ndelineation of cellular states and interactions, providing crucial insights\ninto cellular heterogeneity. Building on this potential, numerous computational\nmethods have been developed for tasks such as cell clustering, cell type\nannotation, and marker gene identification. To fully assess and compare these\nmethods, standardized, analysis-ready datasets are essential. However, such\ndatasets remain scarce, and variations in data formats, preprocessing\nworkflows, and annotation strategies hinder reproducibility and complicate\nsystematic evaluation of existing methods. To address these challenges, we\npresent scUnified, an AI-ready standardized resource for single-cell RNA\nsequencing data that consolidates 13 high-quality datasets spanning two species\n(human and mouse) and nine tissue types. All datasets undergo standardized\nquality control and preprocessing and are stored in a uniform format to enable\ndirect application in diverse computational analyses without additional data\ncleaning. We further demonstrate the utility of scUnified through experimental\nanalyses of representative biological tasks, providing a reproducible\nfoundation for the standardized evaluation of computational methods on a\nunified dataset."}
{"id": "2509.26019", "pdf": "https://arxiv.org/pdf/2509.26019", "abs": "https://arxiv.org/abs/2509.26019", "authors": ["Xiaoyu Zhang", "Pengcheng Yang", "Yifei Zhang", "Bowei Qin", "Qiang Luo", "Wei Lin", "Xin Lu"], "title": "Structural Heterogeneity of the Drosophila Brain Network", "categories": ["q-bio.NC"], "comment": null, "summary": "Decoding the heterogeneity of biological neural systems is key to\nunderstanding the nervous system's complex dynamical behaviors. This study\nanalyzes the comprehensive Drosophila brain connectome, which is the most\nrecent data set, containing over 130,000 neurons and 50 million synapses. We\nconducted meticulous analyses of both network and spatial structure. Our\nfindings reveal significant heterogeneity in network properties and distinct\nspatial clustering across functional regions. Besides, our analysis revealed a\nmodular organizational pattern within the neural network, wherein regions with\nsimilar functions exhibited higher connection densities, forming distinct\ncommunity structures. Moreover, we observed spatial clustering within\nfunctional regions but was not statistically significant. Additionally, we\nidentify pervasive bilateral symmetry in network topology and spatial\norganization. Simulations based on the Kuramoto model demonstrate that the\nfunctional asymmetry between cerebral hemispheres arises from disparities in\nthe intrinsic frequencies of neurons rather than from structural asymmetry\nwithin the neural network itself. Finally, we develop a 3D connectome\nvisualization tool for detailed mapping of neuronal morphology. These insights\nadvance our understanding of neural network organization and complexity in\nbiological systems."}
{"id": "2509.25509", "pdf": "https://arxiv.org/pdf/2509.25509", "abs": "https://arxiv.org/abs/2509.25509", "authors": ["Langzhou He", "Junyou Zhu", "Fangxin Wang", "Junhua Liu", "Haoyan Xu", "Yue Zhao", "Philip S. Yu", "Qitian Wu"], "title": "Can Molecular Foundation Models Know What They Don't Know? A Simple Remedy with Preference Optimization", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Molecular foundation models are rapidly advancing scientific discovery, but\ntheir unreliability on out-of-distribution (OOD) samples severely limits their\napplication in high-stakes domains such as drug discovery and protein design. A\ncritical failure mode is chemical hallucination, where models make\nhigh-confidence yet entirely incorrect predictions for unknown molecules. To\naddress this challenge, we introduce Molecular Preference-Aligned Instance\nRanking (Mole-PAIR), a simple, plug-and-play module that can be flexibly\nintegrated with existing foundation models to improve their reliability on OOD\ndata through cost-effective post-training. Specifically, our method formulates\nthe OOD detection problem as a preference optimization over the estimated OOD\naffinity between in-distribution (ID) and OOD samples, achieving this goal\nthrough a pairwise learning objective. We show that this objective essentially\noptimizes AUROC, which measures how consistently ID and OOD samples are ranked\nby the model. Extensive experiments across five real-world molecular datasets\ndemonstrate that our approach significantly improves the OOD detection\ncapabilities of existing molecular foundation models, achieving up to 45.8%,\n43.9%, and 24.3% improvements in AUROC under distribution shifts of size,\nscaffold, and assay, respectively."}
{"id": "2509.26223", "pdf": "https://arxiv.org/pdf/2509.26223", "abs": "https://arxiv.org/abs/2509.26223", "authors": ["Chenyu Li", "Elias Ziyadeh", "Yash Sharma", "Bernhard Dumoulin", "Jonathan Levinsohn", "Eunji Ha", "Siyu Pan", "Vishwanatha Rao", "Madhav Subramaniyam", "Mario Szegedy", "Nancy Zhang", "Katalin Susztak"], "title": "Nephrobase Cell+: Multimodal Single-Cell Foundation Model for Decoding Kidney Biology", "categories": ["q-bio.GN"], "comment": null, "summary": "Background: Large foundation models have revolutionized single-cell analysis,\nyet no kidney-specific model currently exists, and it remains unclear whether\norgan-focused models can outperform generalized models. The kidney's complex\ncellular architecture further complicate integration of large-scale omics data,\nwhere current frameworks trained on limited datasets struggle to correct batch\neffects, capture cross-modality variation, and generalize across species.\nMethods: We developed Nephrobase Cell+, the first kidney-focused large\nfoundation model, pretrained on ~100 billion tokens from ~39.5 million\nsingle-cell and single-nucleus profiles across 4,319 samples. Nephrobase Cell+\nuses a transformer-based encoder-decoder architecture with gene-token\ncross-attention and a mixture-of-experts module for scalable representation\nlearning. Results: Nephrobase Cell+ sets a new benchmark for kidney single-cell\nanalysis. It produces tightly clustered, biologically coherent embeddings in\nhuman and mouse kidneys, far surpassing previous foundation models such as\nGeneformer, scGPT, and UCE, as well as traditional methods such as PCA and\nautoencoders. It achieves the highest cluster concordance and batch-mixing\nscores, effectively removing donor/assay batch effects while preserving\ncell-type structure. Cross-species evaluation shows superior alignment of\nhomologous cell types and >90% zero-shot annotation accuracy for major kidney\nlineages in both human and mouse. Even its 1B-parameter and 500M variants\nconsistently outperform all existing models. Conclusions: Nephrobase Cell+\ndelivers a unified, high-fidelity representation of kidney biology that is\nrobust, cross-species transferable, and unmatched by current single-cell\nfoundation models, offering a powerful resource for kidney genomics and disease\nresearch."}
{"id": "2509.26083", "pdf": "https://arxiv.org/pdf/2509.26083", "abs": "https://arxiv.org/abs/2509.26083", "authors": ["Adi Wijaya", "Said Hasibuan", "Wiga Maulana Baihaqi", "Rizki Darmawan", "Rifkie Primartha", "Catur Supriyanto"], "title": "Bibliometric-enhanced Systematic Literature Review of EEG in Education: Learning Concepts, Computational Methods, and Research Opportunities", "categories": ["q-bio.NC", "eess.SP"], "comment": "29 pages, 6 figures, 5 tables", "summary": "Application of electroencephalography (EEG) in educational research has grown\nsubstantially, yet a comprehensive integration of methodological frameworks,\neducational constructs, computational methods, and research gaps remains\nlimited. This study applies a Bibliometric-enhanced Systematic Literature\nReview (BenSLR) to provide a systematic overview of EEG in education.\nLiterature was extracted from Scopus, screened, and analyzed, with keyword\nco-occurrence evaluated using VOSviewer and emerging trends visualized through\nan Enhanced Strategic Diagram via BiblioPlot. Key findings include engagement,\nattention, and learning style as prominent constructs, with machine learning\nand deep learning frequently employed for modeling complex cognitive states.\nEEG signal processing, feature extraction, and assessment of cognitive and\naffective states were recurrent across studies. Innovative interventions such\nas virtual reality and neurofeedback demonstrate EEG's role in supporting\nadaptive and individualized learning experiences. Challenges remain in linking\nneural markers with observable learning behaviors, extending measurements\nbeyond attention and working memory, and enhancing predictive model\ngeneralizability. The study demonstrates BenSLR's potential to integrate\nqualitative and quantitative perspectives and offers a transferable approach\nfor other research areas to develop methodologies and evidence-based\neducational interventions."}
{"id": "2509.26577", "pdf": "https://arxiv.org/pdf/2509.26577", "abs": "https://arxiv.org/abs/2509.26577", "authors": ["Chiara Mattamira", "Olivia Prosper Feldman"], "title": "Stochasticity and Practical Identifiability in Epidemic Models: A Monte Carlo Perspective", "categories": ["stat.ME", "q-bio.QM"], "comment": null, "summary": "Assessing the practical identifiability of epidemic models is essential for\ndetermining whether parameters can be meaningfully estimated from observed\ndata. Monte Carlo (MC) methods provide an accessible and intuitive framework;\nhowever, their standard implementation - perturbing deterministic trajectories\nwith independent Gaussian noise - rests on assumptions poorly suited to\nepidemic processes, which are inherently stochastic, temporally correlated, and\nhighly variable, especially in small populations or under slow transmission. In\nthis study, we investigate the structure of stochastic variability in the\nclassic Susceptible-Infected-Recovered (SIR) model across a range of\nepidemiological regimes, and assess whether it can be represented within the\nindependent Gaussian noise framework. We show that continuous-time Markov chain\n(CTMC) trajectories consistently exhibit super-Poissonian variability and\nstrong temporal dependence. Through coverage analysis, we further demonstrate\nthat independent Gaussian noise systematically underestimates the variability\nof the underlying stochastic process, leading to overly optimistic conclusions\nabout parameter identifiability. In addition, we propose a hybrid simulation\napproach that introduces time- and amplitude-dependent variability into\ndeterministic ODE trajectories, preserving computational efficiency while\ncapturing key features of epidemic stochasticity. Our findings highlight the\nlimitations of the standard MC algorithm and provide a pathway for\nincorporating more realistic noise structures into epidemic inference."}
{"id": "2509.25346", "pdf": "https://arxiv.org/pdf/2509.25346", "abs": "https://arxiv.org/abs/2509.25346", "authors": ["Lawrence Phillips", "Marc Boubnovski Martell", "Aditya Misra", "Josefa Lia Stoisser", "Cesar A. Prada-Medina", "Rory Donovan-Maiye", "Kaspar M√§rtens"], "title": "SynthPert: Enhancing LLM Biological Reasoning via Synthetic Reasoning Traces for Cellular Perturbation Prediction", "categories": ["cs.AI", "cs.LG", "q-bio.CB", "q-bio.GN"], "comment": null, "summary": "Predicting cellular responses to genetic perturbations represents a\nfundamental challenge in systems biology, critical for advancing therapeutic\ndiscovery and virtual cell modeling. While large language models (LLMs) show\npromise for biological reasoning, their application to perturbation prediction\nremains underexplored due to challenges in adapting them to structured\nexperimental data. We present SynthPert, a novel method that enhances LLM\nperformance through supervised fine-tuning on synthetic reasoning traces\ngenerated by frontier models. Using the PerturbQA benchmark, we demonstrate\nthat our approach not only achieves state-of-the-art performance but surpasses\nthe capabilities of the frontier model that generated the training data. Our\nresults reveal three key insights: (1) Synthetic reasoning traces effectively\ndistill biological knowledge even when partially inaccurate, (2) This approach\nenables cross-cell-type generalization with 87% accuracy on unseen RPE1 cells,\nand (3) Performance gains persist despite using only 2% of quality-filtered\ntraining data. This work shows the effectiveness of synthetic reasoning\ndistillation for enhancing domain-specific reasoning in LLMs."}
{"id": "2509.26085", "pdf": "https://arxiv.org/pdf/2509.26085", "abs": "https://arxiv.org/abs/2509.26085", "authors": ["Yu Chen", "Jing Lian", "Zhaofei Yu", "Jizhao Liu", "Jisheng Dang", "Gang Wang"], "title": "A Chaotic Dynamics Framework Inspired by Dorsal Stream for Event Signal Processing", "categories": ["q-bio.NC"], "comment": null, "summary": "Event cameras are bio-inspired vision sensor that encode visual information\nwith high dynamic range, high temporal resolution, and low latency.Current\nstate-of-the-art event stream processing methods rely on end-to-end deep\nlearning techniques. However, these models are heavily dependent on data\nstructures, limiting their stability and generalization capabilities across\ntasks, thereby hindering their deployment in real-world scenarios. To address\nthis issue, we propose a chaotic dynamics event signal processing framework\ninspired by the dorsal visual pathway of the brain. Specifically, we utilize\nContinuous-coupled Neural Network (CCNN) to encode the event stream. CCNN\nencodes polarity-invariant event sequences as periodic signals and\npolarity=changing event sequences as chaotic signals. We then use continuous\nwavelet transforms to analyze the dynamical states of CCNN neurons and\nestablish the high-order mappings of the event stream. The effectiveness of our\nmethod is validated through integration with conventional classification\nnetworks, achieving state-of-the-art classification accuracy on the\nN-Caltech101 and N-CARS datasets, with results of 84.3% and 99.9%,\nrespectively. Our method improves the accuracy of event camera-based object\nclassification while significantly enhancing the generalization and stability\nof event representation. Our code is available in\nhttps://github.com/chenyu0193/ACDF."}
{"id": "2509.26090", "pdf": "https://arxiv.org/pdf/2509.26090", "abs": "https://arxiv.org/abs/2509.26090", "authors": ["Alexis Berland", "Youssouf Ismail Cherifi", "Alexis Paljic", "Emmanuel Guigon"], "title": "Coexistence of two adaptation processes in a visuomotor rotation task", "categories": ["q-bio.NC"], "comment": null, "summary": "Motor adaptation is a learning process that enables humans to regain\nproficiency when sensorimotor conditions are sustainably altered. Many studies\nhave documented the properties of motor adaptation, yet the underlying\nmechanisms of motor adaptation remain imperfectly understood. In this study, we\npropose a computational analysis of adaptation to a visuomotor rotation task\nand examine it through an experiment. Our analysis suggests that two distinct\nprocesses contribute to produce adaptation: one which straightens trajectories,\nand another which redirects trajectories. We designed a visuomotor rotation\ntask in a 3D virtual environment where human participants performed a pointing\ntask using a head-mounted display controller represented by a cursor that was\nvisually rotated by an angular deviation relative to its actual position. We\nobserved that: (1) the trajectories were initially curved and misdirected, and\nbecame straighter and better directed with learning; (2) the straightening\nprocess occurred faster than the redirection process. These findings are\nconsistent with our computational analysis and disclose a new and different\nperspective on motor adaptation."}
{"id": "2509.26606", "pdf": "https://arxiv.org/pdf/2509.26606", "abs": "https://arxiv.org/abs/2509.26606", "authors": ["Andrew Jun Lee", "Daniel Turek", "Omer Daglar Tanrikulu"], "title": "Beyond Suboptimality: Resource-Rationality and Task Demands Shape the Complexity of Perceptual Representations", "categories": ["q-bio.NC"], "comment": null, "summary": "Early theories of perception as probabilistic inference propose that\nuncertainty about the interpretation of sensory input is represented as a\nprobability distribution over many interpretations -- a relatively complex\nrepresentation. However, critics argue that persistent demonstrations of\nsuboptimal perceptual decision-making indicate limits in representational\ncomplexity. We contend that suboptimality arises not from genuine limits, but\nparticipants' resource-rational adaptations to task demands. For example, when\ntasks are solvable with minimal attention to stimuli, participants may neglect\ninformation needed for complex representations, relying instead on simpler ones\nthat engender suboptimality. Across three experiments, we progressively reduced\nthe efficacy of resource-rational strategies on a carefully controlled decision\ntask. Model fits favored simple representations when resource-rational\nstrategies were effective, and favored complex representations when\nineffective, suggesting that perceptual representations can be simple or\ncomplex depending on task demands. We conclude that resource-rationality is an\nepistemic constraint for experimental design and essential to a complete theory\nof perception."}
{"id": "2509.26560", "pdf": "https://arxiv.org/pdf/2509.26560", "abs": "https://arxiv.org/abs/2509.26560", "authors": ["Chanwoo Chun", "Abdulkadir Canatar", "SueYeon Chung", "Daniel Lee"], "title": "Estimating Dimensionality of Neural Representations from Finite Samples", "categories": ["stat.ML", "cs.LG", "q-bio.NC"], "comment": null, "summary": "The global dimensionality of a neural representation manifold provides rich\ninsight into the computational process underlying both artificial and\nbiological neural networks. However, all existing measures of global\ndimensionality are sensitive to the number of samples, i.e., the number of rows\nand columns of the sample matrix. We show that, in particular, the\nparticipation ratio of eigenvalues, a popular measure of global dimensionality,\nis highly biased with small sample sizes, and propose a bias-corrected\nestimator that is more accurate with finite samples and with noise. On\nsynthetic data examples, we demonstrate that our estimator can recover the true\nknown dimensionality. We apply our estimator to neural brain recordings,\nincluding calcium imaging, electrophysiological recordings, and fMRI data, and\nto the neural activations in a large language model and show our estimator is\ninvariant to the sample size. Finally, our estimators can additionally be used\nto measure the local dimensionalities of curved neural manifolds by weighting\nthe finite samples appropriately."}
