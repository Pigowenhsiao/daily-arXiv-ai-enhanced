{"id": "2601.09634", "pdf": "https://arxiv.org/pdf/2601.09634", "abs": "https://arxiv.org/abs/2601.09634", "authors": ["Patrick Fournier", "Fabrice Larribe"], "title": "Human Ancestries Simulation and Inference: a Review of Ancestral Recombination Graph Samplers", "categories": ["q-bio.PE"], "comment": null, "summary": "There is little debate about the importance of the ancestral recombination graph in population genetics. An important theoretical tool, the main obstacle to its widespread usage is the computational cost required to match the ever-increasing scale of the data being analyzed. Many of these difficulties have been overcome in the past two decades, which have consequently seen the development of increasingly sophisticated ARG simulation and inference software. Nonetheless, challenges remain, especially in the area of ancestry inference. This paper is a comprehensive review of ARG samplers that have emerged in the past three decades to meet the need for scalable and flexible ancestry simulation and inference solutions. It specifically focuses on their performance, usability, and the biological realism of the underlying algorithm, and aims primarily to provide a technical overview of the field for researchers seeking to write their own coalescent-with-recombination sampler. As a complement to this article, we have compiled links to software, source code and documentation and made them available at https://www.patrickfournier.ca/arg-samplers-review/graph."}
{"id": "2601.09320", "pdf": "https://arxiv.org/pdf/2601.09320", "abs": "https://arxiv.org/abs/2601.09320", "authors": ["William Dorrell", "Peter E. Latham"], "title": "Mapping Connectomic Structure to Function(s) in Cerebellar-like Networks using Kernel Regression", "categories": ["q-bio.NC"], "comment": "12 pages, 7 figures", "summary": "Cerebellar-like networks, in which input activity patterns are separated by projection to a much higher-dimensional space before classification, are a recurring neurobiological motif, present in the cerebellum, dentate gyrus, insect olfactory system, and electrosensory system of the electric fish. Their relatively well-understood design presents a promising test-case for probing principles of biological learning. The circuits' expansive projections have long been modelled as random, enabling effective general purpose pattern separation. However, electron-microscopy studies have discovered interesting hints of structure in both the fly mushroom body and mouse cerebellum. Recent numerical work suggested that this non-random connectivity enables the circuit to prioritise learning of some, presumably natural, tasks over others. Here, rather than numerical results, we present a robust mathematical link between the observed connectivity patterns and the cerebellar circuit's learning ability. In particular, we extend a simplified kernel regression model of the system and use recent machine learning theory results to relate connectivity to learning. We find that the reported structure in the projection weights shapes the network's inductive bias in intuitive ways: functions are easier to learn if they depend on inputs that are oversampled, or on collections of neurons that tend to connect to the same hidden layer neurons. Our approach is analytically tractable and pleasingly simple, and we hope it continues to serve as a model for understanding the functional implications of other processing motifs in cerebellar-like networks."}
{"id": "2601.09011", "pdf": "https://arxiv.org/pdf/2601.09011", "abs": "https://arxiv.org/abs/2601.09011", "authors": ["Steven A. Frank"], "title": "Fisher's fundamental theorem and regression in causal analysis", "categories": ["stat.ME", "q-bio.PE"], "comment": null, "summary": "Fisher's fundamental theorem describes the change caused by natural selection as the change in gene frequencies multiplied by the partial regression coefficients for the average effects of genes on fitness. Fisher's result has generated extensive controversy in biology. I show that the theorem is a simple example of a general partition for change in regression predictions across altered contexts. By that rule, the total change in a mean response is the sum of two terms. The first ascribes change to the difference in predictor variables, holding constant the regression coefficients. The second ascribes change to altered context, captured by shifts in the regression coefficients. This general result follows immediately from the product rule for finite differences applied to a regression equation. Economics widely applies this same partition, the Oaxaca-Blinder decomposition, as a fundamental tool that can in proper situations be used for causal analysis. Recognizing the underlying mathematical generality clarifies Fisher's theorem, provides a useful tool for causal analysis, and reveals connections across disciplines."}
{"id": "2601.08855", "pdf": "https://arxiv.org/pdf/2601.08855", "abs": "https://arxiv.org/abs/2601.08855", "authors": ["Enso O. Torres Alegre"], "title": "Evolutionary tuning of TAM receptor-ligand interfaces highlights electrostatic features associated with regenerative phagocytic signaling", "categories": ["physics.bio-ph", "q-bio.NC"], "comment": "25 pages, 5 figures, 4 suplemetary tables", "summary": "Efficient resolution of neuroinflammation and debris clearance is a key determinant of successful central nervous system regeneration. Regenerative vertebrates such as Danio rerio often exhibit faster immune resolution and debris clearance than mammals, yet the molecular determinants underlying these differences remain incompletely understood. TAM receptor tyrosine kinases (Tyro3, Axl, and Mertk) and their ligands Gas6 and Protein S are central regulators of phagocytosis and immune resolution in the nervous system, but whether intrinsic structural properties of these receptor-ligand complexes contribute to regenerative efficiency has not been systematically explored.\n  Here, we present a comparative in silico analysis of TAM receptors and ligands from zebrafish, human, and mouse, integrating sequence evolution, high-confidence structural modeling, interface characterization, and electrostatic analysis. Despite substantial sequence divergence, ligand-binding domains display strong structural conservation, supporting a conserved global mode of TAM-ligand engagement. At the interface level, zebrafish complexes show enhanced electrostatic contributions and increased salt-bridge density, particularly in the Tyro3-Protein S interaction. Residue-level electrostatic analysis reveals clustered interface hotspots that are spatially conserved across species despite evolutionary rewiring of individual contacts.\n  Together, these results suggest that TAM receptor-ligand interfaces are evolutionarily tuned through subtle electrostatic and geometric optimization rather than large-scale structural changes, providing a conserved yet adaptable framework for species-specific modulation of phagocytic signaling."}
{"id": "2601.09537", "pdf": "https://arxiv.org/pdf/2601.09537", "abs": "https://arxiv.org/abs/2601.09537", "authors": ["Bjarki Eldon"], "title": "Gene genealogies in haploid populations evolving according to sweepstakes reproduction", "categories": ["math.PR", "q-bio.PE"], "comment": "52 pages, 9 figures", "summary": "Sweepstakes reproduction may be generated by chance matching of reproduction with favorable environmental conditions. Gene genealogies generated by sweepstakes reproduction are in the domain of attraction of multiple-merger coalescents where a random number of lineages merges at such times. We consider population genetic models of sweepstakes reproduction for haploid panmictic populations of both constant ($N$), and varying population size, and evolving in a random environment. We construct our models so that we can recover the observed number of new mutations in a given sample without requiring strong assumptions regarding the population size or the mutation rate. Our main results are {\\it (i)} continuous-time coalescents that are either the Kingman coalescent or specific families of Beta- or Poisson-Dirichlet coalescents; when combining the results the parameter $α$ of the Beta-coalescent ranges from 0 to 2, and the Beta-coalescents may be incomplete due to an upper bound on the number of potential offspring an arbitrary individual may produce; {\\it (ii)} in large populations we measure time in units proportional to either $ N/\\log N$ or $N$ generations; {\\it (iii)} incorporating fluctuations in population size leads to time-changed multiple-merger coalescents where the time-change does not depend on $α$; {\\it (iv)} using simulations we show that in some cases approximations of functionals of a given coalescent do not match the ones of the ancestral process in the domain of attraction of the given coalescent; {\\it (v)} approximations of functionals obtained by conditioning on the population ancestry (the ancestral relations of all gene copies at all times) are broadly similar (for the models considered here) to the approximations obtained without conditioning on the population ancestry."}
{"id": "2601.08963", "pdf": "https://arxiv.org/pdf/2601.08963", "abs": "https://arxiv.org/abs/2601.08963", "authors": ["Adrita Das", "Peiran Jiang", "Dantong Zhu", "Barnabas Poczos", "Jose Lugo-Martinez"], "title": "Breaking the Bottlenecks: Scalable Diffusion Models for 3D Molecular Generation", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Diffusion models have emerged as a powerful class of generative models for molecular design, capable of capturing complex structural distributions and achieving high fidelity in 3D molecule generation. However, their widespread use remains constrained by long sampling trajectories, stochastic variance in the reverse process, and limited structural awareness in denoising dynamics. The Directly Denoising Diffusion Model (DDDM) mitigates these inefficiencies by replacing stochastic reverse MCMC updates with deterministic denoising step, substantially reducing inference time. Yet, the theoretical underpinnings of such deterministic updates have remained opaque. In this work, we provide a principled reinterpretation of DDDM through the lens of the Reverse Transition Kernel (RTK) framework by Huang et al. 2024, unifying deterministic and stochastic diffusion under a shared probabilistic formalism. By expressing the DDDM reverse process as an approximate kernel operator, we show that the direct denoising process implicitly optimizes a structured transport map between noisy and clean samples. This perspective elucidates why deterministic denoising achieves efficient inference. Beyond theoretical clarity, this reframing resolves several long-standing bottlenecks in molecular diffusion. The RTK view ensures numerical stability by enforcing well-conditioned reverse kernels, improves sample consistency by eliminating stochastic variance, and enables scalable and symmetry-preserving denoisers that respect SE(3) equivariance. Empirically, we demonstrate that RTK-guided deterministic denoising achieves faster convergence and higher structural fidelity than stochastic diffusion models, while preserving chemical validity across GEOM-DRUGS dataset. Code, models, and datasets are publicly available in our project repository."}
{"id": "2601.08996", "pdf": "https://arxiv.org/pdf/2601.08996", "abs": "https://arxiv.org/abs/2601.08996", "authors": ["Andrea Toloba", "Klaus Langohr", "Guadalupe Gómez Melis"], "title": "Semiparametric estimation of GLMs with interval-censored covariates via an augmented Turnbull estimator", "categories": ["stat.ME", "q-bio.QM"], "comment": null, "summary": "Interval-censored covariates are frequently encountered in biomedical studies, particularly in time-to-event data or when measurements are subject to detection or quantification limits. Yet, the estimation of regression models with interval-censored covariates remains methodologically underdeveloped. In this article, we address the estimation of generalized linear models when one covariate is subject to interval censoring. We propose a likelihood-based approach, GELc, that builds upon an augmented version of Turnbull's nonparametric estimator for interval-censored data. We prove that the GELc estimator is consistent and asymptotically normal under mild regularity conditions, with available standard errors. Simulation studies demonstrate favorable finite-sample performance of the estimator and satisfactory coverage of the confidence intervals. Finally, we illustrate the method using two real-world applications: the AIDS Clinical Trials Group Study 359 and an observational nutrition study on circulating carotenoids. The proposed methodology is available as an R package at github.com/atoloba/ICenCov."}
{"id": "2601.08932", "pdf": "https://arxiv.org/pdf/2601.08932", "abs": "https://arxiv.org/abs/2601.08932", "authors": ["Karoline-Marie Bornemann", "Perry S. Choi", "Jay Huber", "Alexander K. Reed", "Amit Sharir", "Shiraz A. Maskatia", "Alison L. Marsden", "Michael R. Ma", "Alexander D. Kaiser"], "title": "Simulations Predict Improved Valve Performance Without Direct Leaflet Intervention After Neonatal Truncus Arteriosus Repair", "categories": ["q-bio.TO"], "comment": null, "summary": "Truncus arteriosus (TA) is a rare and severe congenital heart disease. Quadricuspid valve morphology occurs in 25% of all TA patients and is linked to regurgitation and increased risk of re-operation. It remains unclear how hemodynamic changes after TA repair alter valve performance. This study simulated pre- and postoperative conditions in a neonatal TA patient to investigate valve performance without direct intervention. We hypothesize that valve performance before and after truncal repair can be predicted in-silico, matching in-vivo imaging and identifying mechanisms how hemodynamic changes after repair will reduce valve regurgitation without direct intervention. Pre- and postoperative CT images of a neonatal patient with quadricuspid valve were segmented. Free edge length and geometric height from the patient's echocardiogram were used to model the valve. For the preoperative condition, ventricular pressures were set equal modeling an unrestricted ventricular septal defect. Systemic and pulmonary resistances were tuned based on the patient's Qp:Qs ratio. For the postoperative condition, boundary conditions were modified to mimic patient-specific hemodynamics after TA repair. The preoperative simulation confirmed mild valve regurgitation seen in-vivo. Interaction between asymmetric flow and surrounding vessel resulted in asymmetric opening and closing. Poor central coaptation led to a central regurgitant jet toward the septum. Altered postoperative hemodynamics improved coaptation and eliminated regurgitation, as seen in-vivo. This modeling approach reproduced in-vivo pre- and postoperative valve performance and identified mechanisms improving coaptation after TA repair. TA repair led to elimination of regurgitation due to enhanced central coaptation. Thus, altered postoperative hemodynamic conditions after TA repair may improve valve performance without direct leaflet intervention."}
{"id": "2601.09173", "pdf": "https://arxiv.org/pdf/2601.09173", "abs": "https://arxiv.org/abs/2601.09173", "authors": ["Prashant C. Raju"], "title": "Geometric Stability: The Missing Axis of Representations", "categories": ["cs.LG", "cs.CL", "q-bio.QM", "stat.ML"], "comment": null, "summary": "Analysis of learned representations has a blind spot: it focuses on $similarity$, measuring how closely embeddings align with external references, but similarity reveals only what is represented, not whether that structure is robust. We introduce $geometric$ $stability$, a distinct dimension that quantifies how reliably representational geometry holds under perturbation, and present $Shesha$, a framework for measuring it. Across 2,463 configurations in seven domains, we show that stability and similarity are empirically uncorrelated ($ρ\\approx 0.01$) and mechanistically distinct: similarity metrics collapse after removing the top principal components, while stability retains sensitivity to fine-grained manifold structure. This distinction yields actionable insights: for safety monitoring, stability acts as a functional geometric canary, detecting structural drift nearly 2$\\times$ more sensitively than CKA while filtering out the non-functional noise that triggers false alarms in rigid distance metrics; for controllability, supervised stability predicts linear steerability ($ρ= 0.89$-$0.96$); for model selection, stability dissociates from transferability, revealing a geometric tax that transfer optimization incurs. Beyond machine learning, stability predicts CRISPR perturbation coherence and neural-behavioral coupling. By quantifying $how$ $reliably$ systems maintain structure, geometric stability provides a necessary complement to similarity for auditing representations across biological and computational systems."}
{"id": "2601.09660", "pdf": "https://arxiv.org/pdf/2601.09660", "abs": "https://arxiv.org/abs/2601.09660", "authors": ["Carla Nathaly Villacís Núñez", "Siddhartha Srivastava", "Ulrich Scheven", "Asheesh Bedi", "Krishna Garikipati", "Ellen M. Arruda"], "title": "Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons", "categories": ["physics.bio-ph", "q-bio.TO"], "comment": null, "summary": "In this work, we characterized the material properties of an animal model of the rotator cuff tendon using full volume datasets of both its intact and injured states by capturing internal strain behavior throughout the tendon. Our experimental setup, involving tension along the fiber direction, activated volumetric, tensile, and shear mechanisms due to the tendon's complex geometry. We implemented an approach to model inference that we refer to as variational system identification (VSI) to solve the weak form of the stress equilibrium equation using these full volume displacements. Three constitutive models were used for parameter inference: a neo-Hookean model, a modified Holzapfel-Gasser-Ogden (HGO) model with higher-order terms in the first and second invariants, and a reduced polynomial model consisting of terms based on the first, second, and fiber-related invariants. Inferred parameters were further refined using an adjoint-based partial differential equation (PDE)-constrained optimization framework. Our results show that the modified HGO model captures the tendon's deformation mechanisms with reasonable accuracy, while the neo-Hookean model fails to reproduce key internal features, particularly the shear behavior in the injured tendon. Surprisingly, the simplified polynomial model performed comparably to the modified HGO formulation using only three terms. These findings suggest that while current constitutive models do not fully replicate the complex internal mechanics of the tendon, they are capable of capturing key trends in both intact and damaged tissue, using a homogeneous modeling approach. Continued model development is needed to bridge this gap and enable clinical-grade, predictive simulations of tendon injury and repair."}
