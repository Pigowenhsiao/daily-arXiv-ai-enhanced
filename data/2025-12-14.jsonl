{"id": "2512.10115", "pdf": "https://arxiv.org/pdf/2512.10115", "abs": "https://arxiv.org/abs/2512.10115", "authors": ["Jorge Vila"], "title": "Decoding How Proteins Fold", "categories": ["q-bio.BM"], "comment": "18 pages, 3 figures", "summary": "The primary aims of this perspective are twofold. Firstly, to assess whether a universal principle could govern the process of protein folding. Secondly, to clarify whether the folding of a protein could be characterized by an effective trajectory, as determined by the principle of least action, while concurrently addressing the Levinthal Paradox. The effective-trajectory conjecture, which is compatible with the existence of multiple folding pathways and characterized by a single folding rate, addresses the search timescale paradox by explaining how a protein in a proper environment always reaches its native state at a consistent folding rate and in a biologically reasonable time frame (as determined by the thermodynamic hypothesis, or Anfinsen dogma). The preliminary findings support the hypothesis that the protein folding process is governed by a universal principle: that of least action. From this viewpoint, it should be regarded as a fundamental physical model that not only facilitates the identification of folding pathways and trajectories but also offers a physical framework for understanding how nature may link the optimal kinetic speed of the protein folding process with its higher thermodynamic stability."}
{"id": "2512.10515", "pdf": "https://arxiv.org/pdf/2512.10515", "abs": "https://arxiv.org/abs/2512.10515", "authors": ["Han Tang", "Wouter Boomsma"], "title": "UNAAGI: Atom-Level Diffusion for Generating Non-Canonical Amino Acid Substitutions", "categories": ["q-bio.BM"], "comment": null, "summary": "Proposing beneficial amino acid substitutions, whether for mutational effect prediction or protein engineering, remains a central challenge in structural biology. Recent inverse folding models, trained to reconstruct sequences from structure, have had considerable impact in identifying functional mutations. However, current approaches are constrained to designing sequences composed exclusively of natural amino acids (NAAs). The larger set of non-canonical amino acids (NCAAs), which offer greater chemical diversity, and are frequently used in in-vivo protein engineering, remain largely inaccessible for current variant effect prediction methods.\n  To address this gap, we introduce \\textbf{UNAAGI}, a diffusion-based generative model that reconstructs residue identities from atomic-level structure using an E(3)-equivariant framework. By modeling side chains in full atomic detail rather than as discrete tokens, UNAAGI enables the exploration of both canonical and non-canonical amino acid substitutions within a unified generative paradigm. We evaluate our method on experimentally benchmarked mutation effect datasets and demonstrate that it achieves substantially improved performance on NCAA substitutions compared to the current state-of-the-art. Furthermore, our results suggest a shared methodological foundation between protein engineering and structure-based drug design, opening the door for a unified training framework across these domains."}
{"id": "2512.10309", "pdf": "https://arxiv.org/pdf/2512.10309", "abs": "https://arxiv.org/abs/2512.10309", "authors": ["Jiayu Weng", "Xinyi Zhu", "Jing Liu", "Linyuan Lü", "Pan Zhang", "Ying Tang"], "title": "Tracking large chemical reaction networks and rare events by neural networks", "categories": ["q-bio.MN", "cs.LG", "physics.bio-ph"], "comment": null, "summary": "Chemical reaction networks are widely used to model stochastic dynamics in chemical kinetics, systems biology and epidemiology. Solving the chemical master equation that governs these systems poses a significant challenge due to the large state space exponentially growing with system sizes. The development of autoregressive neural networks offers a flexible framework for this problem; however, its efficiency is limited especially for high-dimensional systems and in scenarios with rare events. Here, we push the frontier of neural-network approach by exploiting faster optimizations such as natural gradient descent and time-dependent variational principle, achieving a 5- to 22-fold speedup, and by leveraging enhanced-sampling strategies to capture rare events. We demonstrate reduced computational cost and higher accuracy over the previous neural-network method in challenging reaction networks, including the mitogen-activated protein kinase (MAPK) cascade network, the hitherto largest biological network handled by the previous approaches of solving the chemical master equation. We further apply the approach to spatially extended reaction-diffusion systems, the Schlögl model with rare events, on two-dimensional lattices, beyond the recent tensor-network approach that handles one-dimensional lattices. The present approach thus enables efficient modeling of chemical reaction networks in general."}
{"id": "2512.09964", "pdf": "https://arxiv.org/pdf/2512.09964", "abs": "https://arxiv.org/abs/2512.09964", "authors": ["Donghyeon Lee", "Dongseok Kim", "Seokhwan Ko", "Seo-Young Park", "Junghwan Cho"], "title": "Development of an Agentic AI Model for NGS Downstream Analysis Targeting Researchers with Limited Biological Background", "categories": ["q-bio.GN"], "comment": null, "summary": "Next-Generation Sequencing (NGS) has become a cornerstone of genomic research, yet the complexity of downstream analysis-ranging from differential expression gene (DEG) identification to biological interpretations-remains a significant barrier for researchers lacking specialized computational and biological expertise. While recent studies have introduced AI agents for RNA-seq analysis, most focus on general workflows without offering tailored interpretations or guidance for novices. To address this gap, we developed an Agentic AI model designed to automate NGS downstream analysis, provide literature-backed interpretations, and autonomously recommend advanced analytical methods. Built on the Llama 3 70B Large Language Model (LLM) and a Retrieval-Augmented Generation (RAG) framework, the model is deployed as an interactive Streamlit web application. The system integrates standard bioinformatics tools (Biopython, GSEApy, gProfiler) to execute core analyses, including DEG identification, clustering, and pathway enrichment. Uniquely, the agent utilizes RAG to query PubMed via Entrez, synthesizing biological insights and validating hypotheses with current literature. In a case study using cancer-related dataset, the model successfully identified significant DEGs, visualized clinical correlations, and derived evidence-based insights (e.g., linking BRAF mutations to prognosis), subsequently executing advanced survival modeling upon user selection. This framework democratizes bioinformatics by enabling researchers with limited backgrounds to seamlessly transition from basic data processing to advanced hypothesis testing and validation."}
{"id": "2512.10898", "pdf": "https://arxiv.org/pdf/2512.10898", "abs": "https://arxiv.org/abs/2512.10898", "authors": ["Elena Braverman", "Jenny Lawson"], "title": "Trimming to coexistence: How dispersal strategies should be accounted for in resource management", "categories": ["q-bio.PE"], "comment": "6 figures", "summary": "For two resource-sharing species we explore the interplay of harvesting and dispersal strategies, as well as their influence on competition outcomes. Although the extinction of either species can be achieved by excessive culling, choosing a harvesting strategy such that the biodiversity of the populations is preserved is much more complicated. We propose a type of heterogeneous harvesting policy, dependent on dispersal strategy, where the two managed populations become an ideal free pair, and show that this strategy guarantees the coexistence of the species. We also show that if the harvesting of one of the populations is perturbed in some way, then it is possible for the coexistence to be preserved. Further, we show that if the dispersal of two species formed an ideal free pair, then a slight change in the dispersal strategy for one of them does not affect their ability to coexist. Finally, in the model, directed movement is represented by the term $Δ(u/P)$, where $P$ is the dispersal strategy and target distribution. We justify that once an invading species, which has an advantage in carrying capacity, chooses a dispersal strategy that mimics the resident species distribution, then successful invasion is guaranteed. However, numerical simulations show that invasion may be successful even without an advantage in carrying capacity. More work is needed to understand the conditions, in addition to targeted culling, under which the host species would be able to persist through an invasion."}
{"id": "2512.10525", "pdf": "https://arxiv.org/pdf/2512.10525", "abs": "https://arxiv.org/abs/2512.10525", "authors": ["Robert Worden"], "title": "Parallel Neuron Groups in the Drosophila Brain", "categories": ["q-bio.NC"], "comment": "18 pages, 14 figures. Supplementary data is in the file groups.csv", "summary": "The full connectome of an adult Drosophila enables a search for novel neural structures in the insect brain. I describe a new neural structure, called a Parallel Neuron Group (PNG). Two neurons are called parallel if they share a significant number of input neurons and output neurons. Most pairs of neurons in the Drosophila brain have very small parallel match. There are about twenty larger groups of neurons for which any pair of neurons in the group has a high match. These are the parallel groups. Parallel groups contain only about 1000 out of the 65,000 neurons in the brain, and have distinctive properties. There are groups in the right mushroom bodies, the antennal lobes, the lobula, and in two central neuropils (GNG and EB). Most parallel groups do not have lateral symmetry. A group usually has one major input neuron, which inputs to all the neurons in the group, and a small number of major output neurons. The major input and output neurons are laterally asymmetric. Parallel neuron groups present puzzles, such as: what does a group do, that could not be done by one larger neuron? Do all neurons in a group fire in synchrony, or do they perform different functions? Why are they laterally asymmetric? These may merit further investigation."}
{"id": "2512.10588", "pdf": "https://arxiv.org/pdf/2512.10588", "abs": "https://arxiv.org/abs/2512.10588", "authors": ["John F. Allen"], "title": "Why a chloroplast needs its own genome tethered to the thylakoid membrane -- Co-location for Redox Regulation", "categories": ["q-bio.MN"], "comment": "15 pages, 1 figure", "summary": "A chloroplast is a subcellular organelle of photosynthesis in plant and algal cells. A chloroplast genome encodes proteins of the photosynthetic electron transport chain and ribosomal proteins required to express them. Chloroplast-encoded photosynthetic proteins are mostly intrinsic to the chloroplast thylakoid membrane where they drive vectorial electron and proton transport. There they function in close contact with proteins whose precursors are encoded in the cell nucleus for cytosolic synthesis, subsequent processing, and import into the chloroplast. The protein complexes of photosynthetic electron transport thus contain subunits with one of two quite different sites of synthesis. If most chloroplast proteins result from expression of nuclear genes then why not all? What selective pressure accounts for the persistence of the chloroplast genome? One proposal is that photosynthetic electron transport itself governs expression of genes for its own components: co-location of chloroplast genes with their gene products allows redox regulation of gene expression, thereby resulting in self-adjustment of protein stoichiometry in response to environmental change. This hypothesis posits Co-Location for Redox Regulation, termed CoRR, as the primary reason for the retention of genomes in both photosynthetic chloroplasts and respiring mitochondria. I propose that redox regulation affects all stages of chloroplast gene expression and that this integrated control is mediated by a chloroplast mesosome or nucleoid - a structure that tethers chloroplast DNA to the thylakoid."}
{"id": "2512.10147", "pdf": "https://arxiv.org/pdf/2512.10147", "abs": "https://arxiv.org/abs/2512.10147", "authors": ["Sarwan Ali", "Taslim Murad"], "title": "Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today's multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4\\% classification accuracy while reducing embedding generation time by as much as 99.81\\%. This highlights the method's potential as a fast, effective, and scalable solution for large-scale viral sequence analysis."}
{"id": "2512.10834", "pdf": "https://arxiv.org/pdf/2512.10834", "abs": "https://arxiv.org/abs/2512.10834", "authors": ["Tiago S. A. N. Simões", "José S. Andrade", "Hans J. Herrmann", "Stefano Zapperi", "Lucilla de Arcangelis"], "title": "Allometric scaling of brain activity explained by avalanche criticality", "categories": ["q-bio.NC"], "comment": null, "summary": "Allometric scaling laws, such as Kleiber's law for metabolic rate, highlight how efficiency emerges with size across living systems. The brain, with its characteristic sublinear scaling of activity, has long posed a puzzle: why do larger brains operate with disproportionately lower firing rates? Here we show that this economy of scale is a universal outcome of avalanche dynamics. We derive analytical scaling laws directly from avalanche statistics, establishing that any system governed by critical avalanches must exhibit sublinear activity-size relations. This theoretical prediction is then verified in integrate-and-fire neuronal networks at criticality and in classical self-organized criticality models, demonstrating that the effect is not model-specific but generic. The predicted exponents align with experimental observations across mammal species, bridging dynamical criticality with the allometry of brain metabolism. Our results reveal avalanche criticality as a fundamental mechanism underlying Kleiber-like scaling in the brain."}
{"id": "2512.10708", "pdf": "https://arxiv.org/pdf/2512.10708", "abs": "https://arxiv.org/abs/2512.10708", "authors": ["Marcel Friedrichs", "Daniel Merkle"], "title": "Saturation-Based Atom Provenance Tracing in Chemical Reaction Networks", "categories": ["q-bio.MN", "cs.DM"], "comment": null, "summary": "Atom tracing is essential for understanding the fate of labeled atoms in biochemical reaction networks, yet existing computational methods either simplify label correlations or suffer from combinatorial explosion. We introduce a saturation-based framework for enumerating labeling patterns that directly operates on atom-atom maps without requiring flux data or experimental measurements. The approach models reaction semantics using Kleisli morphisms in the powerset monad, allowing for compositional propagation of atom provenance through reaction networks. By iteratively saturating all possible educt combinations of reaction rules, the method exhaustively enumerates labeled molecular configurations, including multiplicities and reuse. Allowing arbitrary initial labeling patterns - including identical or distinct labels - the method expands only isotopomers reachable from these inputs, keeping the configuration space as small as necessary and avoids the full combinatorial growth characteristic of previous approaches. In principle, even every atom could carry a distinct identifier (e.g., tracing all carbon atoms individually), illustrating the generality of the framework beyond practical experimental limitations. The resulting template instance hypergraph captures the complete flow of atoms between compounds and supports projections tailored to experimental targets. Customizable labeling sets significantly reduce generated network sizes, providing efficient and exact atom traces focused on specific compounds or available isotopes. Applications to the tricarboxylic acid cycle, and glycolytic pathways demonstrate that the method fully automatically reproduces known labeling patterns and discovers steady-state labeling behavior. The framework offers a scalable, mechanistically transparent, and generalizable foundation for isotopomer modeling and experiment design."}
{"id": "2512.10844", "pdf": "https://arxiv.org/pdf/2512.10844", "abs": "https://arxiv.org/abs/2512.10844", "authors": ["C. Sun", "D. Fettahoglu", "D. Holcman"], "title": "Modeling, Segmenting and Statistics of Transient Spindles via Two-Dimensional Ornstein-Uhlenbeck Dynamics", "categories": ["q-bio.NC", "math.SP"], "comment": "6 figs", "summary": "We develop here a stochastic framework for modeling and segmenting transient spindle-like oscillatory bursts in electroencephalogram (EEG) signals. At the modeling level, individual spindles are represented as path realizations of a two-dimensional Ornstein{Uhlenbeck (OU) process with a stable focus, providing a low-dimensional stochastic dynamical system whose trajectories reproduce key morphological features of spindles, including their characteristic rise{decay amplitude envelopes. On the signal processing side, we propose a segmentation procedure based on Empirical Mode Decomposition (EMD) combined with the detection of a central extremum, which isolates single spindle events and yields a collection of oscillatory atoms. This construction enables a systematic statistical analysis of spindle features: we derive empirical laws for the distributions of amplitudes, inter-spindle intervals, and rise/decay durations, and show that these exhibit exponential tails consistent with the underlying OU dynamics. We further extend the model to a pair of weakly coupled OU processes with distinct natural frequencies, generating a stochastic mixture of slow, fast, and mixed spindles in random temporal order. The resulting framework provides a data-driven framework for the analysis of transient oscillations in EEG and, more generally, in nonstationary time series."}
{"id": "2512.10011", "pdf": "https://arxiv.org/pdf/2512.10011", "abs": "https://arxiv.org/abs/2512.10011", "authors": ["Lennart P. L. Landsmeer", "Amirreza Movahedin", "Mario Negrello", "Said Hamdioui", "Christos Strydis"], "title": "Spatial Spiking Neural Networks Enable Efficient and Robust Temporal Computation", "categories": ["cs.NE", "q-bio.NC"], "comment": null, "summary": "The efficiency of modern machine intelligence depends on high accuracy with minimal computational cost. In spiking neural networks (SNNs), synaptic delays are crucial for encoding temporal structure, yet existing models treat them as fully trainable, unconstrained parameters, leading to large memory footprints, higher computational demand, and a departure from biological plausibility. In the brain, however, delays arise from physical distances between neurons embedded in space. Building on this principle, we introduce Spatial Spiking Neural Networks (SpSNNs), a framework in which neurons learn coordinates in a finite-dimensional Euclidean space and delays emerge from inter-neuron distances. This replaces per-synapse delay learning with position learning, substantially reducing parameter count while retaining temporal expressiveness. Across the Yin-Yang and Spiking Heidelberg Digits benchmarks, SpSNNs outperform SNNs with unconstrained delays despite using far fewer parameters. Performance consistently peaks in 2D and 3D networks rather than infinite-dimensional delay spaces, revealing a geometric regularization effect. Moreover, dynamically sparsified SpSNNs maintain full accuracy even at 90% sparsity, matching standard delay-trained SNNs while using up to 18x fewer parameters. Because learned spatial layouts map naturally onto hardware geometries, SpSNNs lend themselves to efficient neuromorphic implementation. Methodologically, SpSNNs compute exact delay gradients via automatic differentiation with custom-derived rules, supporting arbitrary neuron models and architectures. Altogether, SpSNNs provide a principled platform for exploring spatial structure in temporal computation and offer a hardware-friendly substrate for scalable, energy-efficient neuromorphic intelligence."}
