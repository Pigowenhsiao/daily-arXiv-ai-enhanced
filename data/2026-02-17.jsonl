{"id": "2602.13249", "pdf": "https://arxiv.org/pdf/2602.13249", "abs": "https://arxiv.org/abs/2602.13249", "authors": ["Hyosoon Jang", "Hyunjin Seo", "Yunhui Jang", "Seonghyun Park", "Sungsoo Ahn"], "title": "Boltz is a Strong Baseline for Atom-level Representation Learning", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "comment": null, "summary": "Foundation models in molecular learning have advanced along two parallel tracks: protein models, which typically utilize evolutionary information to learn amino acid-level representations for folding, and small-molecule models, which focus on learning atom-level representations for property prediction tasks such as ADMET. Notably, cutting-edge protein-centric models such as Boltz now operate at atom-level granularity for protein-ligand co-folding, yet their atom-level expressiveness for small-molecule tasks remains unexplored. A key open question is whether these protein co-folding models capture transferable chemical physics or rely on protein evolutionary signals, which would limit their utility for small-molecule tasks. In this work, we investigate the quality of Boltz atom-level representations across diverse small-molecule benchmarks. Our results show that Boltz is competitive with specialized baselines on ADMET property prediction tasks and effective for molecular generation and optimization. These findings suggest that the representational capacity of cutting-edge protein-centric models has been underexplored and position Boltz as a strong baseline for atom-level representation learning for small molecules."}
{"id": "2602.13503", "pdf": "https://arxiv.org/pdf/2602.13503", "abs": "https://arxiv.org/abs/2602.13503", "authors": ["Maxwell Kleinsasser", "Brayden J. Halverson", "Edward Kraft", "Sean Francis-Lyon", "Sarah E. Hugo", "Mackenzie R. Roman", "Ben Miller", "Andrew D. Blevins", "Ian K. Quigley"], "title": "Hermes: Large DEL Datasets Train Generalizable Protein-Ligand Binding Prediction Models", "categories": ["q-bio.BM"], "comment": null, "summary": "The quality and consistency of training data remain critical bottlenecks for protein-ligand binding prediction. Public affinity datasets, aggregated from thousands of labs and assay formats, introduce biases that limit model generalization and complicate evaluation. DNA-encoded chemical libraries (DELs) offer a potential solution: unified experimental protocols generating massive binding datasets across diverse chemical and protein target space. We present Hermes, a lightweight transformer trained exclusively on DEL data from screens against hundreds of protein targets, representing one of the largest and most protein-diverse DEL training sets applied to protein-ligand interaction (PLI) modeling to date. Despite never seeing traditional affinity measurements during training, Hermes generalizes to held-out targets, novel chemical scaffolds, and external benchmarks derived from public binding data and high-throughput screens. Our results demonstrate that DEL data alone captures transferable protein-ligand interaction representations, while Hermes' minimal architecture enables inference speeds suitable for large-scale virtual screening."}
{"id": "2602.14005", "pdf": "https://arxiv.org/pdf/2602.14005", "abs": "https://arxiv.org/abs/2602.14005", "authors": ["Jiayi Wang", "Jules Nde", "Andrei G. Gasic", "Jacob Haseley", "Margaret S. Cheung"], "title": "Physical principles of building protein megacomplexes in a crowded milieu", "categories": ["q-bio.BM"], "comment": null, "summary": "Multiple phenotypic protein expressions arising from one genome represent variations in the protein relative abundance and their stoichiometry. A lack of definite compositional parts challenges the modeling of protein megacomplexes and cellular architectures. Despite the advances in protein structural predictions with AI, the mechanism of protein interactions and the emergence of megacomplexes they assemble remains unclear. Here, we present a statistical physics framework of grand canonical ensemble to explore the protein interactions that drive the emergent assembly of a megacomplex using the observational mass spectrometry datasets including protein relative abundance and the cross linked connections. Using chromatin remodeler megacomplex, INO80, as an example, we discovered a class of divergent protein that plays a critical role in orchestrating the assembly beyond nearest neighbors, dependent on the excluded volumes exerted by others. With the constraints of the excluded volumes by varying crowding contents, these divergent subunits orchestrate and form clusters with selective components growing into configurationally distinct architectures. We propose a machinery view for the INO80 chromatin remodeler complex where each loosely associated subunits can be occasionally recruited for parts as attachment into a core assembly driven by excluded volumes. Our computational framework provides a mechanistic insight into taking the macromolecular crowding as necessary physicochemical variables representing cell states to remodel the configurations of protein megacomplexes with structurally loose modules."}
{"id": "2602.14328", "pdf": "https://arxiv.org/pdf/2602.14328", "abs": "https://arxiv.org/abs/2602.14328", "authors": ["Slavica Jonic"], "title": "Conformational landscapes in cryo-ET data based on MD simulations", "categories": ["q-bio.BM", "q-bio.QM"], "comment": null, "summary": "Cryo-electron tomography (cryo-ET) provides a unique window into molecular organization in cellular environments (in situ). However, the interpretation of molecular structural information is complicated by several intrinsic properties of cryo-ET data, such as noise, missing wedge, and continuous conformational variability of the molecules. Additionally, in crowded in situ environments, the number of particles extracted is sometimes small and precludes extensive classification into discrete states. These challenges shift the emphasis from high-resolution structure determination toward validation and interpretation of low-resolution density maps, and analysis of conformational flexibility. Molecular Dynamics (MD) simulations are particularly well suited to this task, as they provide a physically grounded way to explore continuous conformation transitions consistent with both experimental data and molecular energetics. This review focuses on the roles of MD simulations in cryo-ET, emphasizing their use in emerging methods for conformational landscape determination and their contribution to gain new biological insight."}
{"id": "2602.13346", "pdf": "https://arxiv.org/pdf/2602.13346", "abs": "https://arxiv.org/abs/2602.13346", "authors": ["Zhen Wang", "Yiming Gao", "Jieyuan Liu", "Enze Ma", "Jefferson Chen", "Mark Antkowiak", "Mengzhou Hu", "JungHo Kong", "Dexter Pratt", "Zhiting Hu", "Wei Wang", "Trey Ideker", "Eric P. Xing"], "title": "CellMaster: Collaborative Cell Type Annotation in Single-Cell Analysis", "categories": ["q-bio.GN", "cs.AI", "cs.CV"], "comment": "Preprint", "summary": "Single-cell RNA-seq (scRNA-seq) enables atlas-scale profiling of complex tissues, revealing rare lineages and transient states. Yet, assigning biologically valid cell identities remains a bottleneck because markers are tissue- and state-dependent, and novel states lack references. We present CellMaster, an AI agent that mimics expert practice for zero-shot cell-type annotation. Unlike existing automated tools, CellMaster leverages LLM-encoded knowledge (e.g., GPT-4o) to perform on-the-fly annotation with interpretable rationales, without pre-training or fixed marker databases. Across 9 datasets spanning 8 tissues, CellMaster improved accuracy by 7.1% over best-performing baselines (including CellTypist and scTab) in automatic mode. With human-in-the-loop refinement, this advantage increased to 18.6%, with a 22.1% gain on subtype populations. The system demonstrates particular strength in rare and novel cell states where baselines often fail. Source code and the web application are available at \\href{https://github.com/AnonymousGym/CellMaster}{https://github.com/AnonymousGym/CellMaster}."}
{"id": "2602.13419", "pdf": "https://arxiv.org/pdf/2602.13419", "abs": "https://arxiv.org/abs/2602.13419", "authors": ["Shreyas Vinaya Sathyanarayana", "Shah Rahil Kirankumar", "Sharanabasava D. Hiremath", "Bharath Ramsundar"], "title": "Protect$^*$: Steerable Retrosynthesis through Neuro-Symbolic State Encoding", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable potential in scientific domains like retrosynthesis; yet, they often lack the fine-grained control necessary to navigate complex problem spaces without error. A critical challenge is directing an LLM to avoid specific, chemically sensitive sites on a molecule - a task where unconstrained generation can lead to invalid or undesirable synthetic pathways. In this work, we introduce Protect$^*$, a neuro-symbolic framework that grounds the generative capabilities of Large Language Models (LLMs) in rigorous chemical logic. Our approach combines automated rule-based reasoning - using a comprehensive database of 55+ SMARTS patterns and 40+ characterized protecting groups - with the generative intuition of neural models. The system operates via a hybrid architecture: an ``automatic mode'' where symbolic logic deterministically identifies and guards reactive sites, and a ``human-in-the-loop mode'' that integrates expert strategic constraints. Through ``active state tracking,'' we inject hard symbolic constraints into the neural inference process via a dedicated protection state linked to canonical atom maps. We demonstrate this neuro-symbolic approach through case studies on complex natural products, including the discovery of a novel synthetic pathway for Erythromycin B, showing that grounding neural generation in symbolic logic enables reliable, expert-level autonomy."}
{"id": "2602.13502", "pdf": "https://arxiv.org/pdf/2602.13502", "abs": "https://arxiv.org/abs/2602.13502", "authors": ["Trevor Chan", "Ilias Tagkopoulos"], "title": "Translating Dietary Standards into Healthy Meals with Minimal Substitutions", "categories": ["cs.AI", "q-bio.OT"], "comment": "49 pages, 4 figures", "summary": "An important goal for personalized diet systems is to improve nutritional quality without compromising convenience or affordability. We present an end-to-end framework that converts dietary standards into complete meals with minimal change. Using the What We Eat in America (WWEIA) intake data for 135,491 meals, we identify 34 interpretable meal archetypes that we then use to condition a generative model and a portion predictor to meet USDA nutritional targets. In comparisons within archetypes, generated meals are better at following recommended daily intake (RDI) targets by 47.0%, while remaining compositionally close to real meals. Our results show that by allowing one to three food substitutions, we were able to create meals that were 10% more nutritious, while reducing costs 19-32%, on average. By turning dietary guidelines into realistic, budget-aware meals and simple swaps, this framework can underpin clinical decision support, public-health programs, and consumer apps that deliver scalable, equitable improvements in everyday nutrition."}
{"id": "2602.13325", "pdf": "https://arxiv.org/pdf/2602.13325", "abs": "https://arxiv.org/abs/2602.13325", "authors": ["Cédric Allier", "Larissa Heinrich", "Magdalena Schneider", "Stephan Saalfeld"], "title": "Graph neural networks uncover structure and functions underlying the activity of simulated neural assemblies", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Graph neural networks trained to predict observable dynamics can be used to decompose the temporal activity of complex heterogeneous systems into simple, interpretable representations. Here we apply this framework to simulated neural assemblies with thousands of neurons and demonstrate that it can jointly reveal the connectivity matrix, the neuron types, the signaling functions, and in some cases hidden external stimuli. In contrast to existing machine learning approaches such as recurrent neural networks and transformers, which emphasize predictive accuracy but offer limited interpretability, our method provides both reliable forecasts of neural activity and interpretable decomposition of the mechanisms governing large neural assemblies."}
{"id": "2602.13419", "pdf": "https://arxiv.org/pdf/2602.13419", "abs": "https://arxiv.org/abs/2602.13419", "authors": ["Shreyas Vinaya Sathyanarayana", "Shah Rahil Kirankumar", "Sharanabasava D. Hiremath", "Bharath Ramsundar"], "title": "Protect$^*$: Steerable Retrosynthesis through Neuro-Symbolic State Encoding", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG", "q-bio.BM"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable potential in scientific domains like retrosynthesis; yet, they often lack the fine-grained control necessary to navigate complex problem spaces without error. A critical challenge is directing an LLM to avoid specific, chemically sensitive sites on a molecule - a task where unconstrained generation can lead to invalid or undesirable synthetic pathways. In this work, we introduce Protect$^*$, a neuro-symbolic framework that grounds the generative capabilities of Large Language Models (LLMs) in rigorous chemical logic. Our approach combines automated rule-based reasoning - using a comprehensive database of 55+ SMARTS patterns and 40+ characterized protecting groups - with the generative intuition of neural models. The system operates via a hybrid architecture: an ``automatic mode'' where symbolic logic deterministically identifies and guards reactive sites, and a ``human-in-the-loop mode'' that integrates expert strategic constraints. Through ``active state tracking,'' we inject hard symbolic constraints into the neural inference process via a dedicated protection state linked to canonical atom maps. We demonstrate this neuro-symbolic approach through case studies on complex natural products, including the discovery of a novel synthetic pathway for Erythromycin B, showing that grounding neural generation in symbolic logic enables reliable, expert-level autonomy."}
{"id": "2602.14828", "pdf": "https://arxiv.org/pdf/2602.14828", "abs": "https://arxiv.org/abs/2602.14828", "authors": ["Ana F. Rodrigues", "Lucas Ferraz", "Laura Balbi", "Pedro Giesteira Cotovio", "Catia Pesquita"], "title": "Exploring the limits of pre-trained embeddings in machine-guided protein design: a case study on predicting AAV vector viability", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Effective representations of protein sequences are widely recognized as a cornerstone of machine learning-based protein design. Yet, protein bioengineering poses unique challenges for sequence representation, as experimental datasets typically feature few mutations, which are either sparsely distributed across the entire sequence or densely concentrated within localized regions. This limits the ability of sequence-level representations to extract functionally meaningful signals. In addition, comprehensive comparative studies remain scarce, despite their crucial role in clarifying which representations best encode relevant information and ultimately support superior predictive performance. In this study, we systematically evaluate multiple ProtBERT and ESM2 embedding variants as sequence representations, using the adeno-associated virus capsid as a case study and prototypical example of bioengineering, where functional optimization is targeted through highly localized sequence variation within an otherwise large protein. Our results reveal that, prior to fine-tuning, amino acid-level embeddings outperform sequence-level representations in supervised predictive tasks, whereas the latter tend to be more effective in unsupervised settings. However, optimal performance is only achieved when embeddings are fine-tuned with task-specific labels, with sequence-level representations providing the best performance. Moreover, our findings indicate that the extent of sequence variation required to produce notable shifts in sequence representations exceeds what is typically explored in bioengineering studies, showing the need for fine-tuning in datasets characterized by sparse or highly localized mutations."}
{"id": "2602.13368", "pdf": "https://arxiv.org/pdf/2602.13368", "abs": "https://arxiv.org/abs/2602.13368", "authors": ["Benjamin Knopp", "Theresa Tennstedt", "Dominik Endres"], "title": "The Influence of Width Ratios on Structural Beauty in Male Faces", "categories": ["q-bio.NC"], "comment": null, "summary": "This study investigates the relationship between interocular distance relative to overall facial width (width ratio) and perceived subjective beauty in male faces. Building on the methodology of Pallett et al. (2010), who found that average proportions in female faces were rated as most attractive, the current study aimed to test this hypothesis in male faces. Faces from the Chicago Face Database (Ma et al., 2015) were morphed into average faces within three groups (with low, medium, and high width ratios), each composed of 96 or 97 individual images. These three average faces were then systematically manipulated in their width ratios across three levels in both directions, respectively, resulting in a total of 21 comparable faces. The use of multiple base faces served as a control for potential artifacts of image processing. Consequently, comparisons were restricted to within-group pairs to avoid confounding by co-varying facial features (e.g., skin tone), which precluded direct cross-condition comparisons but ensured internal validity. In a two-alternative forced-choice task, participants selected the more beautiful face from each pair. The data were analyzed using a Bayesian model which enables inference of the width ratio perceived as most beautiful. Results support the hypothesis that averageness in facial proportions correlates with higher perceived attractiveness. The study highlights the importance of controlling for image manipulation, including attempts at methodological implementation, and of considering ethnicity as a potential moderating variable. These findings offer a data-driven foundation for understanding facial aesthetics and cognitive processes of human perception, with applications in advertising, artificial face generation, and plastic surgery."}
{"id": "2602.13423", "pdf": "https://arxiv.org/pdf/2602.13423", "abs": "https://arxiv.org/abs/2602.13423", "authors": ["Amer Al-Hiyasat", "Daniel W. Swartz", "Jeff Gore", "Mehran Kardar"], "title": "Spatiotemporal noise stabilizes unbounded diversity in strongly-competitive communities", "categories": ["q-bio.PE", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": "Main text: 6 pages, 4 figures. Supplementary Information: 12 pages, 3 figures", "summary": "Classical ecological models predict that large, diverse communities should be unstable, presenting a central challenge to explaining the stable biodiversity seen in nature. We revisit this long-standing problem by extending the generalized Lotka-Volterra model to include both spatial structure and environmental fluctuations across space and time. We find that neither space nor environmental noise alone can resolve the tension between diversity and stability, but that their combined effects permit arbitrarily many species to stably coexist despite strongly disordered competitive interactions. We analytically characterize the noise-induced transition to coexistence, showing that spatiotemporal noise drives an anomalous scaling of abundance fluctuations, known empirically as Taylor's law. At the community level, this manifests as an effective sublinear self-inhibition that renders the community stable and asymptotically neutral in the high-diversity limit. Spatiotemporal noise thus provides a novel resolution to the diversity-stability paradox and a generic mechanism by which complex communities can persist."}
{"id": "2602.15022", "pdf": "https://arxiv.org/pdf/2602.15022", "abs": "https://arxiv.org/abs/2602.15022", "authors": ["Cai Zhou", "Zijie Chen", "Zian Li", "Jike Wang", "Kaiyi Jiang", "Pan Li", "Rose Yu", "Muhan Zhang", "Stephen Bates", "Tommi Jaakkola"], "title": "Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation", "categories": ["cs.LG", "cs.AI", "math.GR", "q-bio.BM"], "comment": "32 pages", "summary": "Many generative tasks in chemistry and science involve distributions invariant to group symmetries (e.g., permutation and rotation). A common strategy enforces invariance and equivariance through architectural constraints such as equivariant denoisers and invariant priors. In this paper, we challenge this tradition through the alternative canonicalization perspective: first map each sample to an orbit representative with a canonical pose or order, train an unconstrained (non-equivariant) diffusion or flow model on the canonical slice, and finally recover the invariant distribution by sampling a random symmetry transform at generation time. Building on a formal quotient-space perspective, our work provides a comprehensive theory of canonical diffusion by proving: (i) the correctness, universality and superior expressivity of canonical generative models over invariant targets; (ii) canonicalization accelerates training by removing diffusion score complexity induced by group mixtures and reducing conditional variance in flow matching. We then show that aligned priors and optimal transport act complementarily with canonicalization and further improves training efficiency. We instantiate the framework for molecular graph generation under $S_n \\times SE(3)$ symmetries. By leveraging geometric spectra-based canonicalization and mild positional encodings, canonical diffusion significantly outperforms equivariant baselines in 3D molecule generation tasks, with similar or even less computation. Moreover, with a novel architecture Canon, CanonFlow achieves state-of-the-art performance on the challenging GEOM-DRUG dataset, and the advantage remains large in few-step generation."}
{"id": "2602.13398", "pdf": "https://arxiv.org/pdf/2602.13398", "abs": "https://arxiv.org/abs/2602.13398", "authors": ["Daniel Emerson", "Nora Gaby-Biegel", "Purva Joshi", "Yoed Rabin", "Rebecca D. Sandlin", "Levent Burak Kara"], "title": "Accelerated Discovery of Cryoprotectant Cocktails via Multi-Objective Bayesian Optimization", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Designing cryoprotectant agent (CPA) cocktails for vitrification is challenging because formulations must be concentrated enough to suppress ice formation yet non-toxic enough to preserve cell viability. This tradeoff creates a large, multi-objective design space in which traditional discovery is slow, often relying on expert intuition or exhaustive experimentation. We present a data-efficient framework that accelerates CPA cocktail design by combining high-throughput screening with an active-learning loop based on multi-objective Bayesian optimization. From an initial set of measured cocktails, we train probabilistic surrogate models to predict concentration and viability and quantify uncertainty across candidate formulations. We then iteratively select the next experiments by prioritizing cocktails expected to improve the Pareto front, maximizing expected Pareto improvement under uncertainty, and update the models as new assay results are collected. Wet-lab validation shows that our approach efficiently discovers cocktails that simultaneously achieve high CPA concentrations and high post-exposure viability. Relative to a naive strategy and a strong baseline, our method improves dominated hypervolume by 9.5\\% and 4.5\\%, respectively, while reducing the number of experiments needed to reach high-quality solutions. In complementary synthetic studies, it recovers a comparably strong set of Pareto-optimal solutions using only 30\\% of the evaluations required by the prior state-of-the-art multi-objective approach, which amounts to saving approximately 10 weeks of experimental time. Because the framework assumes only a suitable assay and defined formulation space, it can be adapted to different CPA libraries, objective definitions, and cell lines to accelerate cryopreservation development."}
{"id": "2602.14843", "pdf": "https://arxiv.org/pdf/2602.14843", "abs": "https://arxiv.org/abs/2602.14843", "authors": ["Angelica Kaufmann"], "title": "Evolutionarily Primitive Social Entities", "categories": ["q-bio.NC"], "comment": null, "summary": "Social entities only exist in virtue of collective acceptance or recognition, or acknowledgement by two or more individuals in the context of joint activities. Joint activities are made possible by the coordination of plans for action, and the coordination of plans for action is made possible by the capacity for collective intentionality. This paper investigates how primitive is the capacity that nonhuman animals have to create social entities, by individuating how primitive is the capacity for collective intentionality. I present a novel argument for the evolutionary primitiveness of social entities, by showing that the collective intentions upon which these social entities are created and shared are metaphysically reducible to the relevant individual intentions."}
{"id": "2602.13630", "pdf": "https://arxiv.org/pdf/2602.13630", "abs": "https://arxiv.org/abs/2602.13630", "authors": ["Ranu Kundu", "Priya Chakraborty", "Sohini Guin", "Shyam Sundar Poriah", "Sayantari Ghosh"], "title": "Bistability to Quad-stability: Emergence of Hybrid Phenotypes & Enhanced Spatio-temporal Plasticity in Presence of Host-Circuit Coupling", "categories": ["q-bio.PE"], "comment": "18 pages 9 Fig", "summary": "In the context of multistability driven diseases, like cancer, spatiotemporal plasticity plays a significant role to achieve a spectrum of phenotypic variations. The interplay between gene regulatory networks and environmental factors, such as resource competition and spatial diffusion, plays a crucial role in determining cellular behaviour and phenotypic heterogeneity. Though reaction diffusion frameworks have been widely applied in developmental biology, less attention has been paid to the simultaneous effects of resource competition and growth feedback on spatial organization. In this paper, we observed that a bistable genetic circuit under high resource competition due to growth feedback gives rise to multiple emergent phenotypes, as observed in cancer systems. Furthermore, we observed how spatial diffusion coupled with intrinsic nonlinearity can drive the emergence of distinct spatial dynamics over time. The observed spatiotemporal plasticity can also be driven by the comparative stability of the fixed points, diffusivity, and asymmetry of diffusion. Our findings highlight that growth-induced resource competition combined with diffusion can provide deeper insights into metastasis and cancer progression."}
{"id": "2602.14328", "pdf": "https://arxiv.org/pdf/2602.14328", "abs": "https://arxiv.org/abs/2602.14328", "authors": ["Slavica Jonic"], "title": "Conformational landscapes in cryo-ET data based on MD simulations", "categories": ["q-bio.BM", "q-bio.QM"], "comment": null, "summary": "Cryo-electron tomography (cryo-ET) provides a unique window into molecular organization in cellular environments (in situ). However, the interpretation of molecular structural information is complicated by several intrinsic properties of cryo-ET data, such as noise, missing wedge, and continuous conformational variability of the molecules. Additionally, in crowded in situ environments, the number of particles extracted is sometimes small and precludes extensive classification into discrete states. These challenges shift the emphasis from high-resolution structure determination toward validation and interpretation of low-resolution density maps, and analysis of conformational flexibility. Molecular Dynamics (MD) simulations are particularly well suited to this task, as they provide a physically grounded way to explore continuous conformation transitions consistent with both experimental data and molecular energetics. This review focuses on the roles of MD simulations in cryo-ET, emphasizing their use in emerging methods for conformational landscape determination and their contribution to gain new biological insight."}
{"id": "2602.13421", "pdf": "https://arxiv.org/pdf/2602.13421", "abs": "https://arxiv.org/abs/2602.13421", "authors": ["Hadi Vafaii", "Jacob L. Yates"], "title": "Metabolic cost of information processing in Poisson variational autoencoders", "categories": ["stat.ML", "cs.AI", "q-bio.NC"], "comment": null, "summary": "Computation in biological systems is fundamentally energy-constrained, yet standard theories of computation treat energy as freely available. Here, we argue that variational free energy minimization under a Poisson assumption offers a principled path toward an energy-aware theory of computation. Our key observation is that the Kullback-Leibler (KL) divergence term in the Poisson free energy objective becomes proportional to the prior firing rates of model neurons, yielding an emergent metabolic cost term that penalizes high baseline activity. This structure couples an abstract information-theoretic quantity -- the *coding rate* -- to a concrete biophysical variable -- the *firing rate* -- which enables a trade-off between coding fidelity and energy expenditure. Such a coupling arises naturally in the Poisson variational autoencoder (P-VAE) -- a brain-inspired generative model that encodes inputs as discrete spike counts and recovers a spiking form of *sparse coding* as a special case -- but is absent from standard Gaussian VAEs. To demonstrate that this metabolic cost structure is unique to the Poisson formulation, we compare the P-VAE against Grelu-VAE, a Gaussian VAE with ReLU rectification applied to latent samples, which controls for the non-negativity constraint. Across a systematic sweep of the KL term weighting coefficient $β$ and latent dimensionality, we find that increasing $β$ monotonically increases sparsity and reduces average spiking activity in the P-VAE. In contrast, Grelu-VAE representations remain unchanged, confirming that the effect is specific to Poisson statistics rather than a byproduct of non-negative representations. These results establish Poisson variational inference as a promising foundation for a resource-constrained theory of computation."}
{"id": "2602.13913", "pdf": "https://arxiv.org/pdf/2602.13913", "abs": "https://arxiv.org/abs/2602.13913", "authors": ["Jose de Jesus Bernal-Alvarado", "David Delepine"], "title": "Gauge-Mediated Contagion: A Quantum Electrodynamics-Inspired Framework for Non-Local Epidemic Dynamics and Superdiffusion", "categories": ["q-bio.PE", "physics.bio-ph", "physics.data-an", "physics.med-ph"], "comment": "12, 3 figures", "summary": "In this paper, we introduce a gauge-mediated Epidemiological Model inspired by Quantum Electrodynamics (QED). In this model, the ``direct contact'' paradigm of classical SIR models is replaced by a gauge-mediated interaction where the environment, represented by a pathogen field $\\varphi$, plays a fundamental role in the epidemic dynamics. In this model, the non-local characteristics of epidemics appear naturally by integrating out the pathogen field. Utilizing the Doi-Peliti formalism, we derive the effective action of the system and the standard Feynman rules that can be used to compute perturbatively any observables. Using standard QED techniques, we show how to relate renormalized pathogen mass, Debye screening, to epidemiological concepts and we compute at first order the effective reproductive number,$R_{eff}$, and how the condition to have an epidemic is related to a phase transition in the pathogen mass. We show that the superspreading hosts can be included easily in this formalism."}
{"id": "2602.14616", "pdf": "https://arxiv.org/pdf/2602.14616", "abs": "https://arxiv.org/abs/2602.14616", "authors": ["Richard D. Paul", "Anton Stratmann", "Johann F. Jadebeck", "Martin Beyß", "Hanno Scharr", "David Rügamer", "Katharina Nöh"], "title": "Higher-Order Hit-&-Run Samplers for Linearly Constrained Densities", "categories": ["stat.CO", "q-bio.QM", "stat.AP"], "comment": null, "summary": "Markov chain Monte Carlo (MCMC) sampling of densities restricted to linearly constrained domains is an important task arising in Bayesian treatment of inverse problems in the natural sciences. While efficient algorithms for uniform polytope sampling exist, much less work has dealt with more complex constrained densities. In particular, gradient information as used in unconstrained MCMC is not necessarily helpful in the constrained case, where the gradient may push the proposal's density out of the polytope. In this work, we propose a novel constrained sampling algorithm, which combines strengths of higher-order information, like the target's log-density's gradients and curvature, with the Hit-&-Run proposal, a simple mechanism which guarantees the generation of feasible proposals, fulfilling the linear constraints. Our extensive experiments demonstrate improved sampling efficiency on complex constrained densities over various constrained and unconstrained samplers."}
{"id": "2602.13887", "pdf": "https://arxiv.org/pdf/2602.13887", "abs": "https://arxiv.org/abs/2602.13887", "authors": ["Hamed Heidari-Gorji", "Raquel Gil Rodriguez", "Karl R. Gegenfurtner"], "title": "Human-Aligned Evaluation of a Pixel-wise DNN Color Constancy Model", "categories": ["cs.CV", "q-bio.NC"], "comment": null, "summary": "We previously investigated color constancy in photorealistic virtual reality (VR) and developed a Deep Neural Network (DNN) that predicts reflectance from rendered images. Here, we combine both approaches to compare and study a model and human performance with respect to established color constancy mechanisms: local surround, maximum flux and spatial mean. Rather than evaluating the model against physical ground truth, model performance was assessed using the same achromatic object selection task employed in the human experiments. The model, a ResNet based U-Net from our previous work, was pre-trained on rendered images to predict surface reflectance. We then applied transfer learning, fine-tuning only the network's decoder on images from the baseline VR condition. To parallel the human experiment, the model's output was used to perform the same achromatic object selection task across all conditions. Results show a strong correspondence between the model and human behavior. Both achieved high constancy under baseline conditions and showed similar, condition-dependent performance declines when the local surround or spatial mean color cues were removed."}
{"id": "2602.14645", "pdf": "https://arxiv.org/pdf/2602.14645", "abs": "https://arxiv.org/abs/2602.14645", "authors": ["Nerea Martínez-López", "Niclas Nordholt", "Frank Schreiber", "Míriam R. García"], "title": "Conditions for Bacterial Selection and Extinction Driven by Growth-Kill Trade-Off in Cyclic Antimicrobial Treatments", "categories": ["q-bio.PE"], "comment": null, "summary": "Antimicrobial protocols - using substances such as antibiotics or disinfectants - remain the preferred option for preventing the spread of pathogenic bacteria. However, bacteria can develop mechanisms to reduce their antimicrobial susceptibility, which can lead to treatment failure and the selection of resistance or tolerance. In this work, we propose a minimal population dynamics model to study bacterial selection during cyclic antimicrobial application, a commonly used protocol. Selection in bacterial populations with heterogeneous antimicrobial susceptibility is modelled here as a trade-off between survival advantage (reduction in antimicrobial killing) and potential fitness costs (reduction in growth rate) of the less susceptible strains. The proposed model allows us to derive useful expressions for determining the success of cyclic antimicrobial treatments based on two bacterial traits: growth and kill rates. The results obtained here are directly applicable to preventing the selection and spread of resistant and tolerant bacterial strains in real-life protocols."}
{"id": "2602.14885", "pdf": "https://arxiv.org/pdf/2602.14885", "abs": "https://arxiv.org/abs/2602.14885", "authors": ["Ramón Nartallo-Kaluarachchi", "Renaud Lambiotte", "Alain Goriely"], "title": "Drift-Diffusion Matching: Embedding dynamics in latent manifolds of asymmetric neural networks", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "q-bio.NC"], "comment": "23 pages, 15 figures", "summary": "Recurrent neural networks (RNNs) provide a theoretical framework for understanding computation in biological neural circuits, yet classical results, such as Hopfield's model of associative memory, rely on symmetric connectivity that restricts network dynamics to gradient-like flows. In contrast, biological networks support rich time-dependent behaviour facilitated by their asymmetry. Here we introduce a general framework, which we term drift-diffusion matching, for training continuous-time RNNs to represent arbitrary stochastic dynamical systems within a low-dimensional latent subspace. Allowing asymmetric connectivity, we show that RNNs can faithfully embed the drift and diffusion of a given stochastic differential equation, including nonlinear and nonequilibrium dynamics such as chaotic attractors. As an application, we construct RNN realisations of stochastic systems that transiently explore various attractors through both input-driven switching and autonomous transitions driven by nonequilibrium currents, which we interpret as models of associative and sequential (episodic) memory. To elucidate how these dynamics are encoded in the network, we introduce decompositions of the RNN based on its asymmetric connectivity and its time-irreversibility. Our results extend attractor neural network theory beyond equilibrium, showing that asymmetric neural populations can implement a broad class of dynamical computations within low-dimensional manifolds, unifying ideas from associative memory, nonequilibrium statistical mechanics, and neural computation."}
{"id": "2602.14863", "pdf": "https://arxiv.org/pdf/2602.14863", "abs": "https://arxiv.org/abs/2602.14863", "authors": ["C. J. Palpal-latoc", "Ian Vega"], "title": "Quasilocalization under coupled mutation-selection dynamics", "categories": ["q-bio.PE"], "comment": "25 pages, 12 figures, comments welcome", "summary": "When mutations are rampant, quasispecies theory or Eigen's model predicts that the fittest type in a population may not dominate. Beyond a critical mutation rate, the population may even be delocalized completely from the peak of the fitness landscape and the fittest is ironically lost. Extensive efforts have been made to understand this exceptional scenario. But in general, there is no simple prescription that predicts the eventual degree of localization for arbitrary fitness landscapes and mutation rates. Here, we derive a simple and general relation linking the quasispecies' Hill numbers, which are diversity metrics in ecology, and the ratio of an effective fitness variance to the mean mutation rate squared. This ratio, which we call the localization factor, emerges from mean approximations of decomposed surprisal or stochastic entropy change rates. On the side of application, the relation we obtained here defines a combination of Hill numbers that may complement other complexity or diversity measures for real viral quasispecies. Its advantage being that there is an underlying biological interpretation under Eigen's model."}
{"id": "2602.14562", "pdf": "https://arxiv.org/pdf/2602.14562", "abs": "https://arxiv.org/abs/2602.14562", "authors": ["Simone Baldassarri", "Peter Braunsteins", "Frank den Hollander", "Michel Mandjes"], "title": "Infection models on dense dynamic random graphs", "categories": ["math.PR", "q-bio.PE"], "comment": "29 pages,", "summary": "We consider Susceptible-Infected-Recovered (SIR) models on dense dynamic random graphs, in which the joint dynamics of vertices and edges are co-evolutionary, i.e., they influence each other bidirectionally. In particular, edges appear and disappear over time depending on the states of the two connected vertices, on how long they have been infected, and on the total density of susceptible and infected vertices. Our main results establish functional laws of large numbers for the densities of susceptible, infected, and recovered vertices, jointly with the underlying evolving random graphs in the graphon space. Our results are supported by simulations, which characterize the limiting size of the epidemics, i.e., the limiting density of susceptible vertices, and how the peak of the epidemics depends on the rate of the evolution of the underlying graph.\n  The proofs of our main results rely on the careful construction of a mimicking process, obtained by approximating the two-way feedback interaction between vertex and edge dynamics with a mean-field type interaction, acting only as one-way feedback, that remains sufficiently close to the original co-evolutionary process. To treat the more general setting in which edge dynamics are affected by the proportions of susceptible and infected individuals, we introduce a methodological extension of existing techniques. We thus show that our model exhibits multiple epidemic peaks -- a phenomenon observed in real-world epidemics -- which can emerge in models that incorporate mutual feedback between vertex and edge dynamics."}
