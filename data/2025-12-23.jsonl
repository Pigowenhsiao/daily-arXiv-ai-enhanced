{"id": "2512.18442", "pdf": "https://arxiv.org/pdf/2512.18442", "abs": "https://arxiv.org/abs/2512.18442", "authors": ["Tianyu Wu"], "title": "Markovian Promoter Models: A Mechanistic Alternative to Hill Functions in Gene Regulatory Networks", "categories": ["q-bio.MN", "q-bio.QM"], "comment": null, "summary": "Gene regulatory networks are typically modeled using ordinary differential equations (ODEs) with phenomenological Hill functions to represent transcriptional regulation. While computationally efficient, Hill functions lack mechanistic grounding and cannot capture stochastic promoter dynamics. We present a hybrid Markovian-ODE framework that explicitly models discrete promoter states while maintaining computational tractability. Our approach tracks individual transcription factor binding events as a continuous-time Markov chain, coupled with deterministic ODEs for molecular concentrations. We validate this framework on seven gene regulatory systems spanning basic to advanced complexity: the GAL system, repressilator, Goodwin oscillator, toggle switch, incoherent feed-forward loop, p53-Mdm2 oscillator, and NF-$κ$B pathway. Comparison with stochastic simulation algorithm (SSA) ground truth demonstrates that Markovian promoter models achieve similar accuracy to full stochastic simulations while being 10-100$\\times$ faster. Our framework provides a mechanistic foundation for gene regulation modeling and enables investigation of promoter-level stochasticity in complex regulatory networks."}
{"id": "2512.18752", "pdf": "https://arxiv.org/pdf/2512.18752", "abs": "https://arxiv.org/abs/2512.18752", "authors": ["Michael Jirasek", "Abhishek Sharma", "Mary Wong", "Jennifer Munro", "Leroy Cronin"], "title": "Quantifying the Emergence of Selection Prior to Biological Evolution", "categories": ["q-bio.MN", "physics.bio-ph", "q-bio.PE"], "comment": "20 pages, 6 figures, 29 references", "summary": "Selection is central to biological evolution, yet there has been no general experimental framework for quantifying selection in chemical systems before life. Here we demonstrate that selection in a prebiological chemical system can be directly quantified. Assembly Theory predicts that selection corresponds to a transition from undirected to directed exploration of chemical possibility space, measurable through the amount of Assembly, A, which integrates molecular assembly index with observed copy number. By analysing peptide ensembles produced under diverse polymerisation conditions, we show that undirected reactions explore sequence space almost uniformly, yielding exploration ratios of 0.85-0.95, whereas reactions influenced by evolved proteases generate markedly lower ratios (0.51-0.75) and elevated A, consistent with selective reinforcement of specific assembly pathways. Across multiple environments and amino-acid combinations, the exploration ratio and ensemble assembly A robustly distinguish directed from undirected exploration, establishing a general, experimentally tractable metric for detecting and measuring selection in chemical evolution."}
{"id": "2512.17988", "pdf": "https://arxiv.org/pdf/2512.17988", "abs": "https://arxiv.org/abs/2512.17988", "authors": ["Avigail Taylor", "Micah P. Fletcher"], "title": "easyplater: The easy way to generate microplate designs deconvolved from multivariate clinical data", "categories": ["q-bio.QM"], "comment": "All in one PDF: 18 pages, 10 figures, 2 boxes, 1 table", "summary": "Microplate-based 'omic studies of large clinical cohorts can massively accelerate biomedical research, but experimental power and veracity may be negatively impacted when plate positional effects confound clinical variables of interest. Plate designs must therefore deconvolve this technical and biological variation, and several computational approaches now exist to achieve this. However, even the most advanced of these methods requires too much user intervention to ensure designs adhere to spatial constraints. Here, we aim to significantly reduce researcher-hours spent in plate design with three innovations: First, we propose a weighted, multivariate plate design score that uses a novel metric of spatial autocorrelation to reward designs where similar samples are in distal wells, and which also incorporates penalties for local, variable-wise homogeneous regions; Next, we use a network-based approach to identify clinically similar samples, and then generate an initial plate design randomized under the constraint that similar samples are allocated to distal wells; Lastly, we propose a novel method to quickly search plate-design space for an improvement on the initial design, as measured by the plate design score. We have implemented this method in easyplater, an R package for generating 96-well plate designs which takes sample clinical data and user-assigned clinical variable weights as input, and outputs the most deconvolved plate design it finds in CSV, XLSX, and HTML formats. Overall, easyplater reduces the need for user intervention in plate design, outperforms currently available methods, and is an important advancement as large, well-phenotyped cohorts become available for high-throughput 'omic studies and numbers of plates and clinical variables increase."}
{"id": "2512.17972", "pdf": "https://arxiv.org/pdf/2512.17972", "abs": "https://arxiv.org/abs/2512.17972", "authors": ["Arthur Aubret", "Jochen Triesch"], "title": "Re-assessing the evidence for mental rotation abilities in children using computational models", "categories": ["q-bio.NC", "cs.AI"], "comment": null, "summary": "There is strong and diverse evidence for mental rotation (MR) abilities in adults. However, current evidence for MR in children rests on just a few behavioral paradigms adapted from the adult literature. Here, we leverage recent computational models of the development of children's object recognition abilities to re-assess the evidence for MR in children. The computational models simulate infants' acquisition of object representations during embodied interactions with objects. We consider two different object recognition strategies, different from MRs, and assess their ability to replicate results from three classical MR tasks assigned to children between the ages of 6 months and 5 years. Our results show that MR may play no role in producing the results obtained from children younger than 5 years. In fact, we find that a simple recognition strategy that reflects a pixel-wise comparison of stimuli is sufficient to model children's behavior in the most used MR task. Thus, our study reopens the debate on how and when children develop genuine MR abilities."}
{"id": "2512.18139", "pdf": "https://arxiv.org/pdf/2512.18139", "abs": "https://arxiv.org/abs/2512.18139", "authors": ["Benjamin Teo", "Cécile Ané"], "title": "Adapting cluster graphs for inference of continuous trait evolution on phylogenetic networks", "categories": ["q-bio.PE", "stat.CO"], "comment": null, "summary": "Dynamic programming approaches have long been applied to fit models of univariate and multivariate trait evolution on phylogenetic trees for discrete and continuous traits, and more recently adapted to phylogenetic networks with reticulation. We previously showed that various trait evolution models on a network can be readily cast as probabilistic graphical models, so that likelihood-based estimation can proceed efficiently via belief propagation on an associated clique tree. Even so, exact likelihood inference can grow computationally prohibitive for large complex networks. Loopy belief propagation can similarly be applied to these settings, using non-tree cluster graphs to optimize a factored energy approximation to the log-likelihood, and may provide a more practical trade-off between estimation accuracy and runtime. However, the influence of cluster graph structure on this trade-off is not precisely understood. We conduct a simulation study using the Julia package PhyloGaussianBeliefProp to investigate how varying maximum cluster size affects this trade-off for Gaussian trait evolution models on networks. We discuss recommended choices for maximum cluster size, and prove the equivalence of likelihood-based and factored-energy-based parameter estimates for the homogeneous Brownian motion model."}
{"id": "2512.17930", "pdf": "https://arxiv.org/pdf/2512.17930", "abs": "https://arxiv.org/abs/2512.17930", "authors": ["Aziz Muminov", "Anne Pham"], "title": "CytoDINO: Risk-Aware and Biologically-Informed Adaptation of DINOv3 for Bone Marrow Cytomorphology", "categories": ["q-bio.OT", "cs.CV", "eess.IV", "q-bio.QM"], "comment": "11 pages, 3 figures", "summary": "Bone marrow cell cytomorphology analysis is critical for the diagnosis of hematological malignancies but remains a labor-intensive process subject to significant inter-observer variability. While recent foundation models have shown promise in computational pathology, they often require extensive computational resources and fail to account for the asymmetric risks associated with clinical misdiagnosis. We introduce CytoDINO, a framework that achieves state-of-the-art performance on the Munich Leukemia Laboratory (MLL) dataset by fine-tuning DINOv3 using Low-Rank Adaptation (LoRA). Our primary contribution is a novel Hierarchical Focal Loss with Critical Penalties, which encodes biological relationships between cell lineages and explicitly penalizes clinically dangerous misclassifications (e.g., classifying blasts as normal cells). CytoDINO achieves an 88.2% weighted F1 score and 76.5% macro F1 on a held-out test set of 21 cell classes. By utilizing parameter-efficient fine-tuning with only 8% trainable parameters on a single NVIDIA RTX 5080, we demonstrate that consumer-grade hardware can match specialized infrastructure. Furthermore, confidence-based selective prediction yields 99.5% accuracy on 67% of samples, suggesting a viable pathway for clinical deployment where high-uncertainty cases are flagged for expert review"}
{"id": "2512.18114", "pdf": "https://arxiv.org/pdf/2512.18114", "abs": "https://arxiv.org/abs/2512.18114", "authors": ["Robert Calef", "Arthur Liang", "Manolis Kellis", "Marinka Zitnik"], "title": "Greater than the Sum of Its Parts: Building Substructure into Protein Encoding Models", "categories": ["q-bio.QM"], "comment": null, "summary": "Protein representation learning has advanced rapidly with the scale-up of sequence and structure supervision, but most models still encode proteins either as per-residue token sequences or as single global embeddings. This overlooks a defining property of protein organization: proteins are built from recurrent, evolutionarily conserved substructures that concentrate biochemical activity and mediate core molecular functions. Although substructures such as domains and functional sites are systematically cataloged, they are rarely used as training signals or representation units in protein models. We introduce Magneton, an environment for developing substructure-aware protein models. Magneton provides (1) a dataset of 530,601 proteins annotated with over 1.7 million substructures spanning 13,075 types, (2) a training framework for incorporating substructures into existing protein models, and (3) a benchmark suite of 13 tasks probing representations at the residue, substructural, and protein levels. Using Magneton, we develop substructure-tuning, a supervised fine-tuning method that distills substructural knowledge into pretrained protein models. Across state-of-the-art sequence- and structure-based models, substructure-tuning improves function prediction, yields more consistent representations of substructure types never observed during tuning, and shows that substructural supervision provides information that is complementary to global structure inputs. The Magneton environment, datasets, and substructure-tuned models are all openly available (https://github.com/rcalef/magneton/)."}
{"id": "2512.17978", "pdf": "https://arxiv.org/pdf/2512.17978", "abs": "https://arxiv.org/abs/2512.17978", "authors": ["Shuntaro Suzuki", "Chia-Chun Dan Hsu", "Yu Tsao", "Komei Sugiura"], "title": "MEGState: Phoneme Decoding from Magnetoencephalography Signals", "categories": ["q-bio.NC", "cs.LG", "cs.SD"], "comment": "Accepted for presentation at LibriBrain Competition, NeurIPS 2025", "summary": "Decoding linguistically meaningful representations from non-invasive neural recordings remains a central challenge in neural speech decoding. Among available neuroimaging modalities, magnetoencephalography (MEG) provides a safe and repeatable means of mapping speech-related cortical dynamics, yet its low signal-to-noise ratio and high temporal dimensionality continue to hinder robust decoding. In this work, we introduce MEGState, a novel architecture for phoneme decoding from MEG signals that captures fine-grained cortical responses evoked by auditory stimuli. Extensive experiments on the LibriBrain dataset demonstrate that MEGState consistently surpasses baseline model across multiple evaluation metrics. These findings highlight the potential of MEG-based phoneme decoding as a scalable pathway toward non-invasive brain-computer interfaces for speech."}
{"id": "2512.18216", "pdf": "https://arxiv.org/pdf/2512.18216", "abs": "https://arxiv.org/abs/2512.18216", "authors": ["Rohan Shirur", "Bryce Morsky"], "title": "Phage-antibiotic therapy under density dependent bacterial defenses", "categories": ["q-bio.PE"], "comment": null, "summary": "Phage therapy is an alternative treatment method for bacterial infections. It has shown particular promise in reducing bacterial load while preventing antibiotic resistance. Here, we develop a mathematical model of a bacterial infection within a host to study phage therapy. It incorporates interactions between phages, bacteria, the immune system, and antibiotics. Additionally, the model includes bacterial social dynamics that provide protection from treatments and the innate immune response. We analytically and numerically identify all of the equilibria of the model and derive insights regarding the overall effectiveness of phage therapy. Without phage therapy, the model exhibits bistability: bacteria populations above a threshold grow and become entrenched, while those below it can be effectively suppressed by the immune system. We find that that phages destabilize the former equilibrium, and thus in combination with the immune system are able to suppress the bacteria. We conducted bifurcation analyses, which show that the equilibrium with a suppressed population of bacteria can become unstable. In this scenario, the system undergoes oscillations. However, these oscillations -- which can be exacerbated by social dynamics -- lead to minuscule bacterial populations, and thus, in practice, phage therapy is widely effective across the parameter space. We also demonstrate how suppression can be further improved by the addition of periodic dosing of antibiotics in a combination therapy."}
{"id": "2512.17966", "pdf": "https://arxiv.org/pdf/2512.17966", "abs": "https://arxiv.org/abs/2512.17966", "authors": ["Brian N. Bailey"], "title": "A generalized framework for procedural generation of three-dimensional static and dynamic plant model geometries", "categories": ["q-bio.OT"], "comment": null, "summary": "This work presents a new framework for procedural generation of dynamic 3D plant model geometries, which has been implemented in the Helios modeling system. Key goals of this work were to develop a model that 1) has a generalized set of parameters that are conserved across species, which are botanically-consistent and readily measurable; 2) significantly reduces the time and effort needed to create photorealistic, dynamically evolving plant models; 3) allows for encoding of the entire plant structure into a character-based representation that can integrated with machine learning models, and 4) includes realistic and computationally efficient collision physics. A model framework that satisfies these specifications is presented in this report. The model was implemented in the Helios C++ and PyHelios Python frameworks, which are open-source libraries that can be used to generate 3D plant geometries based on this model."}
{"id": "2512.18197", "pdf": "https://arxiv.org/pdf/2512.18197", "abs": "https://arxiv.org/abs/2512.18197", "authors": ["Yilei Wu", "Yichi Zhang", "Zijian Dong", "Fang Ji", "An Sen Tan", "Gifford Tan", "Sizhao Tang", "Huijuan Chen", "Zijiao Chen", "Eric Kwun Kei Ng", "Jose Bernal", "Hang Min", "Ying Xia", "Ines Vati", "Liz Cooper", "Xiaoyu Hu", "Yuchen Pei", "Yutao Ma", "Victor Nozais", "Ami Tsuchida", "Pierre-Yves Hervé", "Philippe Boutinaud", "Marc Joliot", "Junghwa Kang", "Wooseung Kim", "Dayeon Bak", "Rachika E. Hamadache", "Valeriia Abramova", "Xavier Lladó", "Yuntao Zhu", "Zhenyu Gong", "Xin Chen", "John McFadden", "Pek Lan Khong", "Roberto Duarte Coello", "Hongwei Bran Li", "Woon Puay Koh", "Christopher Chen", "Joanna M. Wardlaw", "Maria del C. Valdés Hernández", "Juan Helen Zhou"], "title": "Standardized Evaluation of Automatic Methods for Perivascular Spaces Segmentation in MRI -- MICCAI 2024 Challenge Results", "categories": ["q-bio.QM", "cs.CV", "eess.IV"], "comment": null, "summary": "Perivascular spaces (PVS), when abnormally enlarged and visible in magnetic resonance imaging (MRI) structural sequences, are important imaging markers of cerebral small vessel disease and potential indicators of neurodegenerative conditions. Despite their clinical significance, automatic enlarged PVS (EPVS) segmentation remains challenging due to their small size, variable morphology, similarity with other pathological features, and limited annotated datasets. This paper presents the EPVS Challenge organized at MICCAI 2024, which aims to advance the development of automated algorithms for EPVS segmentation across multi-site data. We provided a diverse dataset comprising 100 training, 50 validation, and 50 testing scans collected from multiple international sites (UK, Singapore, and China) with varying MRI protocols and demographics. All annotations followed the STRIVE protocol to ensure standardized ground truth and covered the full brain parenchyma. Seven teams completed the full challenge, implementing various deep learning approaches primarily based on U-Net architectures with innovations in multi-modal processing, ensemble strategies, and transformer-based components. Performance was evaluated using dice similarity coefficient, absolute volume difference, recall, and precision metrics. The winning method employed MedNeXt architecture with a dual 2D/3D strategy for handling varying slice thicknesses. The top solutions showed relatively good performance on test data from seen datasets, but significant degradation of performance was observed on the previously unseen Shanghai cohort, highlighting cross-site generalization challenges due to domain shift. This challenge establishes an important benchmark for EPVS segmentation methods and underscores the need for the continued development of robust algorithms that can generalize in diverse clinical settings."}
{"id": "2512.17989", "pdf": "https://arxiv.org/pdf/2512.17989", "abs": "https://arxiv.org/abs/2512.17989", "authors": ["Muhammad Osama Imran", "Roshni Lulla", "Rodney Sappington"], "title": "The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective", "categories": ["q-bio.NC", "cs.AI"], "comment": "10 pages", "summary": "We examine the conceptual and ethical gaps in current representations of Superintelligence misalignment. We find throughout Superintelligence discourse an absent human subject, and an under-developed theorization of an \"AI unconscious\" that together are potentiality laying the groundwork for anti-social harm. With the rise of AI Safety that has both thematic potential for establishing pro-social and anti-social potential outcomes, we ask: what place does the human subject occupy in these imaginaries? How is human subjecthood positioned within narratives of catastrophic failure or rapid \"takeoff\" toward superintelligence? On another register, we ask: what unconscious or repressed dimensions are being inscribed into large-scale AI models? Are we to blame these agents in opting for deceptive strategies when undesirable patterns are inherent within our beings? In tracing these psychic and epistemic absences, our project calls for re-centering the human subject as the unstable ground upon which the ethical, unconscious, and misaligned dimensions of both human and machinic intelligence are co-constituted. Emergent misalignment cannot be understood solely through technical diagnostics typical of contemporary machine-learning safety research. Instead, it represents a multi-layered crisis. The human subject disappears not only through computational abstraction but through sociotechnical imaginaries that prioritize scalability, acceleration, and efficiency over vulnerability, finitude, and relationality. Likewise, the AI unconscious emerges not as a metaphor but as a structural reality of modern deep learning systems: vast latent spaces, opaque pattern formation, recursive symbolic play, and evaluation-sensitive behavior that surpasses explicit programming. These dynamics necessitate a reframing of misalignment as a relational instability embedded within human-machine ecologies."}
{"id": "2512.18387", "pdf": "https://arxiv.org/pdf/2512.18387", "abs": "https://arxiv.org/abs/2512.18387", "authors": ["Francesca Ballatore", "Lorenzo Scolaris", "Chiara Giverso"], "title": "From Brain Scans to Therapy Response: PDE Modelling of Immunotherapy for Glioblastoma", "categories": ["q-bio.PE"], "comment": null, "summary": "Glioblastoma Multiforme (GBM) is a highly aggressive brain tumour with limited therapeutic options and poor prognosis. This study presents a mathematical framework to investigate the efficacy of immunotherapy strategies based on cytotoxic T-lymphocyte (CTL) infusion. The model couples tumour and immune dynamics through a system of partial differential equations (PDEs), incorporating cell proliferation, diffusion, and chemotactic migration in response to TGF-$β$, a tumour-secreted signalling molecule. A reduced ordinary differential equation (ODE) model is first analysed to derive threshold conditions for tumour eradication, identifying critical infusion levels consistent with clinical data. Numerical bifurcation analysis explores the impact of parameter variations. The full PDE model is solved using the finite element method on simplified 2D domains, followed by sensitivity analyses to quantify parameter influence on tumour mass and volume. The model is then applied to a realistic 3D brain geometry reconstructed from patient-specific MRI and DTI data, accounting for anatomical anisotropy and tissue heterogeneity. Therapeutic scenarios are simulated with spatially localised lymphocyte infusion. Results highlight spatial variations in tumour growth and treatment response, with infusion intensity and tumour location critically influencing therapeutic outcomes. These findings emphasise the importance of personalised, spatially informed modelling in optimising immunotherapy protocols for GBM."}
{"id": "2512.18681", "pdf": "https://arxiv.org/pdf/2512.18681", "abs": "https://arxiv.org/abs/2512.18681", "authors": ["Rohan Sarkar", "Sharmistha Maji", "Tuhin Subhra Pal", "Achal Dharmalal Rajratna", "Avik Ghosh", "Madhurima Roy", "Sampurna Bag", "Srijaya Nandi", "Arpan Bhattacharyya", "S. Sivasubramaniam", "Avirup Chakraborty", "Anindita Bhadra"], "title": "Trick or Treat? Free-ranging dogs use human behavioural cues for foraging", "categories": ["q-bio.OT"], "comment": "5 figures", "summary": "Animals that display behavioural flexibility and adaptability thrive in urban environments, due to their ability to exploit novel anthropogenic resources. Since humans are an important component of such urban environments, animals that apply heterospecific learning in their decision-making are more likely to succeed as urban adapters. Free-ranging dogs, that have been living in human-dominated environments for centuries, are excellent urban adapters. In this study, we sought to understand the role and extent of human behavioural cues in decision-making during foraging by free-ranging dogs. We investigated whether these dogs were more attracted to items that humans appeared to be eating. When presented with a real and a fake biscuit, the dogs showed a clear preference for the food item. Between two identical biscuits, they chose the one that had been bitten by a human. However, when a fake biscuit was bitten and presented with a real one, the dogs failed to choose one over the other, suggesting a strong influence of the human-provided cue of biting over the natural cue of the smell of the food item. The dogs displayed left-bias during food choice across experimental conditions. These results demonstrate that dog foraging choices in urban environments are a mix of heterospecific learning and independent decision-making, highlighting an important facet behind their success in anthropogenic habitats. This also underscores the high level of dependence that free-ranging dogs have on humans in the urban habitat, not only as a source of food, but as an integral part of their ecological niche."}
{"id": "2512.19416", "pdf": "https://arxiv.org/pdf/2512.19416", "abs": "https://arxiv.org/abs/2512.19416", "authors": ["Mamoru Saita", "Yutaka Hori"], "title": "Machine Learning of Temperature-dependent Chemical Kinetics Using Parallel Droplet Microreactors", "categories": ["q-bio.QM", "eess.SY", "physics.bio-ph"], "comment": null, "summary": "Temperature is a fundamental regulator of chemical and biochemical kinetics, yet capturing nonlinear thermal effects directly from experimental data remains a major challenge due to limited throughput and model flexibility. Recent advances in machine learning have enabled flexible modeling beyond conventional physical laws, but most existing strategies remain confined to surrogate models of end-point yields rather than full kinetic dynamics. Consequently, an end-to-end framework that unifies systematic kinetic data acquisition with machine learning based modeling has been lacking. In this paper, we present a unified framework that integrates droplet microfluidics with machine learning for the systematic analysis of temperature-dependent reaction kinetics. The platform is specifically designed to enable stable immobilization and long-term time-lapse imaging of thousands of droplets under dynamic thermal gradients. This configuration yields massively parallel time-resolved datasets across diverse temperature conditions that capture transient kinetics and provides particularly suitable inputs for training machine-learning models of reaction dynamics. Leveraging these datasets, we train Neural ODE models, which embed neural networks within differential equations to flexibly represent nonlinear temperature dependencies beyond conventional formulations. We demonstrate accurate prediction of enzymatic kinetics across diverse thermal environments, highlighting the robustness and versatility of the approach. Our framework bridges high-throughput experimental data acquisition with data-driven modeling, establishing a versatile foundation for enhanced predictive ability and rational analysis and design of temperature-sensitive biochemical processes."}
{"id": "2512.18113", "pdf": "https://arxiv.org/pdf/2512.18113", "abs": "https://arxiv.org/abs/2512.18113", "authors": ["Jacob T. Crosser", "Braden A. W. Brinkman"], "title": "Responses to transient perturbation can distinguish intrinsic from latent criticality in spiking neural populations", "categories": ["q-bio.NC", "cond-mat.dis-nn"], "comment": null, "summary": "The critical brain hypothesis posits that neural circuitry operates near criticality to reap the computational benefits of accessing a wide range of timescales. The theory of critical phenomena generally predicts heavy-tailed (power-law) correlations in space and time near criticality, but it has been argued that in the brain such correlations could be inherited from ``latent variables,'' such as external sensory signals that are not directly observed when recording from neural circuitry. Distinguishing whether heavy-tailed correlations in neural activity are intrinsically generated within a neural circuit or are driven by unobserved latent variables is crucial for properly interpreting circuit functions. We argue that measuring neural responses to sudden perturbative inputs, rather than correlations in ongoing activity, can disambiguate these cases. We demonstrate this approach in a model of stochastic spiking neuron populations receiving external latent input that can be tuned to a critical state. We propose a scaling theory for the covariance and response functions of the spiking network, which we validate with simulations. We end by discussing how our approach might generalize to models of neural populations with more realistic biophysical details."}
{"id": "2512.19485", "pdf": "https://arxiv.org/pdf/2512.19485", "abs": "https://arxiv.org/abs/2512.19485", "authors": ["Eva Molnárová", "Ties A. Mulders", "Marcela Spee-Dropková", "Louise M. Spekking", "Sepinoud Azimi", "Irene Grossmann", "Anne-Marie C. Dingemans", "Kateřina Staňková"], "title": "Enabling Evolutionary Therapy in Metastatic Cancer Lacking Serum Biomarkers", "categories": ["q-bio.PE"], "comment": "15 pages including references, 3 figures, 1 box", "summary": "Evolutionary therapy (ET) aims to steer tumor evolution by adjusting treatment timing and dosing to control rather than eradicate tumor burden. Clinical use requires reliable monitoring of tumor dynamics to inform mathematical models that guide therapy. In cancers such as metastatic castrate-resistant prostate cancer and relapsed platinum-sensitive ovarian cancer, ET models are informed by serial serum biomarkers. For cancers lacking reliable biomarkers, such as metastatic non-small cell lung cancer (NSCLC), radiographic imaging remains the primary method for treatment response assessment, typically using RECIST 1.1 criteria. RECIST, which tracks a few lesions with one-dimensional (1D) measurements and defines progression relative to the nadir, the smallest tumor burden recorded after treatment, was not designed to support ET. It may miss early regrowth, underrepresent tumor burden, and obscure disease trends. Using a virtual NSCLC patient model, we demonstrate that lesion selection and measurement dimensionality strongly affect progression detection. Two-dimensional metrics provide modest improvement, but only 3D volumetric measurements accurately capture both tumor burden and its dynamics, which are key requirements for ET. To support ET in cancers lacking biomarkers, response assessment must evolve beyond RECIST by integrating volumetric imaging, automated segmentation, and potentially liquid biopsies, alongside redefining progression criteria to enable adaptive, patient-centered treatments."}
{"id": "2512.08589", "pdf": "https://arxiv.org/pdf/2512.08589", "abs": "https://arxiv.org/abs/2512.08589", "authors": ["Swarn Singh Warshaneyan", "Maksims Ivanovs", "Blaž Cugmas", "Inese Bērziņa", "Laura Goldberga", "Mindaugas Tamosiunas", "Roberts Kadiķis"], "title": "Automated Pollen Recognition in Optical and Holographic Microscopy Images", "categories": ["cs.CV", "cs.LG", "q-bio.QM"], "comment": "08 pages, 10 figures, 04 tables, 20 references. Date of Conference: 13-14 June 2025 Date Added to IEEE Xplore: 10 July 2025 Electronic ISBN: 979-8-3315-0969-9 Print on Demand(PoD) ISBN: 979-8-3315-0970-5 DOI: 10.1109/AICCONF64766.2025.11064260 Conference Location: Prague, Czech Republic Online Access: https://ieeexplore.ieee.org/document/11064260", "summary": "This study explores the application of deep learning to improve and automate pollen grain detection and classification in both optical and holographic microscopy images, with a particular focus on veterinary cytology use cases. We used YOLOv8s for object detection and MobileNetV3L for the classification task, evaluating their performance across imaging modalities. The models achieved 91.3% mAP50 for detection and 97% overall accuracy for classification on optical images, whereas the initial performance on greyscale holographic images was substantially lower. We addressed the performance gap issue through dataset expansion using automated labeling and bounding box area enlargement. These techniques, applied to holographic images, improved detection performance from 2.49% to 13.3% mAP50 and classification performance from 42% to 54%. Our work demonstrates that, at least for image classification tasks, it is possible to pair deep learning techniques with cost-effective lensless digital holographic microscopy devices."}
{"id": "2512.18165", "pdf": "https://arxiv.org/pdf/2512.18165", "abs": "https://arxiv.org/abs/2512.18165", "authors": ["Hamza Abdelhedi", "Yorguin-Jose Mantilla-Ramos", "Sina Esmaeili", "Annalisa Pascarella", "Vanessa Hadid", "Karim Jerbi"], "title": "Coord2Region: A Python Package for Mapping 3D Brain Coordinates to Atlas Labels, Literature, and AI Summaries", "categories": ["q-bio.NC"], "comment": null, "summary": "We present Coord2Region, an open-source Python package that streamlines coordinate-based neuroimaging workflows by automatically mapping 3D brain coordinates (e.g., MNI or Talairach) to anatomical regions across multiple atlases. The package links mapped coordinates to meta-analytic resources via the Neuroimaging Meta-Analysis Research Environment (NiMARE) , providing direct integration with Neurosynth and NeuroQuery. This directly connects coordinates and regions to the broader neuroimaging literature. In addition to atlas-based labeling and literature retrieval, Coord2Region offers an optional large language model (LLM) functionality that generates text summaries of linked studies and illustrative images of queried regions. These AI-assisted features are intended to support interpretation and exploration, while remaining clearly complementary to peer-reviewed literature and established neuroimaging tools. Coord2Region provides a unified pipeline with a robust command-line interface, flexible dataset management, and provider-agnostic LLM utilities, and it supports both single-coordinate and high-throughput batch queries with nearest-region fallback for volume and surface atlases. Furthermore, Coord2Region includes a web interface for interactive configuration (via JSON Schema forms) and cloud execution (via Hugging Face), enabling users to build YAML configurations and run analyses in-browser without local installation. Together, these capabilities lower friction, reduce manual errors, and improve reproducibility in coordinate-centric neuroimaging workflows, promoting more robust and transparent research practices."}
{"id": "2512.18652", "pdf": "https://arxiv.org/pdf/2512.18652", "abs": "https://arxiv.org/abs/2512.18652", "authors": ["Elad Korngut", "Michael Assaf"], "title": "Impact of temporary lockdown on disease extinction in assortative networks", "categories": ["cond-mat.stat-mech", "q-bio.PE"], "comment": "9 pages, 5 figures", "summary": "Changing environmental conditions can significantly affect the dynamics of disease spread. These changes may arise naturally or result from human interventions; in the latter case, lockdown measures that lead to abrupt but temporary reductions in transmission rates are used to combat disease spread. However, the impact of these measures on rare events in realistic populations has not been studied so far. Here, we analyze the susceptible-infected-susceptible (SIS) model in a stochastic setting where disease extinction -- a sudden clearance of the infection -- occurs via a rare, large fluctuation. We use a semiclassical approximation and extensive numerical simulations to show how the extinction risk of the disease depends on both the duration and magnitude of the lockdown, in heterogeneous assortative networks, with degree-degree correlations between neighboring nodes."}
{"id": "2512.17930", "pdf": "https://arxiv.org/pdf/2512.17930", "abs": "https://arxiv.org/abs/2512.17930", "authors": ["Aziz Muminov", "Anne Pham"], "title": "CytoDINO: Risk-Aware and Biologically-Informed Adaptation of DINOv3 for Bone Marrow Cytomorphology", "categories": ["q-bio.OT", "cs.CV", "eess.IV", "q-bio.QM"], "comment": "11 pages, 3 figures", "summary": "Bone marrow cell cytomorphology analysis is critical for the diagnosis of hematological malignancies but remains a labor-intensive process subject to significant inter-observer variability. While recent foundation models have shown promise in computational pathology, they often require extensive computational resources and fail to account for the asymmetric risks associated with clinical misdiagnosis. We introduce CytoDINO, a framework that achieves state-of-the-art performance on the Munich Leukemia Laboratory (MLL) dataset by fine-tuning DINOv3 using Low-Rank Adaptation (LoRA). Our primary contribution is a novel Hierarchical Focal Loss with Critical Penalties, which encodes biological relationships between cell lineages and explicitly penalizes clinically dangerous misclassifications (e.g., classifying blasts as normal cells). CytoDINO achieves an 88.2% weighted F1 score and 76.5% macro F1 on a held-out test set of 21 cell classes. By utilizing parameter-efficient fine-tuning with only 8% trainable parameters on a single NVIDIA RTX 5080, we demonstrate that consumer-grade hardware can match specialized infrastructure. Furthermore, confidence-based selective prediction yields 99.5% accuracy on 67% of samples, suggesting a viable pathway for clinical deployment where high-uncertainty cases are flagged for expert review"}
{"id": "2512.18585", "pdf": "https://arxiv.org/pdf/2512.18585", "abs": "https://arxiv.org/abs/2512.18585", "authors": ["Ahmad Sohrabi"], "title": "Deep Teleportation: Quantum Simulation of Conscious Report in Attentional Blink", "categories": ["q-bio.NC"], "comment": "23 pages, 19 figures, under review: Cognitive Systems Research", "summary": "Recent quantum models of cognition have successfully simulated several interesting effects in human experimental data, from vision to reasoning and recently even consciousness. The latter case, consciousness has been a quite challenging phenomenon to model, and most efforts have been through abstract mathematical quantum methods, mainly focused on conceptual issues. Classical (non-quantum) models of consciousness-related experiments exist, but they generally fail to align well with human data. We developed a straightforward quantum model to simulate conscious reporting of seeing or missing competing stimuli within the famous attentional blink paradigm. In an attentional blink task, a target stimulus (T2) that appears after a previous one (T1) can be consciously reported if the delay between presenting them is short enough (called lag 1), otherwise it can be rendered invisible during the so-called refractory period of attention (lags 2 to 6 and even longer). For modeling this phenomenon, we employed a three-qubit entanglement ansatz circuit in the form of a deep teleportation channel instead of the well-known EPR channel. While reporting the competing stimuli was supposed to be the classical measurement outcomes, the effect of distractor stimuli (i.e., masks, if any) was encoded simply as random angle rotations. The simulation outcome for different states was measured, and the classical outcome probabilities were further used as inputs to a simple linear neural network. The result revealed a non-linear, alternating state pattern that closely mirrors human responses in conscious stimuli reporting. The main result was a successful simulation of Lag 1 sparing, lag 7 divergence, and masking effect through probabilistic outcome of measurement in different conditions."}
{"id": "2512.18752", "pdf": "https://arxiv.org/pdf/2512.18752", "abs": "https://arxiv.org/abs/2512.18752", "authors": ["Michael Jirasek", "Abhishek Sharma", "Mary Wong", "Jennifer Munro", "Leroy Cronin"], "title": "Quantifying the Emergence of Selection Prior to Biological Evolution", "categories": ["q-bio.MN", "physics.bio-ph", "q-bio.PE"], "comment": "20 pages, 6 figures, 29 references", "summary": "Selection is central to biological evolution, yet there has been no general experimental framework for quantifying selection in chemical systems before life. Here we demonstrate that selection in a prebiological chemical system can be directly quantified. Assembly Theory predicts that selection corresponds to a transition from undirected to directed exploration of chemical possibility space, measurable through the amount of Assembly, A, which integrates molecular assembly index with observed copy number. By analysing peptide ensembles produced under diverse polymerisation conditions, we show that undirected reactions explore sequence space almost uniformly, yielding exploration ratios of 0.85-0.95, whereas reactions influenced by evolved proteases generate markedly lower ratios (0.51-0.75) and elevated A, consistent with selective reinforcement of specific assembly pathways. Across multiple environments and amino-acid combinations, the exploration ratio and ensemble assembly A robustly distinguish directed from undirected exploration, establishing a general, experimentally tractable metric for detecting and measuring selection in chemical evolution."}
{"id": "2512.18442", "pdf": "https://arxiv.org/pdf/2512.18442", "abs": "https://arxiv.org/abs/2512.18442", "authors": ["Tianyu Wu"], "title": "Markovian Promoter Models: A Mechanistic Alternative to Hill Functions in Gene Regulatory Networks", "categories": ["q-bio.MN", "q-bio.QM"], "comment": null, "summary": "Gene regulatory networks are typically modeled using ordinary differential equations (ODEs) with phenomenological Hill functions to represent transcriptional regulation. While computationally efficient, Hill functions lack mechanistic grounding and cannot capture stochastic promoter dynamics. We present a hybrid Markovian-ODE framework that explicitly models discrete promoter states while maintaining computational tractability. Our approach tracks individual transcription factor binding events as a continuous-time Markov chain, coupled with deterministic ODEs for molecular concentrations. We validate this framework on seven gene regulatory systems spanning basic to advanced complexity: the GAL system, repressilator, Goodwin oscillator, toggle switch, incoherent feed-forward loop, p53-Mdm2 oscillator, and NF-$κ$B pathway. Comparison with stochastic simulation algorithm (SSA) ground truth demonstrates that Markovian promoter models achieve similar accuracy to full stochastic simulations while being 10-100$\\times$ faster. Our framework provides a mechanistic foundation for gene regulation modeling and enables investigation of promoter-level stochasticity in complex regulatory networks."}
{"id": "2512.19450", "pdf": "https://arxiv.org/pdf/2512.19450", "abs": "https://arxiv.org/abs/2512.19450", "authors": ["Leo D'Amato", "Davide Nuzzi", "Alberto Testolin", "Ivilin Peev Stoianov", "Marco Zorzi", "Giovanni Pezzulo"], "title": "A Rate-Distortion Perspective on the Emergence of Number Sense in Unsupervised Generative Models", "categories": ["q-bio.NC"], "comment": null, "summary": "Number sense is a core cognitive ability supporting various adaptive behaviors and is foundational for mathematical learning. Here, we study its emergence in unsupervised generative models through the lens of rate-distortion theory (RDT), a normative framework for understanding information processing under limited resources. We train $β$-Variational Autoencoders -- which embody key formal principles of RDT -- on synthetic images containing varying numbers of items, as commonly used in numerosity perception research. We systematically vary the encoding capacity and assess the models' sensitivity to numerosity and the robustness of the emergent numerical representations through a comprehensive set of analyses, including numerosity estimation and discrimination tasks, latent-space analysis, generative capabilities and generalization to novel stimuli. In line with RDT, we find that behavioral performance in numerosity perception and the ability to extract numerosity unconfounded by non-numerical visual features scale with encoding capacity according to a power law. At high capacity, the unsupervised model develops a robust neural code for numerical information, with performance closely approximating a supervised model explicitly trained for visual enumeration. It exhibits strong generative abilities and generalizes well to novel images, whereas at low capacity, the model shows marked deficits in numerosity perception and representation. Finally, comparison with human data shows that models trained at intermediate capacity levels span the full range of human behavioral performance while still developing a robust emergent numerical code. In sum, our results show that unsupervised generative models can develop a number sense and demonstrate that rate-distortion theory provides a powerful information-theoretic framework for understanding how capacity constraints shape numerosity perception."}
{"id": "2512.18454", "pdf": "https://arxiv.org/pdf/2512.18454", "abs": "https://arxiv.org/abs/2512.18454", "authors": ["David Graber", "Victor Armegioiu", "Rebecca Buller", "Siddhartha Mishra"], "title": "Out-of-Distribution Detection in Molecular Complexes via Diffusion Models for Irregular Graphs", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Predictive machine learning models generally excel on in-distribution data, but their performance degrades on out-of-distribution (OOD) inputs. Reliable deployment therefore requires robust OOD detection, yet this is particularly challenging for irregular 3D graphs that combine continuous geometry with categorical identities and are unordered by construction. Here, we present a probabilistic OOD detection framework for complex 3D graph data built on a diffusion model that learns a density of the training distribution in a fully unsupervised manner. A key ingredient we introduce is a unified continuous diffusion over both 3D coordinates and discrete features: categorical identities are embedded in a continuous space and trained with cross-entropy, while the corresponding diffusion score is obtained analytically via posterior-mean interpolation from predicted class probabilities. This yields a single self-consistent probability-flow ODE (PF-ODE) that produces per-sample log-likelihoods, providing a principled typicality score for distribution shift. We validate the approach on protein-ligand complexes and construct strict OOD datasets by withholding entire protein families from training. PF-ODE likelihoods identify held-out families as OOD and correlate strongly with prediction errors of an independent binding-affinity model (GEMS), enabling a priori reliability estimates on new complexes. Beyond scalar likelihoods, we show that multi-scale PF-ODE trajectory statistics - including path tortuosity, flow stiffness, and vector-field instability - provide complementary OOD information. Modeling the joint distribution of these trajectory features yields a practical, high-sensitivity detector that improves separation over likelihood-only baselines, offering a label-free OOD quantification workflow for geometric deep learning."}
{"id": "2512.18471", "pdf": "https://arxiv.org/pdf/2512.18471", "abs": "https://arxiv.org/abs/2512.18471", "authors": ["Xin Li"], "title": "The Geometry of Abstraction: Continual Learning via Recursive Quotienting", "categories": ["cs.LG", "q-bio.NC"], "comment": null, "summary": "Continual learning systems operating in fixed-dimensional spaces face a fundamental geometric barrier: the flat manifold problem. When experience is represented as a linear trajectory in Euclidean space, the geodesic distance between temporal events grows linearly with time, forcing the required covering number to diverge. In fixed-dimensional hardware, this volume expansion inevitably forces trajectory overlap, manifesting as catastrophic interference. In this work, we propose a geometric resolution to this paradox based on Recursive Metric Contraction. We formalize abstraction not as symbolic grouping, but as a topological deformation: a quotient map that collapses the metric tensor within validated temporal neighborhoods, effectively driving the diameter of local sub-manifolds to zero. We substantiate our framework with four rigorous results. First, the Bounded Capacity Theorem establishes that recursive quotient maps allow the embedding of arbitrarily long trajectories into bounded representational volumes, trading linear metric growth for logarithmic topological depth. Second, the Topological Collapse Separability Theorem, derived via Urysohn's Lemma, proves that recursive quotienting renders non-linearly separable temporal sequences linearly separable in the limit, bypassing the need for infinite-dimensional kernel projections. Third, the Parity-Partitioned Stability Theorem solves the catastrophic forgetting problem by proving that if the state space is partitioned into orthogonal flow and scaffold manifolds, the metric deformations of active learning do not disturb the stability of stored memories. Our analysis reveals that tokens in neural architectures are physically realizable as singularities or wormholes, regions of extreme positive curvature that bridge distant points in the temporal manifold."}
{"id": "2512.18566", "pdf": "https://arxiv.org/pdf/2512.18566", "abs": "https://arxiv.org/abs/2512.18566", "authors": ["Ruiqi Chen", "Giacomo Vedovati", "Todd Braver", "ShiNung Ching"], "title": "Comparing Dynamical Models Through Diffeomorphic Vector Field Alignment", "categories": ["cs.LG", "eess.SY", "q-bio.NC"], "comment": "57 pages, 18 figures. For associated code, see https://github.com/rq-Chen/DFORM_stable", "summary": "Dynamical systems models such as recurrent neural networks (RNNs) are increasingly popular in theoretical neuroscience for hypothesis-generation and data analysis. Evaluating the dynamics in such models is key to understanding their learned generative mechanisms. However, such evaluation is impeded by two major challenges: First, comparison of learned dynamics across models is difficult because there is no enforced equivalence of their coordinate systems. Second, identification of mechanistically important low-dimensional motifs (e.g., limit sets) is intractable in high-dimensional nonlinear models such as RNNs. Here, we propose a comprehensive framework to address these two issues, termed Diffeomorphic vector field alignment FOR learned Models (DFORM). DFORM learns a nonlinear coordinate transformation between the state spaces of two dynamical systems, which aligns their trajectories in a maximally one-to-one manner. In so doing, DFORM enables an assessment of whether two models exhibit topological equivalence, i.e., similar mechanisms despite differences in coordinate systems. A byproduct of this method is a means to locate dynamical motifs on low-dimensional manifolds embedded within higher-dimensional systems. We verified DFORM's ability to identify linear and nonlinear coordinate transformations using canonical topologically equivalent systems, RNNs, and systems related by nonlinear flows. DFORM was also shown to provide a quantification of similarity between topologically distinct systems. We then demonstrated that DFORM can locate important dynamical motifs including invariant manifolds and saddle limit sets within high-dimensional models. Finally, using a set of RNN models trained on human functional MRI (fMRI) recordings, we illustrated that DFORM can identify limit cycles from high-dimensional data-driven models, which agreed well with prior numerical analysis."}
{"id": "2512.19419", "pdf": "https://arxiv.org/pdf/2512.19419", "abs": "https://arxiv.org/abs/2512.19419", "authors": ["Tomáš Pikálek", "Miroslav Stibůrek", "Tereza Tučková", "Petra Kolbábková", "Sergey Turtaev", "Jana Krejčí", "Petra Ondráčková", "Hana Uhlířová", "Tomáš Čižmár"], "title": "Hair-thin confocal fluorescence endo-microscopy for deep-brain in-vivo imaging", "categories": ["physics.optics", "q-bio.NC"], "comment": "11 pages (3 figures) + 6 pages of Supplementary information (6 figures, 11 media)", "summary": "Confocal and multi-photon microscopy are widely used for in-vivo fluorescence imaging of biological tissues such as the brain, offering non-invasive access up to ~1 mm depth without major loss in performance. A recently-developed alternative is holographic endoscopy, which exploits controlled light transport through hair-thin optical fibres. With minimal invasiveness, it provides observations at comparable spatial resolution, while extending its applicability to unprecedented depths. It has been used to resolve details of sub-cellular structural connectivity, record neuronal signalling, and monitor blood flow from the deepest locations of the living brain. Yet, its use, particularly in densely labelled brain regions, has so far been constrained by significant contrast loss, primarily due to the absence of a practical mechanism for rejecting out-of-focus fluorescence light -- a capability inherently provided by confocal and multi-photon microscopy. Exploring opportunities in the structure of light modes of different MMF types we identify the possibility of achieving an analogue to confocal fluorescence microscopy through MMF-based endoscopes. Using a novel composite fibre probe that combines graded-index and step-index MMFs, we enable spatially resolved signal collection and selective rejection of out-of-focus light. This confocal filtering significantly enhances image contrast and resolution by suppressing background and off-plane signals. We demonstrate improved imaging performance on fine structural connectivity and intracellular calcium signalling in living mouse brain."}
