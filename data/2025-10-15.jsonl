{"id": "2510.12059", "pdf": "https://arxiv.org/pdf/2510.12059", "abs": "https://arxiv.org/abs/2510.12059", "authors": ["Svetlana Poznanović", "Owen Cardwell", "Christine Heitsch"], "title": "An Efficient Algorithm for Exploring RNA Branching Conformations under the Nearest-Neighbor Thermodynamic Model", "categories": ["q-bio.BM"], "comment": null, "summary": "Background: In the Nearest-Neighbor Thermodynamic Model, a standard approach\nfor RNA secondary structure prediction, the energy of the multiloops is modeled\nusing a linear entropic penalty governed by three branching parameters.\nAlthough these parameters are typically fixed, recent work has shown that\nreparametrizing the multiloop score and considering alternative branching\nconformations can lead to significantly better structure predictions. However,\nprior approaches for exploring the alternative branching structures were\ncomputationally inefficient for long sequences.\n  Results: We present a novel algorithm that partitions the parameter space,\nidentifying all distinct branching structures (optimal under different\nbranching parameters) for a given RNA sequence using the fewest possible\nminimum free energy computations. Our method efficiently computes the full\nparameter-space partition and the associated optimal structures, enabling a\ncomprehensive evaluation of the structural landscape across parameter choices.\nWe apply this algorithm to the Archive II benchmarking dataset, assessing the\nmaximum attainable prediction accuracy for each sequence under the\nreparameterized multiloop model. We find that the potential for improvement\nover default predictions is substantial in many cases, and that the optimal\nprediction accuracy is highly sensitive to auxiliary modeling decisions, such\nas the treatment of lonely base pairs and dangling ends.\n  Conclusion: Our results support the hypothesis that the conventional choice\nof multiloop parameters may limit prediction accuracy and that exploring\nalternative parameterizations is both tractable and worthwhile. The efficient\npartitioning algorithm we introduce makes this exploration feasible for longer\nsequences and larger datasets. Furthermore, we identify several open challenges\nin identifying the optimal structure."}
{"id": "2510.11726", "pdf": "https://arxiv.org/pdf/2510.11726", "abs": "https://arxiv.org/abs/2510.11726", "authors": ["Zhaokang Liang", "Shuyang Zhuang", "Xiaoran Jiao", "Weian Mao", "Hao Chen", "Chunhua Shen"], "title": "scPPDM: A Diffusion Model for Single-Cell Drug-Response Prediction", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "This paper introduces the Single-Cell Perturbation Prediction Diffusion Model\n(scPPDM), the first diffusion-based framework for single-cell drug-response\nprediction from scRNA-seq data. scPPDM couples two condition channels,\npre-perturbation state and drug with dose, in a unified latent space via\nnon-concatenative GD-Attn. During inference, factorized classifier-free\nguidance exposes two interpretable controls for state preservation and\ndrug-response strength and maps dose to guidance magnitude for tunable\nintensity. Evaluated on the Tahoe-100M benchmark under two stringent regimes,\nunseen covariate combinations (UC) and unseen drugs (UD), scPPDM sets new\nstate-of-the-art results across log fold-change recovery, delta correlations,\nexplained variance, and DE-overlap. Representative gains include\n+36.11%/+34.21% on DEG logFC-Spearman/Pearson in UD over the second-best model.\nThis control interface enables transparent what-if analyses and dose tuning,\nreducing experimental burden while preserving biological specificity."}
{"id": "2510.11924", "pdf": "https://arxiv.org/pdf/2510.11924", "abs": "https://arxiv.org/abs/2510.11924", "authors": ["Ji Xia", "Yizi Zhang", "Shuqi Wang", "Genevera I. Allen", "Liam Paninski", "Cole Lincoln Hurwitz", "Kenneth D. Miller"], "title": "Inpainting the Neural Picture: Inferring Unrecorded Brain Area Dynamics from Multi-Animal Datasets", "categories": ["q-bio.NC", "stat.AP", "stat.ML"], "comment": null, "summary": "Characterizing interactions between brain areas is a fundamental goal of\nsystems neuroscience. While such analyses are possible when areas are recorded\nsimultaneously, it is rare to observe all combinations of areas of interest\nwithin a single animal or recording session. How can we leverage multi-animal\ndatasets to better understand multi-area interactions? Building on recent\nprogress in large-scale, multi-animal models, we introduce NeuroPaint, a masked\nautoencoding approach for inferring the dynamics of unrecorded brain areas. By\ntraining across animals with overlapping subsets of recorded areas, NeuroPaint\nlearns to reconstruct activity in missing areas based on shared structure\nacross individuals. We train and evaluate our approach on synthetic data and\ntwo multi-animal, multi-area Neuropixels datasets. Our results demonstrate that\nmodels trained across animals with partial observations can successfully\nin-paint the dynamics of unrecorded areas, enabling multi-area analyses that\ntranscend the limitations of any single experiment."}
{"id": "2510.11982", "pdf": "https://arxiv.org/pdf/2510.11982", "abs": "https://arxiv.org/abs/2510.11982", "authors": ["Pratyusa Datta", "Philippe Lemey", "Marc A. Suchard"], "title": "Inhomogeneous continuous-time Markov chains to infer flexible time-varying evolutionary rates", "categories": ["stat.ME", "q-bio.PE"], "comment": "24 pages, 11 figures", "summary": "Reconstructing evolutionary histories and estimating the rate of evolution\nfrom molecular sequence data is of central importance in evolutionary biology\nand infectious disease research. We introduce a flexible Bayesian phylogenetic\ninference framework that accommodates changing evolutionary rates over time by\nmodeling sequence character substitution processes as inhomogeneous\ncontinuous-time Markov chains (ICTMCs) acting along the unknown phylogeny,\nwhere the rate remains as an unknown, positive and integrable function of time.\nThe integral of the rate function appears in the finite-time transition\nprobabilities of the ICTMCs that must be efficiently computed for all branches\nof the phylogeny to evaluate the observed data likelihood. Circumventing\ncomputational challenges that arise from a fully nonparametric function, we\nsuccessfully parameterize the rate function as piecewise constant with a large\nnumber of epochs that we call the polyepoch clock model. This makes the\ntransition probability computation relatively inexpensive and continues to\nflexibly capture rate change over time. We employ a Gaussian Markov random\nfield prior to achieve temporal smoothing of the estimated rate function.\nHamiltonian Monte Carlo sampling enabled by scalable gradient evaluation under\nthis model makes our framework computationally efficient. We assess the\nperformance of the polyepoch clock model in recovering the true timescales and\nrates through simulations under two different evolutionary scenarios. We then\napply the polyepoch clock model to examine the rates of West Nile virus, Dengue\nvirus and influenza A/H3N2 evolution, and estimate the time-varying rate of\nSARS-CoV-2 spread in Europe in 2020."}
{"id": "2510.11748", "pdf": "https://arxiv.org/pdf/2510.11748", "abs": "https://arxiv.org/abs/2510.11748", "authors": ["Huw Day", "Nina C. Snaith"], "title": "Thinned COE random matrix models for DNA replication", "categories": ["q-bio.OT", "math-ph", "math.MP"], "comment": null, "summary": "This paper details an observation that for more primitive organisms, such as\nsome yeasts, the statistical distribution of the origins of replication\nsometimes looks remarkably like the distribution of eigenvalues from the\nCircular Orthogonal Ensemble (COE) of random matrices. This does not hold for\nmore complex organisms, but a uniform thinning of the COE eigenvalues (which\ninterpolates between the COE and uncorrelated, Poisson statistics) gives a\nplatform to investigate characteristics of replication origin distribution in\nother species where data is available."}
{"id": "2510.12384", "pdf": "https://arxiv.org/pdf/2510.12384", "abs": "https://arxiv.org/abs/2510.12384", "authors": ["Huifa Li", "Feilong Tang", "Haochen Xue", "Yulong Li", "Xinlin Zhuang", "Bin Zhang", "Eran Segal", "Imran Razzak"], "title": "Phenome-Wide Multi-Omics Integration Uncovers Distinct Archetypes of Human Aging", "categories": ["q-bio.GN", "cs.AI"], "comment": null, "summary": "Aging is a highly complex and heterogeneous process that progresses at\ndifferent rates across individuals, making biological age (BA) a more accurate\nindicator of physiological decline than chronological age. While previous\nstudies have built aging clocks using single-omics data, they often fail to\ncapture the full molecular complexity of human aging. In this work, we\nleveraged the Human Phenotype Project, a large-scale cohort of 12,000 adults\naged 30--70 years, with extensive longitudinal profiling that includes\nclinical, behavioral, environmental, and multi-omics datasets -- spanning\ntranscriptomics, lipidomics, metabolomics, and the microbiome. By employing\nadvanced machine learning frameworks capable of modeling nonlinear biological\ndynamics, we developed and rigorously validated a multi-omics aging clock that\nrobustly predicts diverse health outcomes and future disease risk. Unsupervised\nclustering of the integrated molecular profiles from multi-omics uncovered\ndistinct biological subtypes of aging, revealing striking heterogeneity in\naging trajectories and pinpointing pathway-specific alterations associated with\ndifferent aging patterns. These findings demonstrate the power of multi-omics\nintegration to decode the molecular landscape of aging and lay the groundwork\nfor personalized healthspan monitoring and precision strategies to prevent\nage-related diseases."}
{"id": "2510.11743", "pdf": "https://arxiv.org/pdf/2510.11743", "abs": "https://arxiv.org/abs/2510.11743", "authors": ["Timo Jakumeit", "Bastian Heinlein", "Leonie Richter", "Sebastian Lotter", "Robert Schober", "Maximilian Schäfer"], "title": "Mixture of Inverse Gaussians for Hemodynamic Transport (MIGHT) in Vascular Networks", "categories": ["q-bio.QM", "cs.ET"], "comment": "8 pages, 5 figures. Submitted to IEEE International Conference on\n  Communications (ICC) 2026. This version includes extended proofs compared to\n  the conference submission", "summary": "Synthetic molecular communication (MC) in the cardiovascular system (CVS) is\na key enabler for many envisioned medical applications in the human body, such\nas targeted drug delivery, early cancer detection, and continuous health\nmonitoring. The design of MC systems for such applications requires suitable\nmodels for the signaling molecule propagation through complex vessel networks\n(VNs). Existing theoretical models offer limited analytical tractability and\nlack closed-form solutions, making the analysis of large-scale VNs either\ninfeasible or not insightful. To overcome these limitations, in this paper, we\npropose a novel closed-form physical model, termed MIGHT, for\nadvection-diffusion-driven transport of signaling molecules through complex\nVNs. The model represents the received molecule flux as a weighted sum of\ninverse Gaussian (IG) distributions, parameterized by physical properties of\nthe network. The proposed model is validated by comparison with an existing\nconvolution-based model and finite-element simulations. Further, we show that\nthe model can be applied for the reduction of large VNs to simplified\nrepresentations preserving the essential transport dynamics and for estimating\nrepresentative VN based on received signals from unknown VNs."}
{"id": "2510.12141", "pdf": "https://arxiv.org/pdf/2510.12141", "abs": "https://arxiv.org/abs/2510.12141", "authors": ["Sabine Muzellec", "Yousif Kashef Alghetaa", "Simon Kornblith", "Kohitij Kar"], "title": "MAPS: Masked Attribution-based Probing of Strategies- A computational framework to align human and model explanations", "categories": ["q-bio.NC", "cs.CV"], "comment": null, "summary": "Human core object recognition depends on the selective use of visual\ninformation, but the strategies guiding these choices are difficult to measure\ndirectly. We present MAPS (Masked Attribution-based Probing of Strategies), a\nbehaviorally validated computational tool that tests whether explanations\nderived from artificial neural networks (ANNs) can also explain human vision.\nMAPS converts attribution maps into explanation-masked images (EMIs) and\ncompares image-by-image human accuracies on these minimal images with limited\npixel budgets with accuracies on the full stimuli. MAPS provides a principled\nway to evaluate and choose among competing ANN interpretability methods. In\nsilico, EMI-based behavioral similarity between models reliably recovers the\nground-truth similarity computed from their attribution maps, establishing\nwhich explanation methods best capture the model's strategy. When applied to\nhumans and macaques, MAPS identifies ANN-explanation combinations whose\nexplanations align most closely with biological vision, achieving the\nbehavioral validity of Bubble masks while requiring far fewer behavioral\ntrials. Because it needs only access to model attributions and a modest set of\nbehavioral data on the original images, MAPS avoids exhaustive psychophysics\nwhile offering a scalable tool for adjudicating explanations and linking human\nbehavior, neural activity, and model decisions under a common standard."}
{"id": "2510.12614", "pdf": "https://arxiv.org/pdf/2510.12614", "abs": "https://arxiv.org/abs/2510.12614", "authors": ["Eric Alejandro Rozan", "Mario Ignacio Simoy", "Sebastian Bouzat", "Marcelo Nestor Kuperman"], "title": "Modeling Epidemics on Multiplex Networks: Epidemic Threshold and Basic Reproduction Number", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "nlin.AO", "q-bio.PE"], "comment": "22 pages, 7 figures", "summary": "Accurate epidemic forecasting requires models that account for the layered\nand heterogeneous nature of real social interactions. The basic reproduction\nnumber $\\mathcal R_0$ calculated from models that assume homogeneous mixing or\nsingle-layer contact structures have limited applicability to complex social\nsystems. Here, we propose an expression of $\\mathcal R_0$ in the context of\nmultiplex networks, enabling the analysis of disease transmission across\nmultiple social layers.\n  We adapt the Degree-Based Mean-Field (DBMF) SIR model for single-layered\ncomplex networks to the multiplex setting, where each layer has its own degree\ndistribution and infection rate. Using the Next Generation Matrix method, we\nderive an analytical expression for the basic reproduction number $\\mathcal\nR_0$. Numerical integration of the multiplex DBMF equations shows that\n$\\mathcal R_0 = 1$ marks the epidemic threshold and governs the functional\ndependence of key outbreak indicators. In addition to the exact result for the\n$\\mathcal R_0$, we provide an approximation denoted as $\\tau$, which is easier\nto compute and more straightforward to interpret in terms of the parameters of\nthe system, and shares most of the expected properties of the basic\nreproduction number.\n  Stochastic agent-based simulations confirm these results, demonstrating a\ndirect correspondence between $\\tau$ and the average number of secondary\ninfections in the early epidemic phase, in line with the interpretation of\n$\\mathcal R_0$.\n  This research provides a robust generalization of $\\mathcal R_0$ for layered\ncontact structures, offering a more realistic basis for epidemic forecasting\nand the design of intervention strategies."}
{"id": "2510.12617", "pdf": "https://arxiv.org/pdf/2510.12617", "abs": "https://arxiv.org/abs/2510.12617", "authors": ["Davide Greco", "Konrad Rawlik"], "title": "Same model, better performance: the impact of shuffling on DNA Language Models benchmarking", "categories": ["q-bio.GN", "cs.LG"], "comment": null, "summary": "Large Language Models are increasingly popular in genomics due to their\npotential to decode complex biological sequences. Hence, researchers require a\nstandardized benchmark to evaluate DNA Language Models (DNA LMs) capabilities.\nHowever, evaluating DNA LMs is a complex task that intersects genomic's\ndomain-specific challenges and machine learning methodologies, where seemingly\nminor implementation details can significantly compromise benchmark validity.\nWe demonstrate this through BEND (Benchmarking DNA Language Models), where\nhardware-dependent hyperparameters -- number of data loading workers and buffer\nsizes -- create spurious performance variations of up to 4% for identical\nmodels. The problem stems from inadequate data shuffling interacting with\ndomain specific data characteristics. Experiments with three DNA language\nmodels (HyenaDNA, DNABERT-2, ResNet-LM) show these artifacts affect both\nabsolute performance and relative model rankings. We propose a simple solution:\npre-shuffling data before storage eliminates hardware dependencies while\nmaintaining efficiency. This work highlights how standard ML practices can\ninteract unexpectedly with domain-specific data characteristics, with broader\nimplications for benchmark design in specialized domains."}
{"id": "2510.11750", "pdf": "https://arxiv.org/pdf/2510.11750", "abs": "https://arxiv.org/abs/2510.11750", "authors": ["Sazan Mahbub", "Souvik Kundu", "Eric P. Xing"], "title": "PRISM: Enhancing Protein Inverse Folding through Fine-Grained Retrieval on Structure-Sequence Multimodal Representations", "categories": ["q-bio.QM", "cs.LG"], "comment": null, "summary": "Designing protein sequences that fold into a target three-dimensional\nstructure, known as the inverse folding problem, is central to protein\nengineering but remains challenging due to the vast sequence space and the\nimportance of local structural constraints. Existing deep learning approaches\nachieve strong recovery rates, yet they lack explicit mechanisms to reuse\nfine-grained structure-sequence patterns that are conserved across natural\nproteins. We present PRISM, a multimodal retrieval-augmented generation\nframework for inverse folding that retrieves fine-grained representations of\npotential motifs from known proteins and integrates them with a hybrid\nself-cross attention decoder. PRISM is formulated as a latent-variable\nprobabilistic model and implemented with an efficient approximation, combining\ntheoretical grounding with practical scalability. Across five benchmarks\n(CATH-4.2, TS50, TS500, CAMEO 2022, and the PDB date split), PRISM establishes\nnew state of the art in both perplexity and amino acid recovery, while also\nimproving foldability metrics (RMSD, TM-score, pLDDT), demonstrating that\nfine-grained multimodal retrieval is a powerful and efficient paradigm for\nprotein sequence design."}
{"id": "2510.12228", "pdf": "https://arxiv.org/pdf/2510.12228", "abs": "https://arxiv.org/abs/2510.12228", "authors": ["Shunsuke Onoo", "Yoshihiro Nagano", "Yukiyasu Kamitani"], "title": "Readout Representation: Redefining Neural Codes by Input Recovery", "categories": ["q-bio.NC"], "comment": null, "summary": "Sensory representation is typically understood through a hierarchical-causal\nframework where progressively abstract features are extracted sequentially.\nHowever, this causal view fails to explain misrepresentation, a phenomenon\nbetter handled by an informational view based on decodable content. This\ncreates a tension: how does a system that abstracts away details still preserve\nthe fine-grained information needed for downstream functions? We propose\nreadout representation to resolve this, defining representation by the\ninformation recoverable from features rather than their causal origin.\nEmpirically, we show that inputs can be accurately reconstructed even from\nheavily perturbed mid-level features, demonstrating that a single input\ncorresponds to a broad, redundant region of feature space, challenging the\ncausal mapping perspective. To quantify this property, we introduce\nrepresentation size, a metric linked to model robustness and representational\nredundancy. Our framework offers a new lens for analyzing how both biological\nand artificial neural systems learn complex features while maintaining robust,\ninformation-rich representations of the world."}
{"id": "2510.11752", "pdf": "https://arxiv.org/pdf/2510.11752", "abs": "https://arxiv.org/abs/2510.11752", "authors": ["Zhiyu Wang", "Bingxin Zhou", "Jing Wang", "Yang Tan", "Weishu Zhao", "Pietro Liò", "Liang Hong"], "title": "Fast and Interpretable Protein Substructure Alignment via Optimal Transport", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Proteins are essential biological macromolecules that execute life functions.\nLocal motifs within protein structures, such as active sites, are the most\ncritical components for linking structure to function and are key to\nunderstanding protein evolution and enabling protein engineering. Existing\ncomputational methods struggle to identify and compare these local structures,\nwhich leaves a significant gap in understanding protein structures and\nharnessing their functions. This study presents PLASMA, the first deep learning\nframework for efficient and interpretable residue-level protein substructure\nalignment. We reformulate the problem as a regularized optimal transport task\nand leverage differentiable Sinkhorn iterations. For a pair of input protein\nstructures, PLASMA outputs a clear alignment matrix with an interpretable\noverall similarity score. Through extensive quantitative evaluations and three\nbiological case studies, we demonstrate that PLASMA achieves accurate,\nlightweight, and interpretable residue-level alignment. Additionally, we\nintroduce PLASMA-PF, a training-free variant that provides a practical\nalternative when training data are unavailable. Our method addresses a critical\ngap in protein structure analysis tools and offers new opportunities for\nfunctional annotation, evolutionary studies, and structure-based drug design.\nReproducibility is ensured via our official implementation at\nhttps://github.com/ZW471/PLASMA-Protein-Local-Alignment.git."}
{"id": "2510.12751", "pdf": "https://arxiv.org/pdf/2510.12751", "abs": "https://arxiv.org/abs/2510.12751", "authors": ["Junjie Wu", "Benjamin B Risk", "Taylor A James", "Nicholas Seyfried", "David W Loring", "Felicia C Goldstein", "Allan I Levey", "James J Lah", "Deqiang Qiu"], "title": "Non-linear associations of amyloid-$β$ with resting-state functional networks and their cognitive relevance in a large community-based cohort of cognitively normal older adults", "categories": ["q-bio.NC"], "comment": null, "summary": "Background: Non-linear alterations in brain network connectivity may\nrepresent early neural signatures of Alzheimer's disease (AD) pathology in\ncognitively normal older adults. Understanding these changes and their\ncognitive relevance could provide sensitive biomarkers for early detection.\nMost prior studies recruited participants from memory clinics, often with\nsubjective memory concerns, limiting generalizability.\n  Methods: We examined 14 large-scale functional brain networks in 968\ncognitively normal older adults recruited from the community using\nresting-state functional MRI, cerebrospinal fluid (CSF) biomarkers\n(amyloid-$\\beta$ 1-42 [A$\\beta$], total tau, phosphorylated tau 181), and\nneuropsychological assessments. Functional networks were identified using group\nindependent component analysis.\n  Results: Inverted U-shaped associations between CSF A$\\beta$ and functional\nconnectivity were observed in the precuneus network and ventral default mode\nnetwork (DMN), but not in the dorsal DMN, indicating network-specific\nvulnerability to early amyloid pathology. Higher connectivity in\nA$\\beta$-related networks, including dorsal and ventral DMN, precuneus, and\nposterior salience networks, was associated with better visual memory,\nvisuospatial, and executive performance. No significant relationships were\nobserved between CSF tau and functional connectivity.\n  Conclusions: Using a large, community-based cohort, we demonstrate that\nnon-linear alterations in functional connectivity occur in specific networks\neven during the asymptomatic phase of AD. Moreover, A$\\beta$-related network\nconnectivity is cognitively relevant, highlighting functional brain networks as\npromising imaging markers for early detection and prognosis of AD."}
{"id": "2510.11756", "pdf": "https://arxiv.org/pdf/2510.11756", "abs": "https://arxiv.org/abs/2510.11756", "authors": ["Shudong Sun", "Aki Hara", "Laurel Johnstone", "Brian Hallmark", "Joseph C. Watkins", "Cynthia A. Thomson", "Susan M. Schembre", "Susan Sergeant", "Jason Umans", "Guang Yao", "Hao Helen Zhang", "Floyd H. Chilton"], "title": "Optimal Pair Matching Combined with Machine Learning Predicts a Significant Reduction in Myocardial Infarction Risk in African Americans following Omega-3 Fatty Acid Supplementation", "categories": ["q-bio.QM", "stat.AP"], "comment": null, "summary": "Conflicting clinical trial results on omega-3 highly unsaturated fatty acids\n(n-3 HUFA) have prompted uncertainty about their cardioprotective effects.\nWhile the VITAL trial found no overall cardiovascular benefit from n-3 HUFA\nsupplementation, its substantial African American (AfAm) enrollment provided a\nunique opportunity to explore racial differences in response to n-3 HUFA\nsupplementation. The current observational study aimed to simulate randomized\nclinical trial (RCT) conditions by matching 3,766 AfAm and 15,553 non-Hispanic\nWhite (NHW) individuals from the VITAL trial utilizing propensity score\nmatching to address the limitations related to differences in confounding\nvariables between the two groups. Within matched groups (3,766 AfAm and 3,766\nNHW), n-3 HUFA supplementation's impact on myocardial infarction (MI), stroke,\nand cardiovascular disease (CVD) mortality was assessed. A weighted decision\ntree analysis revealed belonging to the n-3 supplementation group as the most\nsignificant predictor of MI among AfAm but not NHW. Further logistic regression\nusing the LASSO method and bootstrap estimation of standard errors indicated\nn-3 supplementation significantly lowered MI risk in AfAm (OR 0.17, 95% CI\n[0.048, 0.60]), with no such effect in NHW. This study underscores the critical\nneed for future RCT to explore racial disparities in MI risk associated with\nn-3 HUFA supplementation and highlights potential causal differences between\nsupplementation health outcomes in AfAm versus NHW populations."}
{"id": "2510.11959", "pdf": "https://arxiv.org/pdf/2510.11959", "abs": "https://arxiv.org/abs/2510.11959", "authors": ["Allison Powell", "Paramahansa Pramanik"], "title": "Genomic Influence of a Key Transcription Factor in Male Glandular Malignancy", "categories": ["q-bio.QM"], "comment": "36 pages, 13 figures, 1 table", "summary": "Prostate cancer (PCa) remains a significant global health concern among men,\nparticularly due to the lethality of its more aggressive variants. Despite\ntherapeutic advancements that have enhanced survival for many patients, high\ngrade PCa continues to contribute substantially to cancer related mortality.\nEmerging evidence points to the MYB proto-oncogene as a critical factor in\npromoting tumor progression, therapeutic resistance, and disease relapse.\nNotably, differential expression patterns have been observed, with markedly\nelevated MYB levels in tumor tissues from Black men relative to their White\ncounterparts potentially offering insight into documented racial disparities in\nclinical outcomes. This study investigates the association between MYB\nexpression and key oncogenic features, including androgen receptor (AR)\nsignaling, disease progression, and the risk of biochemical recurrence.\nEmploying a multimodal approach that integrates histopathological examination,\nquantitative digital imaging, and analyses of public transcriptomic datasets,\nour findings suggest that MYB overexpression is strongly linked to adverse\nprognosis. These results underscore MYB's potential as a prognostic biomarker\nand as a candidate for the development of individualized therapeutic\nstrategies."}
{"id": "2510.12772", "pdf": "https://arxiv.org/pdf/2510.12772", "abs": "https://arxiv.org/abs/2510.12772", "authors": ["Sergio Serrano de Haro Iváñez", "Joshua W. Moore", "Lucile Grzesiak", "Eoghan J. Mullholand", "Heather Harrington", "Simon J. Leedham", "Helen M. Byrne"], "title": "TopROI: A topology-informed network approach for tissue partitioning", "categories": ["q-bio.QM", "math.AT"], "comment": "28 pages, 11 Figures", "summary": "Mammalian tissue architecture is central to biological function, and its\ndisruption is a hallmark of disease. Medical imaging techniques can generate\nlarge point cloud datasets that capture changes in the cellular composition of\nsuch tissues with disease progression. However, regions of interest (ROIs) are\nusually defined by quadrat-based methods that ignore intrinsic structure and\nrisk fragmenting meaningful features. Here, we introduce TopROI, a\ntopology-informed, network-based method for partitioning point clouds into ROIs\nthat preserves both local geometry and higher-order architecture. TopROI\nintegrates geometry-informed networks with persistent homology, combining cell\nneighbourhoods and multiscale cycles to guide community detection. Applied to\nsynthetic point clouds that mimic glandular structure, TopROI outperforms\nquadrat-based and purely geometric partitions by maintaining biologically\nplausible ROI geometry and better preserving ground-truth structures. Applied\nto cellular point clouds obtained from human colorectal cancer biopsies, TopROI\ngenerates ROIs that preserve crypt-like structures and enable persistent\nhomology analysis of individual regions. This study reveals a continuum of\narchitectural changes from healthy mucosa to carcinoma, reflecting progressive\ndisorganisation in tissue structure. TopROI thus provides a principled and\nflexible framework for defining biologically meaningful ROIs in large point\nclouds, enabling more accurate quantification of tissue organization and new\ninsights into structural changes associated with disease progression."}
{"id": "2510.12776", "pdf": "https://arxiv.org/pdf/2510.12776", "abs": "https://arxiv.org/abs/2510.12776", "authors": ["Selim Romero", "Vignesh Kumar", "Robert S. Chapkin", "James J. Cai"], "title": "A Quantum Generative Framework for Modeling Single-Cell Transcriptomes with Gene-Gene and Cell-Cell Interactions", "categories": ["q-bio.QM", "cs.ET", "physics.bio-ph", "q-bio.GN"], "comment": null, "summary": "Single-cell RNA sequencing (scRNA-seq) data simulation is limited by\nclassical methods that rely on linear correlations, failing to capture the\nintrinsic, nonlinear dependencies and the simultaneous gene-gene and cell-cell\ninteractions. We introduce qSimCells, a novel hybrid quantum-classical\nsimulator that leverages quantum entanglement to model single-cell\ntranscriptomes. The core innovation is a quantum kernel that uses a\nparameterized quantum circuit with CNOT gates to encode complex, nonlinear gene\nregulatory network (GRN) and cell-cell communication topologies with explicit\ndirectionality (causality). The synthetic data exhibits non-classical\ndependencies that challenge standard analysis. We demonstrated that classical\ncorrelation methods (Pearson and Spearman) failed to reconstruct the complete\nprogrammed quantum causal paths, instead reporting spurious statistical\nartifacts driven by high base-gene expression probabilities. Applying\nCellChat2.0 to the simulated cell-cell communication validated the true\nmechanistic links by showing a robust, relative increase in communication\nprobability (up to 75-fold) only when the quantum entanglement was active. This\nwork confirms that the quantum kernel is essential for creating high-fidelity\nground truth data, highlighting the need for advanced inference techniques to\ncapture the complex, non-classical dependencies inherent in gene regulation."}
{"id": "2510.12577", "pdf": "https://arxiv.org/pdf/2510.12577", "abs": "https://arxiv.org/abs/2510.12577", "authors": ["Hasi Hays", "William Richardson"], "title": "ECMSim: A high-performance web simulation of cardiac ECM remodeling through integrated ODE-based signaling and diffusion", "categories": ["q-bio.MN", "cs.ET", "physics.bio-ph", "q-bio.QM"], "comment": null, "summary": "Extracellular matrix (ECM) remodeling is central to a wide variety of healthy\nand diseased tissue processes. Unfortunately, predicting ECM remodeling under\nvarious chemical and mechanical conditions has proven to be excessively\nchallenging, due in part to its complex regulation by intracellular and\nextracellular molecular reaction networks that are spatially and temporally\ndynamic. We introduce ECMSim, which is a highly interactive, real-time, and web\napplication designed to simulate heterogeneous matrix remodeling. The current\nmodel simulates cardiac scar tissue with configurable input conditions using a\nlarge-scale model of the cardiac fibroblast signaling network. Cardiac fibrosis\nis a major component of many forms of heart failure. ECMSim simulates over 1.3\nmillion equations simultaneously in real time that include more than 125\nspecies and more than 200 edges in each cell in a 100*100 spatial array (10,000\ncells), which accounts for inputs, receptors, intracellular signaling cascades,\nECM production, and feedback loops, as well as molecular diffusion. The\nalgorithm is represented by a set of ordinary differential equations (ODEs)\nthat are coupled with ECM molecular diffusion. The equations are solved on\ndemand using compiled C++ and the WebAssembly standard. The platform includes\nbrush-style cell selection to target a subset of cells with adjustable input\nmolecule concentrations, parameter sliders to adjust parameters on demand, and\nmultiple coupled real-time visualizations of network dynamics at multiple\nscales. Implementing ECMSim in standard web technologies enables a fully\nfunctional application that combines real-time simulation, visual interaction,\nand model editing. The software enables the investigation of pathological or\nexperimental conditions, hypothetical scenarios, matrix remodeling, or the\ntesting of the effects of an experimental drug(s) with a target receptor."}
{"id": "2510.12719", "pdf": "https://arxiv.org/pdf/2510.12719", "abs": "https://arxiv.org/abs/2510.12719", "authors": ["Matthew Adrian", "Yunsie Chung", "Kevin Boyd", "Saee Paliwal", "Srimukh Prasad Veccham", "Alan C. Cheng"], "title": "Multitask finetuning and acceleration of chemical pretrained models for small molecule drug property prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Chemical pretrained models, sometimes referred to as foundation models, are\nreceiving considerable interest for drug discovery applications. The general\nchemical knowledge extracted from self-supervised training has the potential to\nimprove predictions for critical drug discovery endpoints, including on-target\npotency and ADMET properties. Multi-task learning has previously been\nsuccessfully leveraged to improve predictive models. Here, we show that\nenabling multitasking in finetuning of chemical pretrained graph neural network\nmodels such as Kinetic GROVER Multi-Task (KERMT), an enhanced version of the\nGROVER model, and Knowledge-guided Pre-training of Graph Transformer (KGPT)\nsignificantly improves performance over non-pretrained graph neural network\nmodels. Surprisingly, we find that the performance improvement from finetuning\nKERMT in a multitask manner is most significant at larger data sizes.\nAdditionally, we publish two multitask ADMET data splits to enable more\naccurate benchmarking of multitask deep learning methods for drug property\nprediction. Finally, we provide an accelerated implementation of the KERMT\nmodel on GitHub, unlocking large-scale pretraining, finetuning, and inference\nin industrial drug discovery workflows."}
{"id": "2510.12763", "pdf": "https://arxiv.org/pdf/2510.12763", "abs": "https://arxiv.org/abs/2510.12763", "authors": ["Saurabh Sihag", "Gonzalo Mateos", "Alejandro Ribeiro"], "title": "Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective", "categories": ["eess.SP", "cs.AI", "q-bio.QM"], "comment": "Accepted for publication in IEEE Signal Processing Magazine", "summary": "Neurodegeneration, characterized by the progressive loss of neuronal\nstructure or function, is commonly assessed in clinical practice through\nreductions in cortical thickness or brain volume, as visualized by structural\nMRI. While informative, these conventional approaches lack the statistical\nsophistication required to fully capture the spatially correlated and\nheterogeneous nature of neurodegeneration, which manifests both in healthy\naging and in neurological disorders. To address these limitations, brain age\ngap has emerged as a promising data-driven biomarker of brain health. The brain\nage gap prediction (BAGP) models estimate the difference between a person's\npredicted brain age from neuroimaging data and their chronological age. The\nresulting brain age gap serves as a compact biomarker of brain health, with\nrecent studies demonstrating its predictive utility for disease progression and\nseverity. However, practical adoption of BAGP models is hindered by their\nmethodological obscurities and limited generalizability across diverse clinical\npopulations. This tutorial article provides an overview of BAGP and introduces\na principled framework for this application based on recent advancements in\ngraph signal processing (GSP). In particular, we focus on graph neural networks\n(GNNs) and introduce the coVariance neural network (VNN), which leverages the\nanatomical covariance matrices derived from structural MRI. VNNs offer strong\ntheoretical grounding and operational interpretability, enabling robust\nestimation of brain age gap predictions. By integrating perspectives from GSP,\nmachine learning, and network neuroscience, this work clarifies the path\nforward for reliable and interpretable BAGP models and outlines future research\ndirections in personalized medicine."}
