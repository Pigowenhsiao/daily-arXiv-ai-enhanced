{"id": "2602.16255", "pdf": "https://arxiv.org/pdf/2602.16255", "abs": "https://arxiv.org/abs/2602.16255", "authors": ["Yiquan Wang"], "title": "Piecewise integrability of the discrete Hasimoto map for analytic prediction and design of helical peptides", "categories": ["q-bio.BM", "math-ph", "nlin.PS", "nlin.SI"], "comment": null, "summary": "The representation of protein backbone geometry through the discrete nonlinear Schrödinger equation provides a theoretical connection between biological structure and integrable systems. Although the global application of this framework is constrained by chiral degeneracies and non-local interactions we propose that helical peptides can be effectively modeled as piecewise integrable systems in which the discrete Hasimoto map remains applicable within specific geometric boundaries. We delineate these boundaries through an analytic characterization of the mapping between biochemical dihedral angles and Frenet frame parameters for a dataset of 50 helical peptide chains. We demonstrate that the transformation is information-preserving globally but ill-conditioned within the helical basin characterized by a median Jacobian condition number of 31 which suggests that the loss of chiral information arises primarily from local coordinate compression rather than topological singularities. We define a local integrability error $E[n]$ derived from the discrete dispersion relation to show that deviations from integrability are driven predominantly by torsion non-uniformity while curvature remains structurally rigid. This metric identifies integrable islands where the analytic dispersion relation predicts backbone coordinates with sub-angstrom accuracy yielding a median root-mean-square deviation of 0.77\\,Å and enables a segmentation strategy that isolates structural defects. We further indicate that the inverse design of peptide backbones is feasible within a quantitatively defined integrability zone where the design constraint reduces essentially to the control of torsion uniformity. These findings advance the Hasimoto formalism from a qualitative descriptor toward a precise quantitative framework for analyzing and designing local protein geometry within the limits of piecewise integrability."}
{"id": "2602.16504", "pdf": "https://arxiv.org/pdf/2602.16504", "abs": "https://arxiv.org/abs/2602.16504", "authors": ["Ashley Babjac", "Adrienne Hoarfrost"], "title": "GRIMM: Genetic stRatification for Inference in Molecular Modeling", "categories": ["q-bio.QM"], "comment": "9 pages, 1 figure, 2 tables, submitted to ISMB main conference proceedings 2026", "summary": "The vast majority of biological sequences encode unknown functions and bear little resemblance to experimentally characterized proteins, limiting both our understanding of biology and our ability to harness functional potential for the bioeconomy. Predicting enzyme function from sequence remains a central challenge in computational biology, complicated by low sequence diversity and imbalanced label support in publicly available datasets. Models trained on these data can overestimate performance and fail to generalize. To address this, we introduce GRIMM (Genetic stRatification for Inference in Molecular Modeling), a benchmark for enzyme function prediction that employs genetic stratification: sequences are clustered by similarity and clusters are assigned exclusively to training, validation, or test sets. This ensures that sequences from the same cluster do not appear in multiple partitions. GRIMM produces multiple test sets: a closed-set test with the same label distribution as training (Test-1) and an open-set test containing novel labels (Test-2), serving as a realistic out-of-distribution proxy for discovering novel enzyme functions. While demonstrated on enzymes, this approach is generalizable to any sequence-based classification task where inputs can be clustered by similarity. By formalizing a splitting strategy often used implicitly, GRIMM provides a unified and reproducible framework for closed- and open-set evaluation. The method is lightweight, requiring only sequence clustering and label annotations, and can be adapted to different similarity thresholds, data scales, and biological tasks. GRIMM enables more realistic evaluation of functional prediction models on both familiar and unseen classes and establishes a benchmark that more faithfully assesses model performance and generalizability."}
{"id": "2602.15957", "pdf": "https://arxiv.org/pdf/2602.15957", "abs": "https://arxiv.org/abs/2602.15957", "authors": ["Dan Adler"], "title": "Evolutionary Systems Thinking -- From Equilibrium Models to Open-Ended Adaptive Dynamics", "categories": ["q-bio.PE", "cs.NE", "econ.TH"], "comment": "17 pages, 5 figures", "summary": "Complex change is often described as \"evolutionary\" in economics, policy, and technology, yet most system dynamics models remain constrained to fixed state spaces and equilibrium-seeking behavior. This paper argues that evolutionary dynamics should be treated as a core system-thinking problem rather than as a biological metaphor. We introduce Stability-Driven Assembly (SDA) as a minimal, non-equilibrium framework in which stochastic interactions combined with differential persistence generate endogenous selection without genes, replication, or predefined fitness functions. In SDA, longer-lived patterns accumulate in the population, biasing future interactions and creating feedback between population composition and system dynamics. This feedback yields fitness-proportional sampling as an emergent property, realizing a natural genetic algorithm driven solely by stability. Using SDA, we demonstrate why equilibrium-constrained models, even when simulated numerically, cannot exhibit open-ended evolution: evolutionary systems require population-dependent, non-stationary dynamics in which structure and dynamics co-evolve. We conclude by discussing implications for system dynamics, economics, and policy modeling, and outline how agent-based and AI-enabled approaches may support evolutionary models capable of sustained novelty and structural emergence."}
{"id": "2602.16004", "pdf": "https://arxiv.org/pdf/2602.16004", "abs": "https://arxiv.org/abs/2602.16004", "authors": ["Nan Xu", "Xiaodi Zhang", "Wen-Ju Pan", "Jeremy L. Smith", "Eric H. Schumacher", "Jason W. Allen", "Vince D. Calhoun", "Shella D. Keilholz"], "title": "Time-Varying Directed Interactions in Functional Brain Networks: Modeling and Validation", "categories": ["q-bio.NC", "q-bio.QM"], "comment": null, "summary": "Understanding the dynamic nature of brain connectivity is critical for elucidating neural processing, behavior, and brain disorders. Traditional approaches such as sliding-window correlation (SWC) characterize time-varying undirected associations but do not resolve directional interactions, limiting inference about time-resolved information flow in brain networks. We introduce sliding-window prediction correlation (SWpC), which embeds a directional linear time-invariant (LTI) model within each sliding window to estimate time-varying directed functional connectivity (FC). SWpC yields two complementary descriptors of directed interactions: a strength measure (prediction correlation) and a duration measure (window-wise duration of information transfer). Using concurrent local field potential (LFP) and fMRI BOLD recordings from rat somatosensory cortices, we demonstrate stable directionality estimates in both LFP band-limited power and BOLD. Using Human Connectome Project (HCP) motor task fMRI, SWpC detects significant task-evoked changes in directed FC strength and duration and shows higher sensitivity than SWC for identifying task-evoked connectivity differences. Finally, in post-concussion vestibular dysfunction (PCVD), SWpC reveals reproducible vestibular-multisensory brain-state shifts and improves healthy-control vs subacute patient (HC-ST) discrimination using state-derived features. Together, these results show that SWpC provides biologically interpretable, time-resolved directed connectivity patterns across multimodal validation and clinical application settings, supporting both basic and translational neuroscience."}
{"id": "2602.16696", "pdf": "https://arxiv.org/pdf/2602.16696", "abs": "https://arxiv.org/abs/2602.16696", "authors": ["Huan Souza", "Pankaj Mehta"], "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks", "categories": ["q-bio.GN", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data."}
{"id": "2602.16004", "pdf": "https://arxiv.org/pdf/2602.16004", "abs": "https://arxiv.org/abs/2602.16004", "authors": ["Nan Xu", "Xiaodi Zhang", "Wen-Ju Pan", "Jeremy L. Smith", "Eric H. Schumacher", "Jason W. Allen", "Vince D. Calhoun", "Shella D. Keilholz"], "title": "Time-Varying Directed Interactions in Functional Brain Networks: Modeling and Validation", "categories": ["q-bio.NC", "q-bio.QM"], "comment": null, "summary": "Understanding the dynamic nature of brain connectivity is critical for elucidating neural processing, behavior, and brain disorders. Traditional approaches such as sliding-window correlation (SWC) characterize time-varying undirected associations but do not resolve directional interactions, limiting inference about time-resolved information flow in brain networks. We introduce sliding-window prediction correlation (SWpC), which embeds a directional linear time-invariant (LTI) model within each sliding window to estimate time-varying directed functional connectivity (FC). SWpC yields two complementary descriptors of directed interactions: a strength measure (prediction correlation) and a duration measure (window-wise duration of information transfer). Using concurrent local field potential (LFP) and fMRI BOLD recordings from rat somatosensory cortices, we demonstrate stable directionality estimates in both LFP band-limited power and BOLD. Using Human Connectome Project (HCP) motor task fMRI, SWpC detects significant task-evoked changes in directed FC strength and duration and shows higher sensitivity than SWC for identifying task-evoked connectivity differences. Finally, in post-concussion vestibular dysfunction (PCVD), SWpC reveals reproducible vestibular-multisensory brain-state shifts and improves healthy-control vs subacute patient (HC-ST) discrimination using state-derived features. Together, these results show that SWpC provides biologically interpretable, time-resolved directed connectivity patterns across multimodal validation and clinical application settings, supporting both basic and translational neuroscience."}
{"id": "2602.16059", "pdf": "https://arxiv.org/pdf/2602.16059", "abs": "https://arxiv.org/abs/2602.16059", "authors": ["Mike Steel", "Kristina Wicke", "Arne Mooers"], "title": "Properties of biodiversity indices that model future extinction risk", "categories": ["q-bio.PE"], "comment": "16 pages, 5 figures", "summary": "The loss of biodiversity due to the likely widespread extinction of species in the near future is a focus of current concern in conservation biology. One approach to measure the impact of this extinction is based on the predicted loss of phylogenetic diversity. These predictions have become a focus of the Zoological Society of London's 'EDGE2' program for quantifying biodiversity loss and involves considering the HED (heightened evolutionary distinctiveness) and HEDGE (heightened evolutionary distinctiveness and globally endangered) indices. Here, we show how to generalise the HED(GE) indices by expanding their application to more general settings (to phylogenetic networks, to feature diversity on discrete traits, and to arbitrary biodiversity measures). We provide a simple and explicit description of the mean and variance of such measures, and illustrate our results by an application to the phylogeny of all 27 extant Crocodilians. We also derive various equalities for feature diversity, and an inequality if species extinction rates are correlated with feature types."}
{"id": "2602.16584", "pdf": "https://arxiv.org/pdf/2602.16584", "abs": "https://arxiv.org/abs/2602.16584", "authors": ["Akhil Ramidi", "Kevin Scharp"], "title": "The Representational Alignment Hypothesis: Evidence for and Consequences of Invariant Semantic Structure Across Embedding Modalities", "categories": ["q-bio.NC"], "comment": "23 pages, 3 figures", "summary": "There is growing evidence that independently trained AI systems come to represent the world in the same way. In other words, independently trained embeddings from text, vision, audio, and neural signals share an underlying geometry. We call this the Representational Alignment Hypothesis (RAH) and investigate evidence for and consequences of this claim. The evidence is of two kinds: (i) internal structure comparison techniques, such as representational similarity analysis and topological data analysis, reveal matching relational patterns across modalities without explicit mapping; and (ii) methods based on cross-modal embedding alignment, which learn mappings between representation spaces, show that simple linear transformations can bring different embedding spaces into close correspondence, suggesting near-isomorphism. Taken together, the evidence suggests that, even after controlling for trivial commonalities inherent in standard data preprocessing and embedding procedures, a robust structural correspondence persists, hinting at an underlying organizational principle. Some have argued that this result shows that the shared structure is getting at a fundamental, Platonic level of reality. We argue that this conclusion is unjustified. Moreover, we aim to give the idea an alternative philosophical home, rooted in contemporary metasemantics (i.e., theories of what makes a representation and what makes something meaningful) and responses to the symbol grounding problem. We conclude by considering the scope of the RAH and proposing new ways of distinguishing semantic structures that are genuinely invariant from those that inevitably arise due to the fact that all our data is generated under human-specific conditions on Earth."}
{"id": "2602.16357", "pdf": "https://arxiv.org/pdf/2602.16357", "abs": "https://arxiv.org/abs/2602.16357", "authors": ["Sarkis Ter Martirosyan", "Xinyue Huang", "David Qin", "Anthony Yu", "Stanislav Emelianov"], "title": "Optical Inversion and Spectral Unmixing of Spectroscopic Photoacoustic Images with Physics-Informed Neural Networks", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Accurate estimation of the relative concentrations of chromophores in a spectroscopic photoacoustic (sPA) image can reveal immense structural, functional, and molecular information about physiological processes. However, due to nonlinearities and ill-posedness inherent to sPA imaging, concentration estimation is intractable. The Spectroscopic Photoacoustic Optical Inversion Autoencoder (SPOI-AE) aims to address the sPA optical inversion and spectral unmixing problems without assuming linearity. Herein, SPOI-AE was trained and tested on \\textit{in vivo} mouse lymph node sPA images with unknown ground truth chromophore concentrations. SPOI-AE better reconstructs input sPA pixels than conventional algorithms while providing biologically coherent estimates for optical parameters, chromophore concentrations, and the percent oxygen saturation of tissue. SPOI-AE's unmixing accuracy was validated using a simulated mouse lymph node phantom ground truth."}
{"id": "2602.16282", "pdf": "https://arxiv.org/pdf/2602.16282", "abs": "https://arxiv.org/abs/2602.16282", "authors": ["Yikang Lu", "Wenhao She", "Xiaofang Duan", "Junpyo Park"], "title": "Neutral species facilitate coexistence among cyclically competing species under birth and death processes", "categories": ["q-bio.PE", "physics.soc-ph"], "comment": "10 pages, 12 figures", "summary": "Natural birth and death are fundamental mechanisms of population dynamics in ecosystems and have played pivotal roles in shaping population dynamics. Nevertheless, in studies of cyclic competition systems governed by the rock-paper-scissors (RPS) game, these mechanisms have often been ignored in analyses of biodiversity. On the other hand, given the prevalence and profound impact on biodiversity, understanding how higher-order interactions (HOIs) can affect biodiversity is one of the most challenging issues, and thus HOIs have been continuously studied for their effects on biodiversity in systems of cyclic competing populations, with a focus on neutral species. However, in real ecosystems, species can evolve and die naturally or be preyed upon by predators, whereas previous studies have considered only classic reaction rules among three species with a neutral, nonparticipant species. To identify how neutral species can affect the biodiversity of the RPS system when species' natural birth and death are assumed, we consider a model of neutral species in higher-order interactions within the spatial RPS system, assuming birth-and-death processes. Extensive simulations show that when neutral species interfere positively, they dominate the available space, thereby reducing the proportion of other species. Conversely, when the interference is harmful, the density of competing species increases. In addition, unlike traditional RPS dynamics, biodiversity can be effectively maintained even in high-mobility regimes. Our study reaffirms the critical role of neutral species in preserving biodiversity."}
{"id": "2602.16072", "pdf": "https://arxiv.org/pdf/2602.16072", "abs": "https://arxiv.org/abs/2602.16072", "authors": ["Chenda Duan", "Yipeng Zhang", "Sotaro Kanai", "Yuanyi Ding", "Atsuro Daida", "Pengyue Yu", "Tiancheng Zheng", "Naoto Kuroda", "Shaun A. Hussain", "Eishi Asano", "Hiroki Nariai", "Vwani Roychowdhury"], "title": "Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": "Published as a conference paper at ICLR 2026", "summary": "Epilepsy affects over 50 million people worldwide, and one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom. Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows, however, remain constrained by labor-intensive manual review. At the same time, existing data-driven approaches are typically developed on single-center datasets that are inconsistent in format and metadata, lack standardized benchmarks, and rarely release pathological event annotations, creating barriers to reproducibility, cross-center validation, and clinical relevance. With extensive efforts to reconcile heterogeneous iEEG formats, metadata, and recordings across publicly available sources, we present $\\textbf{Omni-iEEG}$, a large-scale, pre-surgical iEEG resource comprising $\\textbf{302 patients}$ and $\\textbf{178 hours}$ of high-resolution recordings. The dataset includes harmonized clinical metadata such as seizure onset zones, resections, and surgical outcomes, all validated by board-certified epileptologists. In addition, Omni-iEEG provides over 36K expert-validated annotations of pathological events, enabling robust biomarker studies. Omni-iEEG serves as a bridge between machine learning and epilepsy research. It defines clinically meaningful tasks with unified evaluation metrics grounded in clinical priors, enabling systematic evaluation of models in clinically relevant settings. Beyond benchmarking, we demonstrate the potential of end-to-end modeling on long iEEG segments and highlight the transferability of representations pretrained on non-neurophysiological domains. Together, these contributions establish Omni-iEEG as a foundation for reproducible, generalizable, and clinically translatable epilepsy research. The project page with dataset and code links is available at omni-ieeg.github.io/omni-ieeg."}
{"id": "2602.16696", "pdf": "https://arxiv.org/pdf/2602.16696", "abs": "https://arxiv.org/abs/2602.16696", "authors": ["Huan Souza", "Pankaj Mehta"], "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks", "categories": ["q-bio.GN", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data."}
{"id": "2602.16447", "pdf": "https://arxiv.org/pdf/2602.16447", "abs": "https://arxiv.org/abs/2602.16447", "authors": ["Léo Régnier", "Paul Rochette", "Raphaël Laurenceau", "David Bikard", "Simona Cocco", "Rémi Monasson"], "title": "Evolutionary Advantage of Diversity-Generating Retroelements in Switching Environments", "categories": ["q-bio.PE", "cond-mat.stat-mech"], "comment": "Main text: 6 pages, 3 figures. Supplementary Materials: 22 pages, 14 figures", "summary": "Diversity-Generating Retroelements (DGRs) create rapid, targeted variation within specific genomic regions in phages and bacteria. They operate through stochastic retro-transcription of a template region (TR) into a variable region (VR), which typically encodes ligand-binding proteins. Despite their prevalence, the evolutionary conditions that maintain such hypermutating systems remain unclear. Here we introduce a two-timescale framework separating fast VR diversification from slow TR evolution, allowing the dynamics of DGR-controlled loci to be analytically understood from the TR design point of view. We quantity the fitness gain provided by the diversification mechanism of DGR in the presence of environmental switching with respect to standard mutagenesis. Our framework accounts for observed patterns of DGR activity in human-gut \\textit{Bacteroides} and clarifies when constitutive DGR activation is evolutionarily favored."}
{"id": "2602.16626", "pdf": "https://arxiv.org/pdf/2602.16626", "abs": "https://arxiv.org/abs/2602.16626", "authors": ["SungJun Cho", "Chetan Gohil", "Rukuang Huang", "Oiwi Parker Jones", "Mark W. Woolrich"], "title": "A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models", "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "comment": "15 pages, 10 figures, 1 table", "summary": "Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at https://github.com/OHBA-analysis/Cho2026_Tokenizer."}
{"id": "2602.16633", "pdf": "https://arxiv.org/pdf/2602.16633", "abs": "https://arxiv.org/abs/2602.16633", "authors": ["Youngji Jo", "Sileshi Sintayehu Sharbayta", "Bruno Buonomo"], "title": "Behavioral change models for infectious disease transmission: a systematic review (2020-2025)", "categories": ["q-bio.PE"], "comment": "23 pages, 3 tables, 3 figures", "summary": "Background: Human behavior shapes infectious disease dynamics, yet its integration into transmission models remains fragmented. Recent epidemics, particularly COVID-19, highlight the need for models capturing adaptation to perceived risk, social influence, and policy signals. This review synthesizes post-2020 models incorporating behavioral adaptation, examines their theoretical grounding, and evaluates how behavioral constructs modify transmission, vaccination, and compliance. Methods: Following PRISMA guidelines, we searched Scopus and PubMed (2020-2025), screening 1,274 records with citation chaining. We extracted data on disease context, country, modeling framework, behavioral mechanisms (prevalence-dependent, policy/media, imitation/social learning), and psychosocial constructs (personal threat, coping appraisal, barriers, social norms, cues to action). A total of 216 studies met inclusion criteria. Results: COVID-19 accounted for 73% of studies. Most used compartmental ODE models (81%) and focused on theoretical or U.S. settings. Behavioral change was mainly reactive: 47% applied prevalence-dependent feedback, 25% included awareness/media dynamics, and 19% relied on exogenous policy triggers. Game-theoretic or social learning approaches were rare (less or equal than 5%). Behavioral effects primarily modified contact or transmission rates (91%). Psychosocial constructs were unevenly represented: cues to action (n=159) and personal threat (n=145) dominated, whereas coping appraisal (n=82), barriers (n=36), and social norms (n=25) were less common. Conclusions: We propose a taxonomy structured by behavioral drivers, social scale, and memory to clarify dominant paradigms and their empirical basis. Mapping models to psychosocial constructs provides guidance for more theory-informed and data grounded-integration of behavioral processes in epidemiological modeling."}
{"id": "2602.16022", "pdf": "https://arxiv.org/pdf/2602.16022", "abs": "https://arxiv.org/abs/2602.16022", "authors": ["Kyung-Han Choi", "Thomas Hillen"], "title": "The lingering phenomenon and pattern formation in a nonlocal population model with cognitive map", "categories": ["math.AP", "q-bio.PE"], "comment": null, "summary": "The rates at which individuals memorize and forget environmental information strongly influence their movement paths and long-term space use. To understand how these cognitive time scales shape population-level patterns, we propose and analyze a nonlocal population model with a cognitive map. The population density moves by a Fokker--Planck type diffusion driven by a cognitive map that stores a habitat quality information nonlocally. The map is updated through local presence with learning and forgetting rates, and we consider both truncated and normalized perception kernels.\n  We first study the movement-only system without growth. We show that finite perceptual range generates spatial heterogeneity in the cognitive map even in nearly homogeneous habitats, and we prove a lingering phenomenon on unimodal landscapes: for the fixed high learning rate, the peak density near the best location is maximized at an intermediate forgetting rate.\n  We then couple cognitive diffusion to logistic growth. We establish local well-posedness and persistence by proving instability of the extinction equilibrium and the existence of a positive steady state, with uniqueness under an explicit condition on the motility function. Numerical simulations show that lingering persists under logistic growth and reveal a trade-off between the lingering and total population size, since near the strongest-lingering regime the total mass can fall below the total resource, in contrast to classical random diffusive--logistic models."}
